{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd797da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from model.vit import VisionTransformerSmall\n",
    "from utils.model_io import save_model\n",
    "from utils.config_loader import load_config\n",
    "from utils.data_loader import DatasetLoader\n",
    "from pynvml import (\n",
    "  nvmlInit, nvmlDeviceGetName, nvmlShutdown,\n",
    "  nvmlDeviceGetHandleByIndex,\n",
    "  nvmlDeviceGetMemoryInfo,\n",
    "  nvmlDeviceGetUtilizationRates\n",
    ")\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from timm.data import Mixup\n",
    "import numpy as np\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import wandb\n",
    "from utils.checkpoints_manager import CheckpointManager\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, class_count,\n",
    "                  mixup_fn=None, scheduler_warmup_enabled=False, scheduler_warmup=None):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  progress_bar = tqdm(loader, desc=\"Training\", leave=True)\n",
    "  for  inputs, targets in progress_bar:\n",
    "      #print(f'input shape : {inputs.shape}, taget_shape : {targets.shape}, target dim : {targets.ndim}')\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      if mixup_fn is not None:\n",
    "          inputs, targets = mixup_fn(inputs, targets)\n",
    "\n",
    "      if targets.ndim == 2:\n",
    "          targets = targets.type_as(inputs)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if scheduler_warmup_enabled:\n",
    "          if scheduler_warmup is None : raise Exception(f'scheduler warmup is enabled, but no scheduler object has been passed in train_one_epoch function')\n",
    "          scheduler_warmup.step()\n",
    "\n",
    "      running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "      if targets.ndim == 2:\n",
    "          # MixUp with soft labels\n",
    "          _, predicted = outputs.max(1)\n",
    "          _, true_classes = targets.max(1)  # Take argmax of soft labels as true class\n",
    "          correct += predicted.eq(true_classes).sum().item()\n",
    "          total += targets.size(0)\n",
    "      else :\n",
    "          _, predicted = outputs.max(1)\n",
    "          correct += predicted.eq(targets).sum().item()\n",
    "          total += targets.size(0)\n",
    "\n",
    "      # Update progress bar with metrics\n",
    "      if total > 0:\n",
    "          avg_loss = running_loss / total\n",
    "          accuracy = 100. * correct / total\n",
    "          progress_bar.set_postfix({\n",
    "              \"Loss\": f\"{avg_loss:.4f}\",\n",
    "              \"Acc\": f\"{accuracy:.2f}%\"\n",
    "          })\n",
    "\n",
    "      else : raise Exception(f'Expected non-zero batch size, but got 0 targets. Check if the dataset is empty or DataLoader is misconfigured.')\n",
    "\n",
    "  \n",
    "  return avg_loss, accuracy\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  progress_bar = tqdm(loader, desc=\"Validation\", leave=True)\n",
    "  with torch.no_grad():\n",
    "      for inputs, labels in progress_bar:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          running_loss += loss.item() * inputs.size(0)\n",
    "          # Compute accuracy\n",
    "          _, predicted = outputs.max(1)\n",
    "          correct += predicted.eq(labels).sum().item()\n",
    "          total += labels.size(0)\n",
    "\n",
    "          # Avoid division by zero on first step\n",
    "          if total > 0:\n",
    "              avg_loss = running_loss / total\n",
    "              accuracy = 100. * correct / total\n",
    "\n",
    "              progress_bar.set_postfix({\n",
    "                  \"Loss\": f\"{avg_loss:.4f}\",\n",
    "                  \"Acc\": f\"{accuracy:.2f}%\"\n",
    "              })\n",
    "              \n",
    "  return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config\n",
      "Using device: cuda\n",
      "-----------\n",
      "Label Smoothening is Disabled\n",
      "LR Scheduler is Disabled\n",
      "LR SchedulerWarmup is Enabled\n",
      "MixUp is Disabled\n",
      "Data Augmentation is Disabled\n",
      "-----------\n",
      "loading dataset : CIFAR10\n",
      "training size  : 50000\n",
      "validation size : 10000\n",
      "Classes: 10\n",
      "Sample label: 6\n",
      "Train batches: 391, Validation batches: 79\n",
      "data sanity check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/wd/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape and labels shape in training data - one batch : torch.Size([128, 3, 32, 32]), torch.Size([128])\n",
      "initializing wandb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwritd97\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.5s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wd/Documents/work_stuff/ViT_REPLICATION/notebooks/wandb/run-20250617_233221-vittinyv1_cifar10_runV3_20250616_070813</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/writd97/VIT_EXPLORATION/runs/vittinyv1_cifar10_runV3_20250616_070813' target=\"_blank\">vittinyv1_cifar10_runV3</a></strong> to <a href='https://wandb.ai/writd97/VIT_EXPLORATION' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/writd97/VIT_EXPLORATION' target=\"_blank\">https://wandb.ai/writd97/VIT_EXPLORATION</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/writd97/VIT_EXPLORATION/runs/vittinyv1_cifar10_runV3_20250616_070813' target=\"_blank\">https://wandb.ai/writd97/VIT_EXPLORATION/runs/vittinyv1_cifar10_runV3_20250616_070813</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact vittinyv1_cifar10_runV3_checkpoint:latest, 301.61MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:3:19.7 (1.5MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Configuration:\n",
      "  dataset: CIFAR10\n",
      "  data_path: /home/wd/Documents/work_stuff/ViT_REPLICATION/data/CIFAR10\n",
      "  channels: 3\n",
      "  batch_size: 128\n",
      "  num_workers: 8\n",
      "  img_size: 32\n",
      "  mean_aug: [0.4914, 0.4822, 0.4465]\n",
      "  std_aug: [0.2023, 0.1994, 0.201]\n",
      "  num_classes: 10\n",
      "Model Configuration:\n",
      "  name: vit_tiny_v1\n",
      "  patch_size: 4\n",
      "  emb_size: 512\n",
      "  depth: 10\n",
      "  num_heads: 8\n",
      "  mlp_ratio: 3.0\n",
      "  dropout: 0.2\n",
      "Training Configuration:\n",
      "  mixup: {'enabled': False, 'mixup_alpha': 0.0, 'cutmix_alpha': 0.0, 'label_smoothing_mixup': 0.0}\n",
      "  epochs: 100\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.0\n",
      "  scheduler: False\n",
      "  scheduler_warmup: True\n",
      "  warmup_steps: 30\n",
      "  label_smoothing_enabled: False\n",
      "  label_smoothing: 0.0\n",
      "  es_patience: 10\n",
      "  es_improv_delta: 0.001\n",
      "  augmentation_enabled: False\n",
      "Total Trainable Parameters: 26,340,874 (26.34M)\n",
      "printing a few of the model weights - should be random and unique in every run.\n",
      "tensor([[ 0.0980,  0.0169, -0.0253, -0.0753],\n",
      "        [-0.1301, -0.0079,  0.0929, -0.1349],\n",
      "        [ 0.0063,  0.0707, -0.1431, -0.0748],\n",
      "        [ 0.0864,  0.0056,  0.0776, -0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "#def main():\n",
    "print('loading config')\n",
    "# Load config\n",
    "config = load_config(f\"{ROOT_DIR_PATH}/config/vit_config.yaml\")\n",
    "PROJECT_NAME = config['project']\n",
    "RUN_NAME = config['run']\n",
    "RUN_NOTES = config['run_notes']\n",
    "WANDB_TAGS = config['wandb_tags']\n",
    "\n",
    "# *************  choosing the DATASET & MODEL *************\n",
    "dataset_config = config[\"data\"]['CIFAR10']\n",
    "modelConfig = config[\"model\"]\n",
    "specific_config = modelConfig['VIT_TINYV1']\n",
    "# **********************************************************\n",
    "\n",
    "# data\n",
    "DATASET = dataset_config[\"dataset\"]\n",
    "DATA_DIR =f'{ROOT_DIR_PATH}/data/{DATASET}/'\n",
    "BATCH = dataset_config[\"batch_size\"]\n",
    "NUM_WORKERS = dataset_config[\"num_workers\"]\n",
    "IMAGE = dataset_config[\"img_size\"]\n",
    "NUM_CLASSES = dataset_config[\"num_classes\"]\n",
    "CHANNELS = dataset_config[\"channels\"]\n",
    "if DATASET == 'TINYIMAGENET200':\n",
    "    SUBSET_ENABLED = dataset_config['subset_enabled']\n",
    "    SUBSET_SIZE = dataset_config['subset_size']\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = specific_config['name']\n",
    "modelConfigDict = {\n",
    "    'CHANNEL' : CHANNELS,\n",
    "    'PATCH' : specific_config['patch_size'],\n",
    "    'EMBEDDING' : specific_config['emb_size'],\n",
    "    'IMAGE' : IMAGE,\n",
    "    'NUM_HEADS' : specific_config['num_heads'],\n",
    "    'MLP_RATIO' : specific_config['mlp_ratio'],\n",
    "    'DROPOUT' : specific_config['dropout'],\n",
    "    'NUM_CLASSES' : NUM_CLASSES,\n",
    "    'DEPTH' : specific_config['depth']\n",
    "}    \n",
    "\n",
    "# training config\n",
    "trainingConfig = config['training']\n",
    "LEARNING_RATE = trainingConfig['lr']\n",
    "EPOCHS = trainingConfig['epochs']\n",
    "WEIGHT_DECAY = trainingConfig['weight_decay']\n",
    "USE_SCHEDULER = trainingConfig['scheduler']\n",
    "USE_SCHEDULER_WARMUP = trainingConfig['scheduler_warmup']\n",
    "WARMUP_STEPS = trainingConfig['warmup_steps']\n",
    "USE_LABEL_SMOOTHENING = trainingConfig[\"label_smoothing_enabled\"]\n",
    "LABEL_SMOOTHENING = trainingConfig[\"label_smoothing\"]\n",
    "EARLY_STOPPING_PATIENCE = trainingConfig[\"es_patience\"]\n",
    "EARLY_STOPPING_IMPROVEMENT_DELTA = trainingConfig[\"es_improv_delta\"]\n",
    "AUG_ENABLED = trainingConfig[\"augmentation_enabled\"]\n",
    "\n",
    "# mixup config\n",
    "mixupConfig = trainingConfig['mixup']\n",
    "MIXUP_ALPHA = mixupConfig[\"mixup_alpha\"]\n",
    "CUTMIX_ALPHA = mixupConfig[\"cutmix_alpha\"]\n",
    "LABEL_SMOOTHENING_MIXUP = mixupConfig[\"label_smoothing_mixup\"]\n",
    "USE_MIXUP = mixupConfig[\"enabled\"]\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# logging switches\n",
    "print('-----------')\n",
    "print('Label Smoothening is Enabled') if USE_LABEL_SMOOTHENING else print('Label Smoothening is Disabled')\n",
    "print('LR Scheduler is Enabled') if USE_SCHEDULER else print('LR Scheduler is Disabled')\n",
    "print('LR SchedulerWarmup is Enabled') if USE_SCHEDULER_WARMUP else print('LR SchedulerWarmup is Disabled')\n",
    "print('MixUp is Enabled') if USE_MIXUP else print('MixUp is Disabled')\n",
    "print('Data Augmentation is Enabled') if AUG_ENABLED else print('Data Augmentation is Disabled')\n",
    "if DATASET == 'TINYIMAGENET': print(f'Subset is Enabled - {SUBSET_SIZE}') if SUBSET_ENABLED else print('Subset is Disabled.')\n",
    "print('-----------')\n",
    "# === Mixup Setup ===\n",
    "mixup_fn = None\n",
    "if USE_MIXUP:\n",
    "    mixup_fn = Mixup(\n",
    "        mixup_alpha=MIXUP_ALPHA,\n",
    "        cutmix_alpha=CUTMIX_ALPHA,\n",
    "        label_smoothing=LABEL_SMOOTHENING_MIXUP,\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "    train_criterion = nn.BCEWithLogitsLoss()\n",
    "    val_criterion = nn.CrossEntropyLoss(label_smoothing=0.0) #NO LABEL SMOOTHENING during validation\n",
    "else:        \n",
    "    mixup_fn = None\n",
    "    train_criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHENING if USE_LABEL_SMOOTHENING else 0.0)\n",
    "    val_criterion =  nn.CrossEntropyLoss(label_smoothing=0.0) #NO LABEL SMOOTHENING during validation\n",
    "\n",
    "# loading data\n",
    "print(f'loading dataset : {DATASET}')\n",
    "loader = DatasetLoader(dataset_name=DATASET,\n",
    "                        data_dir=DATA_DIR,\n",
    "                        batch_size=BATCH,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        img_size=IMAGE)\n",
    "train_loader, val_loader = loader.get_loaders()\n",
    "print(f\"Train batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "print('data sanity check')\n",
    "for images, labels in train_loader:\n",
    "    print(f'image shape and labels shape in training data - one batch : {images.shape}, {labels.shape}')\n",
    "    break\n",
    "\n",
    "\n",
    "# initializing wandb\n",
    "print('initializing wandb')\n",
    "\n",
    "# creating and storing runids for future reference.\n",
    "timestamp = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#run_id = f\"{RUN_NAME}_{timestamp}\"\n",
    "# writd97/VIT_EXPLORATION/vittinyv1_cifar10_runV3_20250616_070813\n",
    "run_id = \"vittinyv1_cifar10_runV3_20250616_070813\"\n",
    "runid_file_path = f\"{ROOT_DIR_PATH}/wandb_runids/wandb_run_id.txt\"\n",
    "dir_path = os.path.dirname(runid_file_path)\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "with open(runid_file_path, \"w\") as f:\n",
    "    f.write(run_id)\n",
    "\n",
    "#WANDB_API_KEY = os.environ.get(\"WANDB_API_KEY\")\n",
    "WANDB_API_KEY = '7787ed71404a24484725a28084b6bfd8e7744997'\n",
    "wandb.login(key=WANDB_API_KEY, relogin=True)\n",
    "wandb.init(\n",
    "    project=PROJECT_NAME, \n",
    "    id=run_id,\n",
    "    name=RUN_NAME,\n",
    "    notes = RUN_NOTES,\n",
    "    #resume=\"never\",\n",
    "    resume = \"must\",\n",
    "    #config=loggable_config,\n",
    "    config = None,\n",
    "    allow_val_change=True,\n",
    "    tags=WANDB_TAGS\n",
    "    )\n",
    "\n",
    "wandb.define_metric(\"*\", summary=\"none\")  # suppress all\n",
    "checkpoint_manager = CheckpointManager()\n",
    "\n",
    "\n",
    "\n",
    "# loading model *********************************\n",
    "\n",
    "artifact = wandb.use_artifact(f'writd97/{PROJECT_NAME}/vittinyv1_cifar10_runV3_checkpoint:latest', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "ckpt_path = os.path.join(artifact_dir, 'vittinyv1_cifar10_runV3_last_checkpoint.pth')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "model = VisionTransformerSmall(**modelConfigDict).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# model loaded ****************************************\n",
    "\n",
    "# logging model parameters and config\n",
    "print('Data Configuration:')\n",
    "for k, v in dataset_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"Model Configuration:\")\n",
    "for k, v in specific_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"Training Configuration:\")\n",
    "for k, v in trainingConfig.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {total_params:,} ({total_params / 1e6:.2f}M)\")\n",
    "print(f'printing a few of the model weights - should be random and unique in every run.')\n",
    "print(model.patch_embed.projection.weight[0][0][:5]) \n",
    "\n",
    "# optimizer & scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "scheduler_warmup_obj = None\n",
    "scheduler_warmup_enabled_flag = False\n",
    "if USE_SCHEDULER : \n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "elif USE_SCHEDULER_WARMUP:\n",
    "    scheduler_warmup_enabled_flag = True\n",
    "    num_training_steps = EPOCHS * len(train_loader)\n",
    "    num_warmup_steps = WARMUP_STEPS * len(train_loader)\n",
    "\n",
    "    scheduler_warmup = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    scheduler_warmup_obj = scheduler_warmup\n",
    "\n",
    "\n",
    "# loggable_config = {\n",
    "#     \"dataset\": DATASET,\n",
    "#     \"train_sample\":len(train_loader),\n",
    "#     \"val_sample\": len(val_loader),\n",
    "#     \"subset_size\": SUBSET_SIZE if DATASET == 'TINYIMAGENET200' else np.nan,\n",
    "#     \"batch_size\": BATCH,\n",
    "#     \"img_size\": IMAGE,\n",
    "    \n",
    "#     \"model_name\": MODEL_NAME,\n",
    "#     \"model_param_m\": round((total_params / 1e6),2),\n",
    "#     \"patch_size\": specific_config['patch_size'],\n",
    "#     \"embed_dim\": specific_config[\"emb_size\"],\n",
    "#     \"depth\":specific_config[\"depth\"],\n",
    "#     \"heads\": specific_config[\"num_heads\"],\n",
    "#     \"mlp_ratio\": specific_config[\"mlp_ratio\"],\n",
    "#     \"dropout\":specific_config[\"dropout\"],\n",
    "\n",
    "#     \"epochs\": config[\"training\"][\"epochs\"],\n",
    "#     \"lr\": config[\"training\"][\"lr\"],\n",
    "#     \"mixup_alpha\": config[\"training\"][\"mixup\"][\"mixup_alpha\"] if config[\"training\"][\"mixup\"][\"enabled\"] else np.nan,\n",
    "#     \"cutmix_alpha\": config[\"training\"][\"mixup\"][\"cutmix_alpha\"] if config[\"training\"][\"mixup\"][\"enabled\"] else np.nan,\n",
    "#     \"label_smooth_mixup\": config[\"training\"][\"mixup\"][\"label_smoothing_mixup\"] if config[\"training\"][\"mixup\"][\"enabled\"] else np.nan,\n",
    "#     \"label_smooth\": config[\"training\"][\"label_smoothing\"] if config[\"training\"][\"label_smoothing_enabled\"] else np.nan,\n",
    "#     \"weight_decay\": config[\"training\"][\"weight_decay\"],\n",
    "#     \"augmentation\":config[\"training\"][\"augmentation_enabled\"]\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045caf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/391 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 3.69 GiB of which 45.31 MiB is free. Including non-PyTorch memory, this process has 3.62 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 283.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch,EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmixup_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mscheduler_warmup_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_warmup_enabled_flag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mscheduler_warmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_warmup_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, val_criterion, device)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_SCHEDULER : scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device, class_count, mixup_fn, scheduler_warmup_enabled, scheduler_warmup)\u001b[0m\n\u001b[1;32m     49\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mtype_as(inputs)\n\u001b[1;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/model/vit.py:136\u001b[0m, in \u001b[0;36mVisionTransformerSmall.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    134\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cls_tokens, x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    135\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding[:, :x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), :]\n\u001b[0;32m--> 136\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m cls_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(cls_out)\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/model/vit.py:37\u001b[0m, in \u001b[0;36mTransformerEncoderBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work_stuff/ViT_REPLICATION/_vit_rep_py310/lib/python3.10/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 3.69 GiB of which 45.31 MiB is free. Including non-PyTorch memory, this process has 3.62 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 283.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "# monitors initialization\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = np.inf\n",
    "best_model_state = None\n",
    "# gpu utilization\n",
    "max_mem_used = 0\n",
    "max_gpu_util = 0\n",
    "max_mem_util = 0\n",
    "# earlystopping\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Training loop\n",
    "nvmlInit()\n",
    "handle = nvmlDeviceGetHandleByIndex(0)\n",
    "gpu_name = nvmlDeviceGetName(handle)\n",
    "\n",
    "startTime = time.time()\n",
    "for epoch in range(start_epoch,EPOCHS+1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, train_criterion, optimizer, device, class_count=NUM_CLASSES,\n",
    "                                            mixup_fn=mixup_fn,\n",
    "                                            scheduler_warmup_enabled=scheduler_warmup_enabled_flag,\n",
    "                                            scheduler_warmup=scheduler_warmup_obj)\n",
    "    val_loss, val_acc = validate(model, val_loader, val_criterion, device)\n",
    "    if USE_SCHEDULER : scheduler.step()\n",
    "\n",
    "    # Monitor GPU usage\n",
    "    mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    util_info = nvmlDeviceGetUtilizationRates(handle)\n",
    "    mem_used_mb = mem_info.used / (1024 ** 2)\n",
    "    max_mem_used = max(max_mem_used, mem_used_mb)\n",
    "    max_gpu_util = max(max_gpu_util, util_info.gpu)\n",
    "    max_mem_util = max(max_mem_util, util_info.memory)\n",
    "    \n",
    "    import copy\n",
    "    if val_acc > best_val_acc + EARLY_STOPPING_IMPROVEMENT_DELTA:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss = val_loss\n",
    "        corresponding_train_acc = train_acc\n",
    "        corresponding_train_loss = train_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        best_optimizer_state = copy.deepcopy(optimizer.state_dict())\n",
    "        best_scheduler_state = copy.deepcopy(scheduler_warmup.state_dict())\n",
    "\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement+=1\n",
    "\n",
    "    # Early stopping condition\n",
    "    if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"\\nEarly stopping triggered. No improvement(delta={EARLY_STOPPING_IMPROVEMENT_DELTA}) in val_acc for {EARLY_STOPPING_PATIENCE} consecutive epochs.\")\n",
    "        break\n",
    "\n",
    "    endTime = time.time()\n",
    "    elapsedTime = endTime - startTime\n",
    "    hours = int(elapsedTime // 3600)\n",
    "    minutes = int((elapsedTime % 3600) // 60)\n",
    "    seconds = int(elapsedTime % 60)\n",
    "    print(f\"Elapsed Time : {hours}h : {minutes}m : {seconds}s\")\n",
    "\n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch,\n",
    "        \"Train Loss\": train_loss,\n",
    "        \"Train Acc\": train_acc,\n",
    "        \"Val Loss\": val_loss,\n",
    "        \"Val Acc\": val_acc\n",
    "    })\n",
    "    # saving the latest best model/optimizer dict at 10 epochs interval\n",
    "    checkpoint_manager.save_and_upload(\n",
    "        best_epoch,\n",
    "        best_model_state,\n",
    "        best_optimizer_state,\n",
    "        best_scheduler_state,\n",
    "        extra={\"val_acc\": best_val_acc,\n",
    "                \"val_loss\": best_val_loss,\n",
    "                \"train_acc\":corresponding_train_acc,\n",
    "                \"train_loss\":corresponding_train_loss\n",
    "            }\n",
    "        )\n",
    "\n",
    "# gpu monitoring shutdown \n",
    "nvmlShutdown()\n",
    "\n",
    "# saving the best state\n",
    "print('\\n====== Model Performance =======')\n",
    "print(f\"Train     Loss: {corresponding_train_loss:.4f},    Accuracy: {corresponding_train_acc:.2f}%\")\n",
    "print(f\"Val(Best) Loss: {best_val_loss:.4f}, Accuracy: {best_val_acc:.2f}%\")\n",
    "print('====== Hardware Performance =======')\n",
    "print(f\"GPU Used : {gpu_name}\")\n",
    "print(f\"Peak GPU Memory: {max_mem_used:.2f} MB\")\n",
    "print(f\"Peak GPU Utilization: {max_gpu_util}%\")\n",
    "print(f\"Peak Memory Bandwidth Utilization: {max_mem_util}%\")\n",
    "\n",
    "print('\\n\\n-----------')\n",
    "print(f\"saving & uploading the best model state as till epoch : {epoch}\")\n",
    "print(f\"Best model Epoch : {best_epoch}\")\n",
    "checkpoint_manager.save_checkpoint(\n",
    "    best_epoch,\n",
    "    best_model_state,\n",
    "    best_optimizer_state,\n",
    "    best_scheduler_state,\n",
    "    extra={\"val_acc\": best_val_acc,\n",
    "                \"val_loss\": best_val_loss,\n",
    "                \"train_acc\":corresponding_train_acc,\n",
    "                \"train_loss\":corresponding_train_loss\n",
    "                }\n",
    ")\n",
    "checkpoint_manager.upload_to_wandb()\n",
    "time.sleep(10)\n",
    "checkpoint_manager.cleanup_old_wandb_artifacts()   \n",
    "print('-----------\\n')\n",
    "print(f\"\\nTraining completed in: {hours}h : {minutes}m : {seconds}s\\n\\n\")\n",
    "\n",
    "wandb.run.summary[\"performance\"] = {\n",
    "\"trainAcc\": corresponding_train_acc,\n",
    "\"trainLoss\": corresponding_train_loss,\n",
    "\"valAcc\": best_val_acc,\n",
    "\"valLoss\": best_val_loss,\n",
    "\"elapsedTime\":f\"{hours}h : {minutes}m : {seconds}s\"\n",
    "}\n",
    "# finishing the run\n",
    "wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1277a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee523ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226afd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_vit_rep_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
