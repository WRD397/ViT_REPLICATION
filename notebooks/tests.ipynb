{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "643b97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8f6ac",
   "metadata": {},
   "source": [
    "# Data - CIFAR10\n",
    "have 10 classes - labelled 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db5622d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data which is already there in torchvision repo\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataPath = f'/home/wd/Documents/work_stuff/ViT_REPLICATION/data/CIFAR10'\n",
    "dataset = torchvision.datasets.CIFAR10(root=dataPath, train=False, download=True,  \n",
    "                                        transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b1d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89218a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6196, 0.6235, 0.6471,  ..., 0.5373, 0.4941, 0.4549],\n",
       "         [0.5961, 0.5922, 0.6235,  ..., 0.5333, 0.4902, 0.4667],\n",
       "         [0.5922, 0.5922, 0.6196,  ..., 0.5451, 0.5098, 0.4706],\n",
       "         ...,\n",
       "         [0.2667, 0.1647, 0.1216,  ..., 0.1490, 0.0510, 0.1569],\n",
       "         [0.2392, 0.1922, 0.1373,  ..., 0.1020, 0.1137, 0.0784],\n",
       "         [0.2118, 0.2196, 0.1765,  ..., 0.0941, 0.1333, 0.0824]],\n",
       "\n",
       "        [[0.4392, 0.4353, 0.4549,  ..., 0.3725, 0.3569, 0.3333],\n",
       "         [0.4392, 0.4314, 0.4471,  ..., 0.3725, 0.3569, 0.3451],\n",
       "         [0.4314, 0.4275, 0.4353,  ..., 0.3843, 0.3725, 0.3490],\n",
       "         ...,\n",
       "         [0.4863, 0.3922, 0.3451,  ..., 0.3804, 0.2510, 0.3333],\n",
       "         [0.4549, 0.4000, 0.3333,  ..., 0.3216, 0.3216, 0.2510],\n",
       "         [0.4196, 0.4118, 0.3490,  ..., 0.3020, 0.3294, 0.2627]],\n",
       "\n",
       "        [[0.1922, 0.1843, 0.2000,  ..., 0.1412, 0.1412, 0.1294],\n",
       "         [0.2000, 0.1569, 0.1765,  ..., 0.1216, 0.1255, 0.1333],\n",
       "         [0.1843, 0.1294, 0.1412,  ..., 0.1333, 0.1333, 0.1294],\n",
       "         ...,\n",
       "         [0.6941, 0.5804, 0.5373,  ..., 0.5725, 0.4235, 0.4980],\n",
       "         [0.6588, 0.5804, 0.5176,  ..., 0.5098, 0.4941, 0.4196],\n",
       "         [0.6275, 0.5843, 0.5176,  ..., 0.4863, 0.5059, 0.4314]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "856fd4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8752e9",
   "metadata": {},
   "source": [
    "\n",
    "### img.numpy()  vs  np.array(img)\n",
    "For example, the tensor is -> img.shape = torch.Size([3, 32, 32])\n",
    "\n",
    "#### img.numpy() :::: What it does:\n",
    "\n",
    "Converts the PyTorch Tensor to a NumPy array.\n",
    "\n",
    "Shares the same memory (zero-copy).\n",
    "\n",
    "Only works if the tensor is on CPU.\n",
    "\n",
    "✅ Fast and efficient.\n",
    "⚠️ Will raise an error if the tensor is on GPU.\n",
    "\n",
    "img = img.cpu()  # Must be on CPU\n",
    "img_np = img.numpy()\n",
    "\n",
    "#### np.array(img) :::: What it does:\n",
    "What it does:\n",
    "\n",
    "Uses NumPy to create an array from the tensor.\n",
    "\n",
    "Copies the data — does not share memory.\n",
    "\n",
    "Slower and not recommended for tensors.\n",
    "\n",
    "Works even if the tensor is on GPU (but will be wrong!).\n",
    "\n",
    "⚠️ Inefficient.\n",
    "⚠️ May silently produce unexpected results or copy issues.\n",
    "\n",
    "\n",
    "| Method          | Converts To NumPy | Shares Memory? | Fast? | GPU Compatible?      | Recommended? |\n",
    "| --------------- | ----------------- | -------------- | ----- | -------------------- | ------------ |\n",
    "| `img.numpy()`   | ✅                 | ✅ Yes          | ✅ Yes | ❌ No (CPU only)      | ✅ Yes        |\n",
    "| `np.array(img)` | ✅                 | ❌ No (copy)    | ❌ No  | ⚠️ Can silently fail | ❌ No         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0550b0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.61960787, 0.62352943, 0.64705884, ..., 0.5372549 ,\n",
       "         0.49411765, 0.45490196],\n",
       "        [0.59607846, 0.5921569 , 0.62352943, ..., 0.53333336,\n",
       "         0.49019608, 0.46666667],\n",
       "        [0.5921569 , 0.5921569 , 0.61960787, ..., 0.54509807,\n",
       "         0.50980395, 0.47058824],\n",
       "        ...,\n",
       "        [0.26666668, 0.16470589, 0.12156863, ..., 0.14901961,\n",
       "         0.05098039, 0.15686275],\n",
       "        [0.23921569, 0.19215687, 0.13725491, ..., 0.10196079,\n",
       "         0.11372549, 0.07843138],\n",
       "        [0.21176471, 0.21960784, 0.1764706 , ..., 0.09411765,\n",
       "         0.13333334, 0.08235294]],\n",
       "\n",
       "       [[0.4392157 , 0.43529412, 0.45490196, ..., 0.37254903,\n",
       "         0.35686275, 0.33333334],\n",
       "        [0.4392157 , 0.43137255, 0.44705883, ..., 0.37254903,\n",
       "         0.35686275, 0.34509805],\n",
       "        [0.43137255, 0.42745098, 0.43529412, ..., 0.38431373,\n",
       "         0.37254903, 0.34901962],\n",
       "        ...,\n",
       "        [0.4862745 , 0.39215687, 0.34509805, ..., 0.38039216,\n",
       "         0.2509804 , 0.33333334],\n",
       "        [0.45490196, 0.4       , 0.33333334, ..., 0.32156864,\n",
       "         0.32156864, 0.2509804 ],\n",
       "        [0.41960785, 0.4117647 , 0.34901962, ..., 0.3019608 ,\n",
       "         0.32941177, 0.2627451 ]],\n",
       "\n",
       "       [[0.19215687, 0.18431373, 0.2       , ..., 0.14117648,\n",
       "         0.14117648, 0.12941177],\n",
       "        [0.2       , 0.15686275, 0.1764706 , ..., 0.12156863,\n",
       "         0.1254902 , 0.13333334],\n",
       "        [0.18431373, 0.12941177, 0.14117648, ..., 0.13333334,\n",
       "         0.13333334, 0.12941177],\n",
       "        ...,\n",
       "        [0.69411767, 0.5803922 , 0.5372549 , ..., 0.57254905,\n",
       "         0.42352942, 0.49803922],\n",
       "        [0.65882355, 0.5803922 , 0.5176471 , ..., 0.50980395,\n",
       "         0.49411765, 0.41960785],\n",
       "        [0.627451  , 0.58431375, 0.5176471 , ..., 0.4862745 ,\n",
       "         0.5058824 , 0.43137255]]], shape=(3, 32, 32), dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87bf7937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(img.numpy(), (1, 2, 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb1c1d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(img.numpy(), (1, 2, 0))) # you need to pass the index : channel, height, width -> height, width, channel\n",
    "plt.title(f\"Class: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb9ecff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = dataset[9999]\n",
    "plt.imshow(np.transpose(img.numpy(), (1, 2, 0))) # you need to pass the index : channel, height, width -> height, width, channel\n",
    "plt.title(f\"Class: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb525537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920874f1",
   "metadata": {},
   "source": [
    "# Patch Embedding\n",
    "📦 What is the Goal?\n",
    "We want to:\n",
    "\n",
    "Break an image into non-overlapping patches (e.g., 4×4).\n",
    "\n",
    "Flatten each patch.\n",
    "\n",
    "Project each patch into a vector space (i.e., embedding).\n",
    "\n",
    "Output shape should be (Batch, Num_Patches, Embedding_Dim) — just like how Transformers expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148eeb7",
   "metadata": {},
   "source": [
    "\n",
    "### whats the significance of conv2d here ?\n",
    "\n",
    "🎯 What are we trying to do?\n",
    "We want to convert an image (e.g., 32×32) into a sequence of patch vectors, where each patch is represented by a fixed-size vector (like 64-dim, 128-dim etc). This is necessary because:\n",
    "\n",
    "Transformers expect input as a sequence of vectors: (batch, num_patches, embedding_dim)\n",
    "\n",
    "So we need some way to go from image pixels → patch vectors.\n",
    "\n",
    "🧠 This single Conv2d call:\n",
    "\n",
    "Extracts non-overlapping patches\n",
    "\n",
    "Flattens each patch internally\n",
    "\n",
    "Applies a learnable linear transformation to each patch\n",
    "\n",
    "So it acts like a smart patch extractor + embedder in one step.\n",
    "\n",
    "🔍 Why Conv2D works perfectly here\n",
    "kernel_size = patch_size: it looks at one patch at a time.\n",
    "\n",
    "stride = patch_size: it moves in steps of patch size (no overlap).\n",
    "\n",
    "out_channels = emb_size: it maps each patch to an emb_size-d vector.\n",
    "\n",
    "This is exactly what we want:\n",
    "\n",
    "Divide the image into fixed-size patches, and turn each patch into a vector.\n",
    "\n",
    "### 🧪 Without Conv2D — what would you do?\n",
    "\n",
    "If you didn’t use Conv2d, you’d need to:\n",
    "\n",
    "Slice the image manually into 4×4 patches (nested loops).\n",
    "\n",
    "Flatten each patch into a vector.\n",
    "\n",
    "Apply a learnable linear projection (nn.Linear) to each one.\n",
    "\n",
    "That’s a LOT of code and slow on GPU.\n",
    "\n",
    "✅ Conv2d gives you all that in one fast, GPU-optimized layer.\n",
    "\n",
    "🔁 Think of Conv2D here not as a CNN, but as a fast way to do:\n",
    "Patch → Vector projection for all patches at once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1d55d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=4, emb_size=128, img_size=32):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        self.projection = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)       # (B, emb_size, H/patch, W/patch)\n",
    "        print(f'after applying conv2D, {x.shape}')\n",
    "        x = x.flatten(2)             # (B, emb_size, N)\n",
    "        print(f'after flattening, {x.shape}')\n",
    "        x = x.transpose(1, 2)        # (B, N, emb_size)\n",
    "        print(f'after transpose {x.shape}')\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "226fe69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2863, 0.3843, 0.3882,  ..., 0.5294, 0.5294, 0.7961],\n",
       "          [0.2706, 0.3294, 0.2667,  ..., 0.3333, 0.2784, 0.4706],\n",
       "          [0.2706, 0.3529, 0.2431,  ..., 0.2902, 0.2078, 0.2431],\n",
       "          ...,\n",
       "          [0.4824, 0.5176, 0.5059,  ..., 0.4235, 0.2431, 0.1059],\n",
       "          [0.4510, 0.4824, 0.5059,  ..., 0.4510, 0.2588, 0.1059],\n",
       "          [0.4549, 0.4745, 0.5059,  ..., 0.4549, 0.2667, 0.1059]],\n",
       "\n",
       "         [[0.3059, 0.4039, 0.4157,  ..., 0.5882, 0.5843, 0.8431],\n",
       "          [0.2863, 0.3490, 0.2941,  ..., 0.3725, 0.3216, 0.5216],\n",
       "          [0.2863, 0.3725, 0.2784,  ..., 0.3176, 0.2431, 0.2902],\n",
       "          ...,\n",
       "          [0.5020, 0.5176, 0.5020,  ..., 0.4196, 0.2353, 0.1059],\n",
       "          [0.4745, 0.4863, 0.4941,  ..., 0.4549, 0.2549, 0.1059],\n",
       "          [0.4706, 0.4784, 0.5020,  ..., 0.4510, 0.2549, 0.1020]],\n",
       "\n",
       "         [[0.2941, 0.4431, 0.4471,  ..., 0.5961, 0.6039, 0.8745],\n",
       "          [0.2745, 0.3804, 0.3176,  ..., 0.3490, 0.3137, 0.5294],\n",
       "          [0.2745, 0.3922, 0.2902,  ..., 0.2745, 0.2118, 0.2706],\n",
       "          ...,\n",
       "          [0.3765, 0.4000, 0.3922,  ..., 0.3451, 0.2157, 0.1098],\n",
       "          [0.3569, 0.3725, 0.3882,  ..., 0.3686, 0.2314, 0.1059],\n",
       "          [0.3529, 0.3686, 0.3961,  ..., 0.3686, 0.2275, 0.1020]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## UNSQUEEZE : Adds a dimension of size 1 at the specified dim (axis).\n",
    "img_tensor = img.unsqueeze(0)\n",
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "154349fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bb6adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 4\n",
    "n_patches = (32 // patch_size) ** 2\n",
    "projection = nn.Conv2d(3, 128, kernel_size=patch_size, stride=patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d22fd5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2863, 0.3843, 0.3882,  ..., 0.5294, 0.5294, 0.7961],\n",
       "          [0.2706, 0.3294, 0.2667,  ..., 0.3333, 0.2784, 0.4706],\n",
       "          [0.2706, 0.3529, 0.2431,  ..., 0.2902, 0.2078, 0.2431],\n",
       "          ...,\n",
       "          [0.4824, 0.5176, 0.5059,  ..., 0.4235, 0.2431, 0.1059],\n",
       "          [0.4510, 0.4824, 0.5059,  ..., 0.4510, 0.2588, 0.1059],\n",
       "          [0.4549, 0.4745, 0.5059,  ..., 0.4549, 0.2667, 0.1059]],\n",
       "\n",
       "         [[0.3059, 0.4039, 0.4157,  ..., 0.5882, 0.5843, 0.8431],\n",
       "          [0.2863, 0.3490, 0.2941,  ..., 0.3725, 0.3216, 0.5216],\n",
       "          [0.2863, 0.3725, 0.2784,  ..., 0.3176, 0.2431, 0.2902],\n",
       "          ...,\n",
       "          [0.5020, 0.5176, 0.5020,  ..., 0.4196, 0.2353, 0.1059],\n",
       "          [0.4745, 0.4863, 0.4941,  ..., 0.4549, 0.2549, 0.1059],\n",
       "          [0.4706, 0.4784, 0.5020,  ..., 0.4510, 0.2549, 0.1020]],\n",
       "\n",
       "         [[0.2941, 0.4431, 0.4471,  ..., 0.5961, 0.6039, 0.8745],\n",
       "          [0.2745, 0.3804, 0.3176,  ..., 0.3490, 0.3137, 0.5294],\n",
       "          [0.2745, 0.3922, 0.2902,  ..., 0.2745, 0.2118, 0.2706],\n",
       "          ...,\n",
       "          [0.3765, 0.4000, 0.3922,  ..., 0.3451, 0.2157, 0.1098],\n",
       "          [0.3569, 0.3725, 0.3882,  ..., 0.3686, 0.2314, 0.1059],\n",
       "          [0.3529, 0.3686, 0.3961,  ..., 0.3686, 0.2275, 0.1020]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2221a82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0202, -0.1045, -0.0300,  ..., -0.0988, -0.3745, -0.1823],\n",
       "          [-0.0394,  0.0039, -0.0760,  ..., -0.1092, -0.0894, -0.0464],\n",
       "          [ 0.0695,  0.0468, -0.0259,  ..., -0.0219, -0.0361, -0.1044],\n",
       "          ...,\n",
       "          [-0.0519, -0.0913,  0.0129,  ..., -0.1006, -0.1024, -0.1740],\n",
       "          [-0.0485, -0.1100,  0.0042,  ..., -0.0741, -0.0532, -0.1300],\n",
       "          [-0.0783, -0.1298, -0.0687,  ..., -0.0541, -0.0476, -0.1475]],\n",
       "\n",
       "         [[ 0.2131,  0.2673,  0.3952,  ...,  0.3206,  0.2571,  0.3463],\n",
       "          [ 0.1800,  0.1600,  0.1847,  ...,  0.2684,  0.1805,  0.1569],\n",
       "          [ 0.1249,  0.1527,  0.1621,  ...,  0.2292,  0.2173,  0.2119],\n",
       "          ...,\n",
       "          [ 0.2243,  0.2630,  0.1739,  ...,  0.2378,  0.2373,  0.1576],\n",
       "          [ 0.2171,  0.1917,  0.1826,  ...,  0.2284,  0.2200,  0.1457],\n",
       "          [ 0.2292,  0.2096,  0.2355,  ...,  0.2133,  0.2065,  0.1290]],\n",
       "\n",
       "         [[-0.0165,  0.0415,  0.0923,  ..., -0.0759, -0.1321,  0.1253],\n",
       "          [ 0.0247, -0.0124, -0.0133,  ...,  0.0579, -0.1140,  0.0196],\n",
       "          [ 0.0422,  0.0170,  0.0253,  ...,  0.0097, -0.0597, -0.0055],\n",
       "          ...,\n",
       "          [-0.0485,  0.0862,  0.0254,  ..., -0.0300, -0.0342, -0.1687],\n",
       "          [-0.0048, -0.0372,  0.0147,  ..., -0.0303, -0.0597, -0.1229],\n",
       "          [-0.0374, -0.0234,  0.0162,  ..., -0.0164, -0.0274, -0.1390]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1694, -0.1645, -0.2404,  ..., -0.4103, -0.4106, -0.2891],\n",
       "          [-0.1764, -0.1679, -0.1752,  ..., -0.2501, -0.2661, -0.1908],\n",
       "          [-0.2979, -0.2614, -0.2837,  ..., -0.3312, -0.3008, -0.3260],\n",
       "          ...,\n",
       "          [-0.2652, -0.2947, -0.1519,  ..., -0.2803, -0.2798, -0.2771],\n",
       "          [-0.2476, -0.2915, -0.2010,  ..., -0.2760, -0.2674, -0.2330],\n",
       "          [-0.2768, -0.2761, -0.2745,  ..., -0.2585, -0.2608, -0.2329]],\n",
       "\n",
       "         [[ 0.0891,  0.1886,  0.1712,  ...,  0.1097,  0.2200,  0.1955],\n",
       "          [ 0.1231,  0.1019,  0.1177,  ...,  0.1113,  0.0155,  0.1025],\n",
       "          [-0.0439, -0.0112,  0.0390,  ...,  0.1490,  0.1900,  0.1637],\n",
       "          ...,\n",
       "          [ 0.1537,  0.1861,  0.1930,  ...,  0.1562,  0.1663,  0.1099],\n",
       "          [ 0.1580,  0.1056,  0.1273,  ...,  0.1423,  0.1266,  0.0889],\n",
       "          [ 0.1521,  0.1758,  0.1689,  ...,  0.0984,  0.1126,  0.0720]],\n",
       "\n",
       "         [[-0.0701, -0.0985, -0.1588,  ...,  0.0180, -0.0139, -0.2165],\n",
       "          [-0.0885, -0.0641, -0.0702,  ..., -0.1353, -0.2739, -0.1109],\n",
       "          [-0.0649, -0.0187,  0.0019,  ..., -0.1564, -0.1462, -0.1163],\n",
       "          ...,\n",
       "          [-0.0840, -0.0980, -0.0651,  ..., -0.0873, -0.0844, -0.0435],\n",
       "          [-0.0381, -0.0930, -0.0884,  ..., -0.0848, -0.0781, -0.0728],\n",
       "          [-0.0881, -0.0717, -0.1173,  ..., -0.0878, -0.0726, -0.0592]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### applying convolution\n",
    "x = projection(img_tensor)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cb60eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 8, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15a2520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 64])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.flatten(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88e1d60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.flatten(2).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a665ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after applying conv2D, torch.Size([1, 128, 8, 8])\n",
      "after flattening, torch.Size([1, 128, 64])\n",
      "after transpose torch.Size([1, 64, 128])\n",
      "Output shape: torch.Size([1, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "img_tensor = img.unsqueeze(0)  # Add batch dimension: for one image, the shape will be (1, 3, 32, 32), we are faking the batch size just because the model demands a 4D tensor as the input\n",
    "\n",
    "patch_embed = PatchEmbedding(patch_size=4, emb_size=128)\n",
    "with torch.no_grad():\n",
    "    patch_vectors = patch_embed(img_tensor)\n",
    "\n",
    "print(\"Output shape:\", patch_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bef83d",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "### ❓ Why is this needed?\n",
    "Transformers don’t “see” structure in sequences — they treat them as a bag of vectors. So if we feed in 64 patches, it doesn't know:\n",
    "\n",
    "Which patch is top-left?\n",
    "\n",
    "Which one is center?\n",
    "\n",
    "Which one is bottom-right?\n",
    "\n",
    "➡️ We solve this by adding positional information to each patch vector.\n",
    "\n",
    "Transformers don’t know anything about order or position in sequences unless we tell them. Unlike CNNs, which use kernels that scan spatially across pixels, Transformers treat inputs as just a set of tokens.\n",
    "\n",
    "In ViT:\n",
    "We give the Transformer a list of 64 patch vectors.\n",
    "But... it has no clue which patch came from where on the image. 😵\n",
    "\n",
    "So we need to inject position awareness using positional embeddings.\n",
    "\n",
    "### ✅ It’s just a tensor added to each patch vector:\n",
    "patch_embedding:    (1, 64, 128) → 64 patches, each 128-dim\n",
    "positional_encoding:(1, 64, 128) → 64 positional vectors\n",
    "positioned = patch_embedding + positional_encoding\n",
    "\n",
    "So the final input to the Transformer is:\n",
    "(1, 64, 128) — where each patch vector now includes position info\n",
    "\n",
    "### 🧠 Two Ways to Do This\n",
    "Method\tDescription\tCommon in\n",
    "- Fixed Sinusoidal\tUses sine/cosine functions\tNLP Transformers (e.g., BERT)\n",
    "- ✅ Learnable\tPositional embeddings are learned during training\tViT, modern vision models\n",
    "\n",
    "We’ll focus on the learnable version, as used in Vision Transformers.\n",
    "self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, emb_size)) , num_patches + 1 is to include 'cls_token'.\n",
    "\n",
    "| Patch Index | Patch Embedding (128D)   | Positional Embedding (128D) | Final Input to Transformer (128D) |\n",
    "| ----------- | ----------------------- | -------------------------- | -------------------------------- |\n",
    "| Patch 0     | `[e₀₀, e₀₁, ..., e₀127]` | `[p₀₀, p₀₁, ..., p₀127]`    | `e₀ + p₀`                        |\n",
    "| Patch 1     | `[e₁₀, e₁₁, ..., e₁127]` | `[p₁₀, p₁₁, ..., p₁127]`    | `e₁ + p₁`                        |\n",
    "| ...         | ...                     | ...                        | ...                              |\n",
    "| Patch 63    | ...                     | ...                        | `e₆₃ + p₆₃`                      |\n",
    "\n",
    "\n",
    "This way:\n",
    "\n",
    "Even if two patches have identical pixel values (same eᵢ)\n",
    "\n",
    "Their final representation will be different because of pᵢ\n",
    "\n",
    "✅ That’s how we encode spatial awareness into a Transformer.\n",
    "\n",
    "\n",
    "### CLS TOKEN\n",
    "It’s a special trainable vector that is prepended to the sequence of patch embeddings before feeding into the Transformer.\n",
    "\n",
    "Originally introduced in BERT (NLP model), it’s reused in ViT.\n",
    "\n",
    "Transformers process entire sequences, and you typically get one output per token.\n",
    "But in classification, you want one output for the entire image.\n",
    "\n",
    "So instead of:\n",
    "\n",
    "Averaging the patch outputs (like in CNN global pooling),\n",
    "\n",
    "Or building a separate head,\n",
    "\n",
    "✅ You just add a [CLS] token, and let the model learn to treat it as a summary collector.\n",
    "\n",
    "✅ Summary Role of [CLS] Token\n",
    "Input: Added to start of patch sequence\n",
    "\n",
    "Transformer: Attends to all patches in every layer\n",
    "\n",
    "Output: Final hidden state of [CLS] is used for classification\n",
    "\n",
    "Think of [CLS] as a learnable sponge that absorbs global image information through attention.\n",
    "\n",
    "🔬 How It Works in Practice\n",
    "\n",
    "🔢 Suppose:\n",
    "Patch embedding produces 64 tokens of 128 dims each → shape: (B, 64, 128)\n",
    "\n",
    "You prepend 1 [CLS] token → now shape: (B, 65, 128)\n",
    "\n",
    "So:\n",
    "\n",
    "x.shape after patch embedding = (B, 64, 128)\n",
    "\n",
    "Add [CLS]: becomes (B, 65, 128)\n",
    "\n",
    "pos_embedding.shape: (1, 65, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47b500a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Output from the previous step - Patch Embedding \n",
    "patch_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8e54b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0281,  0.0488, -0.1671,  ...,  0.1449,  0.1038, -0.2975],\n",
       "         [ 0.0119,  0.0947,  0.0313,  ...,  0.1755, -0.0231, -0.4171],\n",
       "         [-0.0735,  0.2013, -0.1353,  ...,  0.2423, -0.0250, -0.5145],\n",
       "         ...,\n",
       "         [ 0.0921,  0.0644, -0.3029,  ...,  0.1410,  0.0883, -0.3464],\n",
       "         [ 0.0856,  0.0758, -0.3246,  ...,  0.1737,  0.0869, -0.3674],\n",
       "         [ 0.0298, -0.0794, -0.3328,  ..., -0.0320,  0.2554, -0.1896]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38558eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTInput(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_patches=64, emb_size=64, include_cls=True):    \n",
    "        super().__init__()\n",
    "        self.include_cls = include_cls\n",
    "        if include_cls:\n",
    "            # Create a trainable CLS token\n",
    "            self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))  # (1, 1, 64)\n",
    "        else:\n",
    "            self.cls_token = None\n",
    "        \n",
    "        # Positional embedding for all tokens (patches + CLS if present)\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, num_patches + int(include_cls), emb_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x shape: (B, 64, 64)        \n",
    "        B, N, E = x.shape\n",
    "        \n",
    "        if self.include_cls:\n",
    "            cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, E)\n",
    "            x = torch.cat([cls_tokens, x], dim=1)          # (B, 65, E)\n",
    "\n",
    "        x = x + self.pos_embedding[:, :x.size(1), :]       # Add positional encoding\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.5443, -1.2087, -0.8276,  0.5431,  0.6837,  0.6449, -0.3903,\n",
       "           1.6828,  1.4183,  1.3319,  2.6950, -0.9619,  1.3587, -0.2581,\n",
       "          -0.2381, -0.1279,  0.8174, -0.0683, -0.3495, -0.3837, -1.0224,\n",
       "           1.7470, -1.3680,  1.4968,  1.0419,  1.8361,  1.3865,  0.3257,\n",
       "          -0.3368,  1.5277, -1.4472,  0.6737,  1.1420, -0.2218, -1.5787,\n",
       "           0.3148, -0.5148, -0.8375, -0.6938,  0.5123, -0.1617, -0.6039,\n",
       "          -0.1356, -0.5148, -0.1932, -1.5606,  0.8449, -2.3375, -1.3724,\n",
       "           0.2222,  0.7883,  1.3188, -0.3839, -1.1409,  0.6007,  1.1602,\n",
       "          -0.9717, -0.2907,  0.0898,  0.1581,  0.4025,  0.4153, -0.5192,\n",
       "           0.6851,  2.1454, -0.1097, -1.2872,  1.1641, -0.7736,  1.2010,\n",
       "           0.4821, -2.3750,  0.5498, -1.0623,  0.7939, -0.9616,  0.7300,\n",
       "           0.0193,  0.1770,  0.6844, -1.2934, -0.5852, -0.7679,  0.4909,\n",
       "          -0.2089,  0.0039,  0.2492,  0.4179, -0.8954, -1.0040,  1.3773,\n",
       "           0.4326,  0.3358,  0.4265, -0.7622, -1.5604, -0.0716,  0.5139,\n",
       "          -0.1304,  0.6168, -0.0513, -0.3771, -2.1280,  1.9902, -0.1103,\n",
       "           0.6034, -1.5095, -2.0950,  0.2384,  0.8864,  0.0380, -0.5656,\n",
       "           1.0347,  0.5639, -2.0511,  0.0844,  0.3589, -0.0933, -1.2440,\n",
       "          -0.1617,  2.0943,  1.4670, -0.2284, -0.5596,  1.5421,  1.3926,\n",
       "           0.3727, -0.2670]]], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_token = nn.Parameter(torch.randn(1, 1, 128))\n",
    "cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "141c0622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f75e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c073e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 128])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patches = 64\n",
    "include_cls = True\n",
    "emb_size=128\n",
    "\n",
    "B, N, E = patch_vectors.shape\n",
    "cls_token = nn.Parameter(torch.randn(1, 1, 128))\n",
    "cls_tokens = cls_token.expand(B, -1, -1)\n",
    "patch_vectors_cls_added = torch.cat([cls_tokens, patch_vectors], dim=1)\n",
    "patch_vectors_cls_added.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b03fcd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  1.0369, -1.0193,  ...,  1.7842, -0.1007,  0.2384],\n",
       "         [ 0.0281,  0.0488, -0.1671,  ...,  0.1449,  0.1038, -0.2975],\n",
       "         [ 0.0119,  0.0947,  0.0313,  ...,  0.1755, -0.0231, -0.4171],\n",
       "         ...,\n",
       "         [ 0.0921,  0.0644, -0.3029,  ...,  0.1410,  0.0883, -0.3464],\n",
       "         [ 0.0856,  0.0758, -0.3246,  ...,  0.1737,  0.0869, -0.3674],\n",
       "         [ 0.0298, -0.0794, -0.3328,  ..., -0.0320,  0.2554, -0.1896]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_vectors_cls_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-0.3151, -1.0432, -0.0393,  ..., -0.0140, -1.2721, -1.7620],\n",
       "         [ 1.3543, -0.7176, -1.4389,  ...,  0.2655, -1.0941,  1.2384],\n",
       "         [ 2.3830, -1.8270,  0.2797,  ..., -0.5667,  0.1631, -0.5172],\n",
       "         ...,\n",
       "         [-0.0358,  1.3445, -0.1702,  ..., -0.8810,  0.1896, -1.4092],\n",
       "         [ 0.8369, -0.0627, -0.4133,  ..., -1.0886,  1.2613, -0.3744],\n",
       "         [-0.1815, -0.4302,  2.4264,  ...,  1.7539,  1.8274,  1.6226]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding = nn.Parameter(\n",
    "        torch.randn(1, num_patches + int(include_cls), emb_size)\n",
    "    )\n",
    "pos_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6fec7285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 128])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee8af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-0.3151, -1.0432, -0.0393,  ..., -0.0140, -1.2721, -1.7620],\n",
       "         [ 1.3543, -0.7176, -1.4389,  ...,  0.2655, -1.0941,  1.2384],\n",
       "         [ 2.3830, -1.8270,  0.2797,  ..., -0.5667,  0.1631, -0.5172],\n",
       "         ...,\n",
       "         [-0.0358,  1.3445, -0.1702,  ..., -0.8810,  0.1896, -1.4092],\n",
       "         [ 0.8369, -0.0627, -0.4133,  ..., -1.0886,  1.2613, -0.3744],\n",
       "         [-0.1815, -0.4302,  2.4264,  ...,  1.7539,  1.8274,  1.6226]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding[:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f238dde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_vectors_cls_added.size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "93fbd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding = nn.Parameter(\n",
    "    torch.randn(1, num_patches + int(include_cls), emb_size)\n",
    "    )\n",
    "tokens_with_cls = patch_vectors_cls_added + pos_embedding[:, :patch_vectors_cls_added.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be3b441f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6886,  0.0145, -1.1406,  ...,  0.9967, -0.1300,  0.2415],\n",
       "         [ 3.2012,  0.8436, -0.5777,  ..., -0.4499,  1.4338,  1.1878],\n",
       "         [ 0.7825, -0.2857,  0.4328,  ...,  0.9572,  1.8117, -1.2131],\n",
       "         ...,\n",
       "         [ 0.4234, -1.3387,  1.3495,  ...,  1.0028,  1.1487, -2.0295],\n",
       "         [-0.2278, -0.4514,  0.0765,  ...,  1.4625,  1.1042, -1.1956],\n",
       "         [ 0.9122,  0.0558, -1.8295,  ...,  1.7379, -0.2798,  0.5286]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_with_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a37771c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape with CLS: torch.Size([1, 65, 128])\n"
     ]
    }
   ],
   "source": [
    "vit_input = ViTInput(num_patches=64, emb_size=128, include_cls=True)\n",
    "tokens_with_cls = vit_input(patch_vectors)\n",
    "print(\"Final shape with CLS:\", tokens_with_cls.shape)  # (1, 65, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc9a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4908b745",
   "metadata": {},
   "source": [
    "# Transformer Encoder Block\n",
    "💡 Each Transformer block contains:\n",
    "Multi-Head Self-Attention (MHSA)\n",
    "\n",
    "Add & LayerNorm\n",
    "\n",
    "Feedforward MLP\n",
    "\n",
    "Add & LayerNorm\n",
    "\n",
    "There are multiple such blocks like 6 or 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b3849ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 128])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_with_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, emb_size=64, num_heads=4, mlp_ratio=4.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_size)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=emb_size, num_heads=num_heads, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(emb_size)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_size, int(emb_size * mlp_ratio)),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(int(emb_size * mlp_ratio), emb_size),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multi-head Self-Attention with Residual\n",
    "        x = x + self.attn(self.ln1(x), self.ln1(x), self.ln1(x))[0]\n",
    "        # Feedforward MLP with Residual\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b56d1bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape from Transformer Encoder Block: torch.Size([1, 65, 128])\n"
     ]
    }
   ],
   "source": [
    "encoder_block = TransformerEncoderBlock(emb_size=128, num_heads=4)\n",
    "# Pass input tokens through Transformer Encoder Block\n",
    "with torch.no_grad():  # Disable gradients for now (inference/debug)\n",
    "    output_tokens = encoder_block(tokens_with_cls)\n",
    "\n",
    "print(\"Output shape from Transformer Encoder Block:\", output_tokens.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fcf4893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 128])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c190822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3190, -3.1615,  0.4054,  ...,  1.9170, -2.6788, -0.7548],\n",
       "         [-0.8424,  0.2914, -1.7966,  ...,  1.3436, -0.3509,  0.9910],\n",
       "         [ 0.5700, -0.3865, -0.0163,  ...,  0.1557, -2.4257, -0.8484],\n",
       "         ...,\n",
       "         [ 2.4268, -0.2838,  0.4983,  ...,  1.5367, -0.2998,  1.0226],\n",
       "         [-1.2276,  2.2232,  0.0259,  ..., -0.9833, -0.1569, -0.0787],\n",
       "         [-0.4944, -1.6785,  0.2877,  ...,  0.5237, -1.2672,  0.2341]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de0e8a",
   "metadata": {},
   "source": [
    "# Extracting CLS Token for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b573b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, emb_size=64, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(emb_size)\n",
    "        self.fc = nn.Linear(emb_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_token = x[:, 0]       # Extract only the [CLS] token: shape (B, E)\n",
    "        cls_token = self.norm(cls_token)\n",
    "        return self.fc(cls_token)  # Final shape: (B, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2f7e3df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "head = ClassificationHead(emb_size=128, num_classes=10)\n",
    "with torch.no_grad():\n",
    "    logits = head(output_tokens)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fee240e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5009, -0.0218,  0.1075,  0.9305, -0.6950, -0.1372,  0.2581, -0.5056,\n",
       "          0.2392,  0.5679]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c24b3",
   "metadata": {},
   "source": [
    "# Complete Class Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cfe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# config numbers\n",
    "class ViTConfig:\n",
    "    def __init__(self,\n",
    "                 img_size=32,\n",
    "                 patch_size=4,\n",
    "                 in_channels=3,\n",
    "                 emb_size=64,\n",
    "                 depth=6,\n",
    "                 num_heads=4,\n",
    "                 mlp_ratio=4.0,\n",
    "                 num_classes=10,\n",
    "                 dropout=0.1):\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = in_channels\n",
    "        self.emb_size = emb_size\n",
    "        self.depth = depth\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "\n",
    "# Patch Embedding\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, patch_size, emb_size, img_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        self.projection = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)        # (B, emb_size, H/patch, W/patch)\n",
    "        x = x.flatten(2)              # (B, emb_size, N)\n",
    "        x = x.transpose(1, 2)         # (B, N, emb_size)\n",
    "        return x                      # Shape: (B, N, E)\n",
    "\n",
    "# Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, emb_size, num_heads, mlp_ratio, dropout):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_size)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=emb_size, num_heads=num_heads, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(emb_size)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_size, int(emb_size * mlp_ratio)),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(int(emb_size * mlp_ratio), emb_size),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x), self.ln1(x), self.ln1(x))[0]\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# Vit Test Model\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        cfg = config[\"model\"]\n",
    "        \n",
    "        self.CHANNEL = cfg[\"in_channels\"]\n",
    "        self.PATCH = cfg[\"patch_size\"]\n",
    "        self.EMBEDDING = cfg[\"emb_size\"]\n",
    "        self.IMAGE = cfg[\"img_size\"]\n",
    "        self.NUM_HEADS = cfg[\"num_heads\"]\n",
    "        self.MLP_RATIO = cfg[\"mlp_ratio\"]\n",
    "        self.DROPOUT = cfg[\"dropout\"]\n",
    "        self.NUM_CLASS = cfg[\"num_classes\"]\n",
    "        self.DEPTH = cfg[\"depth\"]\n",
    "\n",
    "        self.patch_embed = PatchEmbedding(\n",
    "            in_channels=self.CHANNEL,\n",
    "            patch_size=self.PATCH,\n",
    "            emb_size=self.EMBEDDING,\n",
    "            img_size=self.IMAGE\n",
    "        )\n",
    "\n",
    "        self.n_patches = (self.IMAGE// self.PATCH) ** 2\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.EMBEDDING))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.n_patches + 1, self.EMBEDDING))\n",
    "\n",
    "        self.encoder = nn.Sequential(*[\n",
    "            TransformerEncoderBlock(\n",
    "                emb_size=self.EMBEDDING,\n",
    "                num_heads=self.NUM_HEADS,\n",
    "                mlp_ratio=self.MLP_RATIO,\n",
    "                dropout=self.DROPOUT\n",
    "            ) for _ in range(self.DEPTH)\n",
    "        ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(self.EMBEDDING)\n",
    "        self.head = nn.Linear(self.EMBEDDING, self.NUM_CLASS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.patch_embed(x)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embedding[:, :x.size(1), :]\n",
    "        x = self.encoder(x)\n",
    "        cls_out = self.norm(x[:, 0])\n",
    "        return self.head(cls_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c14041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "CURR_PATH = f'/home/wd/Documents/work_stuff/ViT_REPLICATION'\n",
    "sys.path.append(os.path.abspath(CURR_PATH))  # Adds root directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10947e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config_loader import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2762f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': {'path': '/home/wd/Documents/work_stuff/ViT_REPLICATION'},\n",
       " 'data': {'dataset': 'CIFAR10',\n",
       "  'data_path': '/home/wd/Documents/work_stuff/ViT_REPLICATION/data/CIFAR10',\n",
       "  'batch_size': 64,\n",
       "  'num_workers': 4,\n",
       "  'img_size': 32},\n",
       " 'model': {'img_size': 32,\n",
       "  'patch_size': 4,\n",
       "  'in_channels': 3,\n",
       "  'emb_size': 128,\n",
       "  'depth': 4,\n",
       "  'num_heads': 4,\n",
       "  'mlp_ratio': 4.0,\n",
       "  'num_classes': 10,\n",
       "  'dropout': 0.1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading config file for CIFAR10\n",
    "config = load_config(f\"{CURR_PATH}/config/vit_test_config.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c23e9b",
   "metadata": {},
   "source": [
    "### building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "Output shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "model = VisionTransformer(config)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "print(dummy_input.shape)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # torch.Size([1, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "da1fddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3500,  0.0149,  0.6415,  0.1470,  0.7542, -0.4720, -0.0573, -0.1689,\n",
       "         -1.3927,  0.0716]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846576ec",
   "metadata": {},
   "source": [
    "### loading Data CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea01113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 782, Test batches: 157\n"
     ]
    }
   ],
   "source": [
    "from utils.data_loader import DatasetLoader\n",
    "\n",
    "# loading config file for CIFAR10\n",
    "data_cfg = config[\"data\"]\n",
    "DATASET = data_cfg[\"dataset\"]\n",
    "DATA_DIR = data_cfg[\"data_path\"]\n",
    "BATCH = data_cfg[\"batch_size\"]\n",
    "NUM_WORKERS = data_cfg[\"num_workers\"]\n",
    "IMAGE = data_cfg[\"img_size\"]\n",
    "\n",
    "# loading data\n",
    "loader = DatasetLoader(dataset_name=DATASET,\n",
    "                        data_dir=DATA_DIR,\n",
    "                        batch_size=BATCH,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        img_size=IMAGE)\n",
    "train_loader, test_loader = loader.get_loaders()\n",
    "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db63014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73df3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes present in the batch of 64 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 9, 6, 7, 5, 2, 0, 2, 4, 8, 2, 5, 7, 0, 2, 4, 5, 1, 7, 6, 8, 0, 5,\n",
       "        2, 5, 0, 8, 8, 1, 5, 7, 0, 5, 5, 2, 5, 7, 0, 3, 5, 2, 8, 0, 8, 5, 1, 4,\n",
       "        3, 5, 8, 7, 3, 1, 6, 2, 1, 8, 6, 2, 5, 8, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('classes present in the batch of 64 images')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257d01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8291a530",
   "metadata": {},
   "source": [
    "# Loading Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecfd6f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 1,\n",
       " 'model_state_dict': OrderedDict([('cls_token',\n",
       "               tensor([[[ 0.7843, -0.9314,  1.4624, -0.3946,  0.3004, -1.0770, -0.6100,\n",
       "                          0.2140,  1.1614,  1.0500,  0.4242, -0.1744,  1.1325, -0.7487,\n",
       "                         -0.4229,  0.5353, -0.3249, -1.0730, -1.1117,  0.4287,  0.7610,\n",
       "                          0.3982, -0.8442,  0.0527, -1.3347, -0.5689, -0.5368,  0.5753,\n",
       "                          0.0610, -0.7938, -0.5675, -1.8793, -0.4842, -0.3414, -0.7753,\n",
       "                         -0.5656, -0.2630, -1.3508,  1.0814, -0.7862, -0.3518, -0.5205,\n",
       "                          0.8435, -1.2750, -0.7247,  0.2069, -1.1504,  1.0995, -0.0320,\n",
       "                          0.0257,  0.9588,  2.2577,  0.7921, -0.4660,  0.0535, -0.2370,\n",
       "                         -1.8077,  1.6081,  0.7494, -1.2345,  0.1506,  0.4924,  1.2985,\n",
       "                          0.9896]]], device='cuda:0')),\n",
       "              ('pos_embedding',\n",
       "               tensor([[[-0.5099,  2.8199,  0.6473,  ..., -0.1389,  0.6447,  1.0771],\n",
       "                        [ 2.0270,  1.5828,  0.9012,  ...,  0.9606,  1.4607,  1.4900],\n",
       "                        [ 0.3907, -0.0489,  0.2650,  ..., -0.2611,  0.2964, -0.7568],\n",
       "                        ...,\n",
       "                        [-1.2063,  0.0563,  0.3625,  ...,  0.5352, -1.3254, -0.6392],\n",
       "                        [-0.6357,  0.7665,  0.1359,  ...,  2.0052,  0.9068,  1.0385],\n",
       "                        [ 0.5113,  0.6038,  0.0938,  ..., -0.3061, -1.8617, -0.1395]]],\n",
       "                      device='cuda:0')),\n",
       "              ('patch_embed.projection.weight',\n",
       "               tensor([[[[-0.0599,  0.1375,  0.1278, -0.1038],\n",
       "                         [ 0.0703, -0.0113, -0.0941,  0.0059],\n",
       "                         [ 0.1174, -0.0047,  0.0098, -0.0121],\n",
       "                         [-0.0938,  0.1363,  0.0246,  0.0384]],\n",
       "               \n",
       "                        [[ 0.0061,  0.0209, -0.0448,  0.0307],\n",
       "                         [-0.0156,  0.0230,  0.1134, -0.0914],\n",
       "                         [-0.0310, -0.1393, -0.1192,  0.0399],\n",
       "                         [-0.0029,  0.0029,  0.0376,  0.0672]],\n",
       "               \n",
       "                        [[ 0.1185, -0.1026,  0.0138,  0.1349],\n",
       "                         [-0.0526,  0.0041,  0.0483,  0.0642],\n",
       "                         [-0.0186,  0.1304, -0.0083, -0.1164],\n",
       "                         [-0.1371, -0.0333, -0.0836, -0.0837]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0246, -0.1117, -0.1204,  0.0297],\n",
       "                         [ 0.0973,  0.1354, -0.0275,  0.0166],\n",
       "                         [ 0.1537,  0.0227, -0.0331, -0.0437],\n",
       "                         [ 0.0937,  0.0415, -0.0462, -0.0737]],\n",
       "               \n",
       "                        [[-0.1172, -0.1376, -0.0570, -0.1359],\n",
       "                         [ 0.0563, -0.0604, -0.1446, -0.1218],\n",
       "                         [ 0.0258, -0.0149,  0.1294, -0.1066],\n",
       "                         [ 0.1001, -0.0234,  0.0335,  0.0393]],\n",
       "               \n",
       "                        [[-0.0492, -0.0371,  0.0765, -0.1011],\n",
       "                         [ 0.0046, -0.1238,  0.0516, -0.0153],\n",
       "                         [-0.0088,  0.1256,  0.0595,  0.0700],\n",
       "                         [ 0.1179,  0.0107, -0.0921,  0.0449]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1271, -0.0802,  0.0942, -0.0552],\n",
       "                         [-0.1567,  0.0548, -0.1624, -0.1277],\n",
       "                         [ 0.0087,  0.0519, -0.0981, -0.0471],\n",
       "                         [-0.1078, -0.0491, -0.0015,  0.0262]],\n",
       "               \n",
       "                        [[ 0.1489,  0.1437, -0.0008, -0.0354],\n",
       "                         [-0.0064,  0.0083,  0.1228,  0.0935],\n",
       "                         [ 0.1399,  0.0287,  0.1124,  0.1276],\n",
       "                         [ 0.0016, -0.0769,  0.1237,  0.0627]],\n",
       "               \n",
       "                        [[-0.0133, -0.0155, -0.0254, -0.0438],\n",
       "                         [ 0.1176,  0.0257,  0.0960,  0.0908],\n",
       "                         [-0.0134, -0.1206,  0.0455,  0.0284],\n",
       "                         [ 0.0958, -0.1139, -0.0381,  0.1403]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0222, -0.0052, -0.0549,  0.0815],\n",
       "                         [ 0.1361,  0.1177, -0.0373, -0.0449],\n",
       "                         [ 0.0136, -0.0235,  0.0979, -0.0980],\n",
       "                         [-0.1206, -0.0731,  0.0380,  0.0804]],\n",
       "               \n",
       "                        [[ 0.0410, -0.1218, -0.1332,  0.0057],\n",
       "                         [ 0.0419, -0.0430,  0.1003,  0.0643],\n",
       "                         [-0.0545,  0.0292, -0.1002,  0.0382],\n",
       "                         [-0.0825, -0.0417,  0.0318, -0.0865]],\n",
       "               \n",
       "                        [[ 0.1293, -0.0111,  0.0230,  0.1037],\n",
       "                         [ 0.0395,  0.0125, -0.0988,  0.0707],\n",
       "                         [ 0.1365, -0.0910,  0.0297, -0.0662],\n",
       "                         [ 0.0054,  0.1443, -0.0689, -0.0021]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1080,  0.0875,  0.0321,  0.1242],\n",
       "                         [-0.0199,  0.1230, -0.0276,  0.0491],\n",
       "                         [-0.1114,  0.0871,  0.0429, -0.1327],\n",
       "                         [ 0.0683, -0.1191, -0.0092,  0.0107]],\n",
       "               \n",
       "                        [[ 0.0151, -0.0955,  0.1323,  0.0503],\n",
       "                         [-0.0879, -0.0998,  0.0881,  0.0479],\n",
       "                         [-0.1110, -0.1095,  0.0740,  0.1093],\n",
       "                         [ 0.1182,  0.0431, -0.0641, -0.0676]],\n",
       "               \n",
       "                        [[-0.1508, -0.0129,  0.1249, -0.0144],\n",
       "                         [-0.0634,  0.1298,  0.1056,  0.0846],\n",
       "                         [-0.1002, -0.0741, -0.0542, -0.0133],\n",
       "                         [ 0.1339, -0.0305,  0.0692, -0.0417]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1275,  0.0491, -0.0642,  0.1132],\n",
       "                         [-0.0012,  0.0187, -0.0410,  0.0973],\n",
       "                         [-0.0304, -0.1077, -0.0741,  0.0660],\n",
       "                         [-0.0034, -0.0064, -0.0666, -0.1023]],\n",
       "               \n",
       "                        [[-0.1270, -0.0884, -0.0472, -0.0908],\n",
       "                         [-0.1165,  0.0836, -0.0352,  0.0639],\n",
       "                         [ 0.1135, -0.0979,  0.0485,  0.0130],\n",
       "                         [ 0.0003, -0.0235, -0.0584,  0.0625]],\n",
       "               \n",
       "                        [[-0.0636, -0.0817,  0.0223, -0.1412],\n",
       "                         [-0.0193, -0.0657, -0.1222, -0.1203],\n",
       "                         [ 0.0734,  0.1247,  0.0011, -0.0152],\n",
       "                         [-0.0842, -0.0347, -0.0857,  0.0569]]]], device='cuda:0')),\n",
       "              ('patch_embed.projection.bias',\n",
       "               tensor([-0.0556, -0.1079, -0.0653, -0.0570, -0.0833,  0.0967,  0.0250,  0.0006,\n",
       "                        0.0618,  0.1323,  0.0426,  0.0067, -0.0194,  0.1104,  0.1007,  0.0474,\n",
       "                       -0.0799,  0.1301,  0.1270, -0.1224, -0.0694,  0.0469, -0.0441,  0.1051,\n",
       "                        0.0970,  0.0960,  0.0988, -0.0515, -0.0054,  0.0652, -0.0329,  0.0696,\n",
       "                        0.0532,  0.0170, -0.0150, -0.1287,  0.0709, -0.0321, -0.1248, -0.0614,\n",
       "                       -0.0084,  0.0832, -0.0977,  0.0218,  0.0518,  0.0038,  0.1331, -0.1220,\n",
       "                        0.0131, -0.0213, -0.0153,  0.0876,  0.0264, -0.1076, -0.1305, -0.0980,\n",
       "                       -0.0402, -0.0983, -0.1350, -0.0826, -0.0211, -0.1304,  0.0409,  0.1097],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.0.ln1.weight',\n",
       "               tensor([1.0018, 1.0255, 1.0198, 1.0126, 1.0095, 1.0041, 0.9974, 1.0414, 1.0343,\n",
       "                       1.0075, 1.0384, 0.9993, 1.0069, 1.0201, 1.0127, 1.0213, 1.0272, 1.0267,\n",
       "                       1.0021, 1.0317, 1.0064, 1.0106, 1.0163, 1.0286, 1.0261, 1.0190, 1.0144,\n",
       "                       1.0291, 1.0181, 1.0069, 1.0086, 1.0169, 1.0092, 1.0107, 1.0348, 1.0278,\n",
       "                       1.0229, 0.9974, 1.0189, 1.0215, 1.0232, 1.0207, 1.0005, 1.0252, 1.0101,\n",
       "                       1.0093, 1.0264, 1.0304, 1.0073, 1.0346, 1.0286, 1.0151, 1.0395, 1.0344,\n",
       "                       1.0160, 1.0091, 1.0056, 1.0265, 1.0144, 1.0267, 1.0147, 1.0207, 1.0203,\n",
       "                       1.0192], device='cuda:0')),\n",
       "              ('encoder.0.ln1.bias',\n",
       "               tensor([ 3.2952e-03,  1.1233e-03, -3.5383e-03, -7.0587e-04,  3.7258e-03,\n",
       "                       -7.9192e-03, -1.0243e-02,  8.0930e-03,  4.8275e-03, -3.3685e-03,\n",
       "                       -3.4677e-03,  2.5697e-03,  2.1841e-03, -5.0806e-04, -2.6097e-03,\n",
       "                        7.6849e-03, -4.0581e-03, -1.1743e-02,  4.3296e-03, -1.3937e-02,\n",
       "                       -1.7432e-03, -3.4084e-03, -5.3105e-03,  2.5752e-03,  1.7026e-03,\n",
       "                        4.5539e-03, -5.9002e-03,  6.2242e-03, -2.1218e-03,  1.7086e-03,\n",
       "                       -3.7592e-03,  2.4256e-03, -1.5966e-03, -8.7631e-04, -6.1433e-03,\n",
       "                        3.1164e-03, -4.7870e-03, -4.9933e-03, -7.2943e-03,  7.0447e-03,\n",
       "                        4.9080e-03,  1.0449e-02,  3.6309e-03,  8.3825e-03,  2.2014e-03,\n",
       "                        2.1709e-04,  3.3436e-03,  4.3273e-03, -4.2445e-03, -5.7132e-03,\n",
       "                        1.9832e-03,  1.8319e-03,  8.7068e-03,  8.6960e-05,  5.7522e-04,\n",
       "                        3.6682e-04, -1.1416e-03, -4.9083e-03, -3.1936e-03,  3.9098e-03,\n",
       "                        1.5550e-03, -2.4517e-03,  1.2800e-02, -9.8116e-03], device='cuda:0')),\n",
       "              ('encoder.0.attn.in_proj_weight',\n",
       "               tensor([[ 0.0584,  0.1051,  0.1256,  ..., -0.0881,  0.0264, -0.1018],\n",
       "                       [-0.0965,  0.0460,  0.0313,  ...,  0.0578,  0.0844, -0.0212],\n",
       "                       [ 0.0905, -0.0921,  0.1224,  ..., -0.0069, -0.0688, -0.0086],\n",
       "                       ...,\n",
       "                       [-0.0335, -0.1022, -0.0032,  ...,  0.0740,  0.0258, -0.0590],\n",
       "                       [-0.1259, -0.1106,  0.0411,  ...,  0.0911, -0.1152,  0.0224],\n",
       "                       [ 0.0128, -0.0407, -0.0616,  ...,  0.1412, -0.0193,  0.0596]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.0.attn.in_proj_bias',\n",
       "               tensor([ 5.4872e-03, -9.2826e-03, -2.0550e-02,  1.1411e-02,  7.7183e-03,\n",
       "                       -2.8371e-03, -9.7403e-03, -5.5113e-03,  3.0332e-03, -2.9087e-03,\n",
       "                       -4.4001e-04, -2.1757e-02,  7.2134e-03,  6.7391e-04, -1.0171e-02,\n",
       "                       -1.0174e-02, -2.0369e-02, -2.6559e-02, -5.6832e-03, -6.0572e-03,\n",
       "                        1.0124e-02, -6.5014e-03,  6.8953e-03,  7.7545e-04, -1.6541e-03,\n",
       "                       -4.5678e-04, -1.9372e-03,  1.5200e-02,  5.3983e-03,  7.8757e-03,\n",
       "                        4.8546e-03,  1.7597e-02, -1.4305e-02, -2.3487e-02,  1.4058e-02,\n",
       "                       -3.4159e-02,  1.7872e-02,  9.0658e-03, -2.3720e-02, -1.5405e-02,\n",
       "                        6.9479e-03, -1.2122e-02, -1.5586e-02, -1.3047e-02,  1.4881e-02,\n",
       "                       -2.6248e-02, -1.0531e-02, -1.7454e-02,  2.2021e-02, -1.7196e-02,\n",
       "                       -1.0790e-02,  3.9865e-04, -9.8141e-03,  6.6451e-03,  9.5282e-03,\n",
       "                       -2.6798e-02, -6.9472e-03, -1.6511e-03,  7.1609e-03, -1.7417e-02,\n",
       "                        1.5688e-02,  2.8028e-03,  2.4257e-02,  1.5307e-02, -2.3575e-05,\n",
       "                        1.4062e-05, -2.5842e-05, -3.7761e-05, -3.5333e-05, -8.0068e-06,\n",
       "                       -7.1718e-06,  4.6888e-05, -4.5306e-05, -4.9150e-05,  6.4216e-06,\n",
       "                        2.3685e-05,  9.8878e-05,  1.1198e-05,  3.3977e-05,  2.8355e-06,\n",
       "                        7.5811e-05,  1.4429e-04,  5.4601e-05,  3.4791e-05, -8.4539e-07,\n",
       "                        2.3421e-05, -2.2164e-05, -6.9185e-06, -4.2471e-05, -5.9706e-06,\n",
       "                       -2.1254e-05, -2.9129e-05,  1.4962e-06, -2.9078e-06, -8.9625e-05,\n",
       "                       -8.9356e-05,  1.2903e-04, -8.7159e-06, -8.5604e-06,  2.3966e-05,\n",
       "                       -9.3830e-07, -3.3827e-07, -4.4159e-07,  3.6715e-05, -2.5363e-05,\n",
       "                        3.0979e-05,  3.7626e-05,  1.6962e-04, -1.9528e-05,  2.0855e-04,\n",
       "                        8.1757e-05,  1.3634e-04, -1.4241e-04, -1.0051e-05,  1.2949e-06,\n",
       "                        1.3630e-05, -5.1892e-05,  3.9774e-05, -2.7004e-05,  2.2239e-05,\n",
       "                       -1.2417e-05, -6.7172e-05, -5.5926e-05, -3.9715e-05, -1.3838e-04,\n",
       "                        2.0840e-06, -6.4981e-05,  2.5658e-06,  3.3552e-03,  8.5573e-03,\n",
       "                        9.5117e-03,  3.9619e-03, -6.5071e-03, -5.3775e-03, -2.1297e-03,\n",
       "                        1.9081e-03,  3.8009e-03,  1.6059e-03,  7.1631e-04,  7.1989e-03,\n",
       "                        5.5715e-03, -1.3668e-03,  1.5350e-03, -1.8381e-03, -5.8205e-04,\n",
       "                       -2.2145e-03,  7.0035e-03, -2.3175e-04,  3.1216e-03, -6.6290e-03,\n",
       "                       -7.1115e-03,  4.9719e-03, -6.2426e-03,  1.1225e-03,  1.2744e-03,\n",
       "                       -2.5342e-03, -9.0951e-04,  3.4005e-03,  3.5272e-03, -8.4078e-04,\n",
       "                        1.0566e-02, -1.6472e-03, -4.1590e-03,  5.2160e-03, -4.0954e-03,\n",
       "                        5.6853e-03, -2.7783e-03, -7.3147e-03, -4.0854e-03, -1.9265e-03,\n",
       "                        1.6128e-03,  2.1278e-03, -3.9473e-03, -9.8568e-04, -1.5177e-03,\n",
       "                       -5.7380e-03,  3.5265e-03, -1.0034e-03,  3.7891e-03,  6.8901e-04,\n",
       "                        5.5162e-03, -6.9010e-03,  4.0729e-03, -4.7709e-03, -7.6007e-03,\n",
       "                        8.7880e-03, -4.2332e-03, -4.0928e-03, -8.7477e-04, -5.2384e-05,\n",
       "                        2.4553e-03,  2.4397e-03], device='cuda:0')),\n",
       "              ('encoder.0.attn.out_proj.weight',\n",
       "               tensor([[ 0.0479,  0.0329, -0.0844,  ...,  0.1453,  0.0229, -0.0283],\n",
       "                       [ 0.0642, -0.0740, -0.0197,  ..., -0.0080,  0.0422,  0.0861],\n",
       "                       [ 0.0229, -0.0876, -0.0680,  ..., -0.0535,  0.0670,  0.0632],\n",
       "                       ...,\n",
       "                       [-0.0106,  0.0137,  0.0031,  ...,  0.1202, -0.0688,  0.1071],\n",
       "                       [ 0.0488, -0.0550,  0.0673,  ...,  0.0138, -0.1113, -0.1009],\n",
       "                       [-0.1160,  0.0649, -0.0770,  ..., -0.0212, -0.0301,  0.0027]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.0.attn.out_proj.bias',\n",
       "               tensor([-3.5489e-03, -2.5494e-04, -5.0151e-03, -5.8046e-03, -4.2924e-03,\n",
       "                        5.2078e-03,  6.1286e-03,  3.7120e-03, -7.5471e-03,  3.9285e-03,\n",
       "                       -3.6370e-03,  4.0080e-03, -2.2025e-03, -2.7322e-03,  2.6004e-03,\n",
       "                       -5.2344e-03,  1.2920e-03,  7.8100e-03, -3.7317e-03,  1.2536e-04,\n",
       "                       -3.1591e-03, -7.1657e-03, -4.6016e-03,  6.3195e-03,  7.2930e-03,\n",
       "                        3.1069e-04,  1.1973e-03, -4.4354e-03,  6.0243e-03, -1.9662e-03,\n",
       "                        3.6849e-03,  1.4894e-02,  2.0957e-03, -4.5654e-03,  1.3167e-03,\n",
       "                       -4.5265e-03,  2.7377e-03,  7.3029e-03,  6.0668e-03,  5.6263e-03,\n",
       "                        5.1354e-03, -8.6262e-04, -6.1455e-04,  3.6958e-03, -4.1787e-04,\n",
       "                       -4.8415e-03, -9.8278e-05, -6.7223e-03, -4.9863e-04, -7.1557e-04,\n",
       "                        4.4556e-06, -1.2093e-02, -3.4075e-03,  1.8575e-03,  5.2945e-03,\n",
       "                        2.9922e-03, -3.0108e-03, -1.0442e-03,  3.8961e-03,  7.7594e-03,\n",
       "                       -4.1200e-03, -3.3304e-03, -2.0025e-03, -7.9241e-03], device='cuda:0')),\n",
       "              ('encoder.0.ln2.weight',\n",
       "               tensor([1.0057, 1.0020, 1.0075, 1.0007, 0.9974, 1.0041, 0.9984, 1.0299, 0.9924,\n",
       "                       1.0032, 1.0030, 1.0030, 1.0015, 1.0046, 1.0253, 1.0032, 1.0142, 0.9959,\n",
       "                       0.9998, 1.0040, 1.0015, 0.9990, 1.0289, 1.0012, 0.9977, 0.9936, 1.0047,\n",
       "                       1.0060, 1.0025, 1.0110, 0.9992, 0.9950, 1.0137, 0.9955, 1.0427, 1.0024,\n",
       "                       1.0157, 0.9994, 0.9998, 1.0005, 1.0042, 0.9935, 1.0138, 0.9922, 1.0052,\n",
       "                       0.9992, 0.9977, 0.9991, 1.0090, 0.9890, 1.0017, 0.9973, 1.0214, 1.0005,\n",
       "                       1.0212, 1.0133, 1.0137, 0.9911, 1.0010, 0.9992, 1.0002, 0.9858, 0.9948,\n",
       "                       1.0022], device='cuda:0')),\n",
       "              ('encoder.0.ln2.bias',\n",
       "               tensor([-5.7888e-03,  2.6264e-03,  4.6246e-03, -9.3876e-03, -1.4022e-03,\n",
       "                       -4.8845e-03,  3.3013e-03, -2.2897e-03, -1.1805e-02,  5.6574e-04,\n",
       "                        1.9129e-03,  6.8838e-03, -1.5864e-03, -4.0998e-03, -9.9938e-05,\n",
       "                        1.3514e-03,  2.4483e-03,  2.4731e-03,  3.4395e-04, -5.1654e-04,\n",
       "                        4.6903e-03, -1.2617e-03, -6.5589e-03, -2.1187e-03,  3.2098e-03,\n",
       "                        3.9340e-05, -1.4607e-03,  4.7405e-03, -8.3671e-04, -5.2408e-03,\n",
       "                        6.0103e-03,  8.8067e-03, -9.0512e-03, -3.5055e-03,  1.9988e-03,\n",
       "                       -4.2098e-03, -1.8967e-03,  7.7099e-04,  1.8707e-03, -3.1409e-04,\n",
       "                        4.0793e-03, -2.3799e-03,  6.8460e-03,  3.7117e-03, -3.1574e-03,\n",
       "                        3.7355e-04,  3.6040e-03, -2.1971e-03, -1.5457e-03,  7.4347e-03,\n",
       "                       -5.9798e-03, -3.5588e-03,  1.2101e-03,  3.2208e-04,  3.8218e-03,\n",
       "                       -4.1969e-03, -1.4090e-03, -9.2124e-03, -1.4612e-04, -1.5148e-03,\n",
       "                       -2.3221e-03, -6.2679e-05, -6.9266e-03,  1.7854e-03], device='cuda:0')),\n",
       "              ('encoder.0.mlp.0.weight',\n",
       "               tensor([[-0.0637,  0.1167,  0.0877,  ..., -0.0242, -0.0410,  0.0562],\n",
       "                       [ 0.0187,  0.1028,  0.1216,  ..., -0.0102, -0.0681,  0.0608],\n",
       "                       [ 0.0086,  0.1024,  0.0110,  ...,  0.0349, -0.1170,  0.0829],\n",
       "                       ...,\n",
       "                       [-0.1121, -0.0190, -0.0566,  ..., -0.1006, -0.0071,  0.0257],\n",
       "                       [-0.0363, -0.0632, -0.0286,  ..., -0.0843, -0.0452, -0.0953],\n",
       "                       [ 0.0392,  0.0064,  0.0957,  ..., -0.0035, -0.0337,  0.0262]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.0.mlp.0.bias',\n",
       "               tensor([-0.0574, -0.0296,  0.1096,  0.0220, -0.0591,  0.1152,  0.0227, -0.0032,\n",
       "                        0.0889, -0.0326, -0.0074,  0.0269,  0.0139, -0.0004,  0.1065, -0.1035,\n",
       "                       -0.0726,  0.0452,  0.1177,  0.1071,  0.0562,  0.0462,  0.0948,  0.1134,\n",
       "                       -0.0846, -0.0331, -0.0452,  0.1043,  0.0199, -0.0319, -0.0919,  0.0062,\n",
       "                        0.0058, -0.0987, -0.1140, -0.0440,  0.1168,  0.0898, -0.0088,  0.0786,\n",
       "                       -0.0658,  0.0430,  0.0970, -0.0795, -0.0678,  0.0904,  0.0497, -0.0577,\n",
       "                        0.0683,  0.0942,  0.0764, -0.0817, -0.0673, -0.0475, -0.0885,  0.0330,\n",
       "                        0.0597,  0.0854,  0.1135, -0.0802,  0.1276,  0.0639,  0.0530, -0.0553,\n",
       "                        0.0468,  0.0528,  0.1127, -0.0519, -0.1010,  0.0106, -0.0597, -0.0454,\n",
       "                        0.0911, -0.0971,  0.0092, -0.0128,  0.0191,  0.0415,  0.0596, -0.0583,\n",
       "                       -0.1207, -0.0957, -0.0532,  0.1015,  0.0099, -0.0602, -0.0230,  0.0989,\n",
       "                        0.1032,  0.0293, -0.0436, -0.0570,  0.1171, -0.0846, -0.0018,  0.1198,\n",
       "                        0.0804,  0.0694, -0.0632,  0.0193,  0.0307,  0.0677,  0.0723, -0.0744,\n",
       "                        0.0730,  0.0649,  0.0186, -0.0075,  0.0539, -0.0563, -0.1082, -0.1107,\n",
       "                       -0.0281,  0.0538, -0.0652, -0.0788,  0.0510,  0.0799, -0.0466, -0.0647,\n",
       "                        0.0109,  0.0216, -0.0276,  0.1180, -0.0265,  0.0724, -0.0369,  0.0598,\n",
       "                       -0.0748,  0.0173,  0.0791, -0.1228,  0.0113,  0.1211,  0.0563,  0.0808,\n",
       "                       -0.1056,  0.0820,  0.1065,  0.0339, -0.0473, -0.0818,  0.0783, -0.1258,\n",
       "                        0.0394, -0.0234,  0.0279,  0.0288,  0.0056,  0.0584,  0.0756,  0.1065,\n",
       "                        0.0707,  0.1212,  0.0814, -0.0653, -0.0109, -0.0831, -0.0305,  0.0759,\n",
       "                        0.0862, -0.0017, -0.1027,  0.0268,  0.0336, -0.0526,  0.0326,  0.0929,\n",
       "                        0.0575,  0.0043, -0.0454, -0.0892, -0.0890, -0.0554,  0.1192,  0.0487,\n",
       "                       -0.0384, -0.1008,  0.0269, -0.0586,  0.0262,  0.1098, -0.0595,  0.0631,\n",
       "                        0.0721, -0.0681,  0.0642, -0.0102,  0.0120,  0.0548, -0.0004, -0.0516],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.0.mlp.3.weight',\n",
       "               tensor([[-0.0067,  0.0623, -0.0344,  ...,  0.0029, -0.0031, -0.0224],\n",
       "                       [-0.0712, -0.0122, -0.0376,  ..., -0.0413, -0.0394,  0.0451],\n",
       "                       [-0.0695, -0.0213, -0.0442,  ...,  0.0670,  0.0548,  0.0016],\n",
       "                       ...,\n",
       "                       [ 0.0129, -0.0115, -0.0612,  ..., -0.0489, -0.0623, -0.0578],\n",
       "                       [-0.0183, -0.0460, -0.0703,  ..., -0.0058,  0.0170, -0.0674],\n",
       "                       [-0.0764, -0.0223,  0.0030,  ..., -0.0662,  0.0422, -0.0620]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.0.mlp.3.bias',\n",
       "               tensor([-0.0304, -0.0565,  0.0417,  0.0520, -0.0055,  0.0446, -0.0290, -0.0173,\n",
       "                       -0.0296, -0.0316, -0.0092,  0.0424, -0.0030, -0.0594, -0.0301, -0.0460,\n",
       "                       -0.0476, -0.0223, -0.0525,  0.0068,  0.0005, -0.0341,  0.0489, -0.0429,\n",
       "                        0.0371,  0.0203, -0.0078, -0.0282, -0.0606,  0.0136,  0.0583,  0.0307,\n",
       "                       -0.0158,  0.0181,  0.0194,  0.0668,  0.0676, -0.0052, -0.0566, -0.0570,\n",
       "                       -0.0506, -0.0496, -0.0485, -0.0272,  0.0307,  0.0523,  0.0278, -0.0023,\n",
       "                       -0.0460, -0.0554,  0.0515,  0.0142, -0.0622,  0.0111, -0.0288, -0.0551,\n",
       "                        0.0496, -0.0231,  0.0212,  0.0562,  0.0211,  0.0400,  0.0400, -0.0415],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.ln1.weight',\n",
       "               tensor([1.0035, 1.0318, 1.0324, 1.0141, 1.0068, 0.9968, 1.0196, 1.0203, 1.0090,\n",
       "                       1.0231, 1.0294, 1.0200, 1.0087, 1.0489, 1.0235, 1.0038, 1.0238, 1.0108,\n",
       "                       1.0231, 1.0166, 1.0027, 0.9988, 1.0084, 1.0339, 1.0203, 1.0009, 1.0080,\n",
       "                       1.0331, 1.0074, 1.0209, 1.0130, 1.0115, 1.0352, 1.0184, 1.0247, 1.0211,\n",
       "                       1.0084, 1.0131, 1.0192, 1.0069, 1.0244, 1.0167, 1.0068, 1.0154, 1.0098,\n",
       "                       1.0255, 1.0235, 1.0172, 1.0312, 1.0260, 1.0122, 1.0131, 1.0317, 1.0169,\n",
       "                       1.0079, 1.0148, 1.0111, 1.0229, 0.9978, 1.0312, 1.0179, 1.0089, 1.0049,\n",
       "                       1.0002], device='cuda:0')),\n",
       "              ('encoder.1.ln1.bias',\n",
       "               tensor([ 0.0003,  0.0072,  0.0059, -0.0020, -0.0090, -0.0056, -0.0027,  0.0027,\n",
       "                       -0.0049,  0.0040,  0.0044,  0.0034, -0.0067,  0.0017,  0.0009, -0.0010,\n",
       "                        0.0006,  0.0032, -0.0030, -0.0001,  0.0073, -0.0031, -0.0022,  0.0002,\n",
       "                       -0.0087, -0.0096,  0.0004,  0.0035, -0.0053,  0.0006, -0.0062, -0.0063,\n",
       "                        0.0023,  0.0065, -0.0057,  0.0073,  0.0030,  0.0034, -0.0015,  0.0025,\n",
       "                        0.0048,  0.0002,  0.0048,  0.0029,  0.0030,  0.0015,  0.0013, -0.0029,\n",
       "                        0.0008, -0.0059,  0.0025, -0.0014, -0.0014,  0.0013,  0.0044,  0.0021,\n",
       "                       -0.0025, -0.0016,  0.0053, -0.0011,  0.0022, -0.0042, -0.0014, -0.0012],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.attn.in_proj_weight',\n",
       "               tensor([[ 0.1412, -0.0930,  0.0799,  ...,  0.0581, -0.1376,  0.1276],\n",
       "                       [ 0.0607,  0.1513,  0.0703,  ..., -0.1315, -0.0667, -0.1508],\n",
       "                       [ 0.1476,  0.0539,  0.1406,  ...,  0.0685, -0.1428, -0.0654],\n",
       "                       ...,\n",
       "                       [ 0.0419,  0.0011,  0.1263,  ...,  0.0302, -0.1155,  0.0720],\n",
       "                       [-0.0739,  0.0152,  0.0695,  ..., -0.0413, -0.1330, -0.1165],\n",
       "                       [-0.1276,  0.0932,  0.0881,  ..., -0.0461, -0.0928,  0.0991]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.attn.in_proj_bias',\n",
       "               tensor([-1.6896e-02, -3.6860e-04, -1.0367e-03, -5.8058e-03, -2.4817e-03,\n",
       "                       -3.9347e-03,  1.2284e-02, -6.2928e-03,  1.4349e-02,  1.0049e-02,\n",
       "                        2.2338e-02,  1.5653e-02,  9.5556e-03, -2.2010e-03, -1.0283e-02,\n",
       "                       -6.5076e-03,  4.4146e-03,  2.0527e-03, -6.1439e-03, -3.0146e-03,\n",
       "                       -2.4786e-02, -1.9547e-03, -8.4727e-03,  3.9468e-03, -4.3892e-03,\n",
       "                       -5.6505e-04, -5.7848e-03,  5.0804e-04, -2.7970e-03,  2.0111e-02,\n",
       "                        1.4295e-02, -2.6079e-02, -1.2497e-02, -1.2915e-02,  3.6052e-03,\n",
       "                       -5.7170e-03, -2.5889e-02, -1.0074e-02, -3.4604e-05, -1.4673e-02,\n",
       "                        1.1680e-02, -1.4881e-03, -9.8249e-03, -2.0660e-02, -4.8396e-03,\n",
       "                        4.1199e-03,  1.3474e-03,  2.3669e-02, -1.4359e-03, -1.3776e-02,\n",
       "                        4.0552e-03, -2.0206e-02, -4.1858e-03,  3.4918e-03, -5.0606e-04,\n",
       "                        4.8519e-03, -1.0697e-02, -2.9390e-02, -4.7695e-03, -1.0654e-02,\n",
       "                       -1.4466e-03,  1.0889e-02, -1.7046e-03, -3.1312e-02,  5.4976e-06,\n",
       "                        1.8385e-05, -7.8292e-06, -1.2285e-05, -2.0318e-05,  8.3264e-06,\n",
       "                        1.8089e-05, -4.3012e-05, -2.8749e-06,  4.9070e-06,  8.1452e-05,\n",
       "                        1.9185e-06,  8.8245e-06,  3.8660e-07, -3.5633e-05, -5.2710e-05,\n",
       "                        8.9537e-08, -1.3678e-05, -4.5407e-06, -1.1379e-06, -7.1036e-05,\n",
       "                        1.8185e-06, -1.5738e-05, -1.0684e-06,  1.3861e-05, -2.8707e-06,\n",
       "                        5.9935e-06, -2.4874e-05, -6.3947e-06,  1.7181e-05,  1.5603e-05,\n",
       "                       -3.8511e-05, -4.3640e-05, -3.5826e-05,  1.4572e-05, -3.2616e-05,\n",
       "                       -8.3524e-05, -3.4017e-06,  6.3097e-06, -2.3348e-05,  6.9199e-05,\n",
       "                        2.5790e-05, -8.7603e-07, -3.8461e-05, -7.2088e-06, -3.3645e-05,\n",
       "                        1.1603e-05,  6.8345e-05, -2.4566e-05, -1.4700e-05,  3.0051e-05,\n",
       "                       -4.5153e-05,  2.4246e-05,  9.9700e-06, -5.1004e-05,  2.3126e-05,\n",
       "                       -3.8952e-05, -1.0013e-04,  2.0978e-05, -2.1958e-05,  1.2235e-06,\n",
       "                        3.6244e-05,  3.3917e-05, -6.3661e-05, -6.4869e-05, -4.1310e-04,\n",
       "                        1.6516e-02,  5.1273e-04, -2.7648e-04, -2.0078e-03, -2.0806e-03,\n",
       "                       -5.1199e-04, -1.2019e-04, -2.4356e-03,  2.6919e-03,  7.6331e-05,\n",
       "                       -4.6644e-03,  4.3809e-03, -5.9680e-03,  3.4486e-03, -2.8876e-03,\n",
       "                       -4.6657e-03, -1.4939e-03,  5.3377e-03,  5.2027e-03, -4.3318e-03,\n",
       "                        3.8954e-03,  1.4061e-03,  2.8196e-03,  2.7767e-03, -1.3530e-03,\n",
       "                        6.2323e-03,  2.0161e-04, -3.0068e-03, -2.1354e-04, -1.0503e-03,\n",
       "                       -1.2316e-04,  1.3818e-02,  3.5230e-03, -5.8808e-03,  8.9207e-04,\n",
       "                       -3.7264e-03,  4.0143e-03, -1.2032e-03,  1.1108e-03,  4.4949e-03,\n",
       "                       -3.6401e-03, -4.0012e-03, -7.9308e-03,  6.1795e-03,  3.1094e-03,\n",
       "                        6.5837e-03, -3.4807e-03,  2.0964e-03, -1.5865e-03,  5.8867e-03,\n",
       "                        3.4818e-03, -4.5531e-04,  7.1622e-03, -8.3477e-04, -1.3925e-03,\n",
       "                       -8.7249e-03,  3.2179e-03, -4.3281e-03,  2.4795e-03, -5.3932e-03,\n",
       "                       -3.7747e-04,  7.3420e-03], device='cuda:0')),\n",
       "              ('encoder.1.attn.out_proj.weight',\n",
       "               tensor([[-0.0720, -0.0430, -0.0539,  ...,  0.1105,  0.0944,  0.0143],\n",
       "                       [-0.0776,  0.0135,  0.0392,  ...,  0.1278, -0.0302, -0.0881],\n",
       "                       [ 0.1097, -0.1208, -0.0325,  ...,  0.0659, -0.0759, -0.0302],\n",
       "                       ...,\n",
       "                       [-0.0677,  0.0457,  0.0256,  ..., -0.0914, -0.0588,  0.1165],\n",
       "                       [-0.0005,  0.0068, -0.0254,  ..., -0.0639,  0.0421,  0.0736],\n",
       "                       [ 0.0720, -0.1279, -0.1318,  ..., -0.0592,  0.0142, -0.0470]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.attn.out_proj.bias',\n",
       "               tensor([-3.0562e-03, -2.5224e-03, -5.6040e-03, -5.0042e-03, -2.6300e-03,\n",
       "                        6.8841e-03,  6.1622e-03,  4.2917e-03, -3.7792e-03,  2.3528e-03,\n",
       "                       -5.0392e-03,  2.6223e-03,  6.6432e-04, -2.2510e-03,  2.3143e-03,\n",
       "                       -5.8814e-03,  1.3170e-03,  8.9109e-03, -6.4399e-04, -1.2350e-03,\n",
       "                       -4.6560e-03, -2.1512e-03,  7.0850e-04,  6.3218e-03,  7.8593e-03,\n",
       "                        3.1235e-03,  5.6329e-04, -5.7607e-03,  8.4391e-03, -2.0868e-03,\n",
       "                        3.4901e-03,  1.2498e-02,  1.3053e-03, -4.1446e-03,  2.9314e-03,\n",
       "                       -5.4742e-03,  1.1546e-03,  6.4127e-03,  4.6911e-03,  4.5548e-03,\n",
       "                        3.7982e-03, -8.6495e-04, -4.9889e-03,  1.3989e-03, -9.9154e-04,\n",
       "                       -5.1153e-03, -3.4679e-04, -6.6722e-03,  1.7397e-04, -7.9120e-04,\n",
       "                        1.8336e-03, -9.0781e-03, -4.3324e-03,  1.1506e-03,  3.9284e-03,\n",
       "                        4.7431e-03, -9.5501e-04,  7.5115e-05,  2.9532e-03,  6.8867e-03,\n",
       "                       -3.5645e-03, -3.4659e-03, -6.6823e-05, -6.7142e-03], device='cuda:0')),\n",
       "              ('encoder.1.ln2.weight',\n",
       "               tensor([1.0169, 0.9993, 0.9975, 0.9970, 1.0220, 1.0039, 0.9977, 1.0109, 1.0003,\n",
       "                       1.0200, 0.9960, 1.0097, 0.9989, 0.9969, 1.0058, 1.0000, 1.0163, 0.9996,\n",
       "                       1.0036, 1.0029, 1.0041, 0.9997, 0.9959, 0.9946, 1.0020, 1.0064, 1.0060,\n",
       "                       0.9957, 0.9988, 1.0180, 1.0052, 0.9976, 0.9985, 1.0006, 1.0409, 1.0040,\n",
       "                       1.0066, 0.9924, 1.0045, 1.0063, 1.0075, 1.0059, 1.0180, 1.0002, 1.0165,\n",
       "                       1.0053, 1.0060, 0.9973, 1.0053, 0.9948, 1.0042, 0.9995, 1.0214, 1.0132,\n",
       "                       1.0133, 1.0309, 1.0093, 1.0004, 1.0072, 0.9981, 1.0068, 0.9982, 1.0021,\n",
       "                       0.9962], device='cuda:0')),\n",
       "              ('encoder.1.ln2.bias',\n",
       "               tensor([-1.3320e-03, -1.7176e-03,  9.5363e-04,  3.4913e-05,  3.0570e-03,\n",
       "                       -2.7633e-03,  1.9389e-03,  5.1283e-04, -5.4129e-04, -3.7432e-03,\n",
       "                       -5.1673e-03, -2.8518e-03, -2.0500e-03, -1.4602e-03, -1.5319e-03,\n",
       "                        7.0282e-04, -1.0172e-03,  2.4846e-03, -3.1543e-03,  8.0508e-05,\n",
       "                        2.9518e-03, -1.3591e-03, -2.0041e-03,  4.9998e-03, -7.2822e-04,\n",
       "                       -3.8738e-03,  5.3022e-04, -2.3066e-03,  3.4415e-03,  3.4081e-04,\n",
       "                        1.9384e-03,  5.1730e-03,  2.6484e-03,  3.3071e-03,  1.6183e-03,\n",
       "                        3.9496e-03, -2.0979e-04,  7.8302e-03, -5.7583e-03, -4.5067e-03,\n",
       "                        3.0387e-03,  2.6429e-03, -9.9406e-04,  1.3848e-03, -1.8005e-03,\n",
       "                        4.6147e-03, -1.1062e-03, -7.3030e-03, -1.9582e-03,  4.8342e-03,\n",
       "                        4.3225e-03, -1.6132e-03,  8.6329e-04,  1.0911e-04, -4.2791e-04,\n",
       "                        3.0158e-03, -4.0792e-03, -1.9628e-03,  3.3177e-03,  1.5286e-03,\n",
       "                        2.7692e-03,  4.1253e-03, -4.1178e-04, -1.6028e-03], device='cuda:0')),\n",
       "              ('encoder.1.mlp.0.weight',\n",
       "               tensor([[ 0.1219, -0.0799, -0.0250,  ..., -0.1174,  0.0745,  0.0200],\n",
       "                       [-0.0137, -0.0126,  0.1095,  ..., -0.0694,  0.0673, -0.0274],\n",
       "                       [-0.0246, -0.0406, -0.1248,  ...,  0.0889, -0.0202,  0.1128],\n",
       "                       ...,\n",
       "                       [-0.0312, -0.0288,  0.0331,  ...,  0.0573, -0.1248, -0.0452],\n",
       "                       [-0.0008,  0.0881,  0.0449,  ...,  0.0625,  0.0788, -0.0897],\n",
       "                       [ 0.0469,  0.0531, -0.0248,  ..., -0.0542,  0.0802, -0.0597]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.mlp.0.bias',\n",
       "               tensor([ 0.0120,  0.0222, -0.1211, -0.0536,  0.0627,  0.0766,  0.0917,  0.1181,\n",
       "                       -0.0092,  0.0133, -0.1108, -0.0911,  0.0161,  0.0767, -0.0853, -0.1013,\n",
       "                       -0.1188,  0.0132, -0.0772, -0.1116,  0.0696,  0.1115,  0.0998, -0.0672,\n",
       "                       -0.0453, -0.0392, -0.0497, -0.1003, -0.0664,  0.1211,  0.0485, -0.0776,\n",
       "                       -0.0804, -0.0473,  0.0265,  0.0550,  0.0414,  0.0861,  0.0970,  0.0142,\n",
       "                        0.0878, -0.0848, -0.0924, -0.0016, -0.0101,  0.0999, -0.1034,  0.0486,\n",
       "                       -0.0760,  0.0427, -0.0973, -0.1020, -0.1055, -0.0745, -0.0503,  0.0374,\n",
       "                       -0.0198,  0.0060,  0.1156, -0.0772, -0.1097,  0.0582,  0.1111, -0.0169,\n",
       "                       -0.0549, -0.1044,  0.0111, -0.0787, -0.0353,  0.0943,  0.1176,  0.0296,\n",
       "                       -0.1055, -0.0931,  0.0597,  0.0023, -0.0741,  0.1156, -0.0070, -0.0160,\n",
       "                        0.0527, -0.0386,  0.0308,  0.0998,  0.0881,  0.1254, -0.0626, -0.0072,\n",
       "                        0.0589, -0.0693, -0.0105, -0.0851, -0.0497, -0.0356,  0.0498,  0.1132,\n",
       "                       -0.0137,  0.0707, -0.0576,  0.1081,  0.0765,  0.0767, -0.0180, -0.0475,\n",
       "                       -0.0033, -0.0934,  0.1145, -0.0095, -0.1132,  0.0996,  0.0857, -0.1087,\n",
       "                       -0.0835, -0.0706, -0.0576,  0.0945, -0.1242, -0.0446, -0.0909,  0.0899,\n",
       "                        0.1047, -0.1248, -0.0464, -0.0778, -0.0920,  0.0918,  0.0755, -0.0752,\n",
       "                       -0.1260, -0.0054, -0.1112,  0.0371, -0.0120, -0.1103,  0.0273,  0.0278,\n",
       "                        0.0872,  0.0913,  0.0312,  0.0246,  0.0256,  0.0922,  0.0217, -0.0546,\n",
       "                        0.0275, -0.0523,  0.0724,  0.0641,  0.0628,  0.0499, -0.0602, -0.0086,\n",
       "                        0.0373, -0.0049, -0.0406,  0.0274,  0.0112, -0.0585, -0.0628, -0.0682,\n",
       "                        0.0449,  0.0389,  0.0239,  0.1255,  0.0758,  0.0727, -0.0465, -0.0641,\n",
       "                       -0.1112, -0.0680,  0.0670, -0.0103,  0.1023,  0.0295,  0.1233,  0.0713,\n",
       "                        0.0327,  0.0744, -0.0579,  0.0288, -0.0455,  0.0143,  0.0974,  0.0872,\n",
       "                       -0.1029,  0.1237, -0.0387,  0.0985, -0.1091,  0.0195,  0.0353, -0.0566],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.mlp.3.weight',\n",
       "               tensor([[-0.0411,  0.0846,  0.0374,  ...,  0.0610,  0.0436, -0.0045],\n",
       "                       [-0.0423,  0.0193,  0.0576,  ...,  0.0239, -0.0620, -0.0087],\n",
       "                       [-0.0338, -0.0712,  0.0028,  ..., -0.0581, -0.0349, -0.0246],\n",
       "                       ...,\n",
       "                       [-0.0112,  0.0141, -0.0598,  ...,  0.0499, -0.0147, -0.0124],\n",
       "                       [ 0.0183, -0.0433,  0.0176,  ...,  0.0677,  0.0545,  0.0433],\n",
       "                       [ 0.0450,  0.0225,  0.0320,  ...,  0.0713,  0.0733, -0.0673]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.1.mlp.3.bias',\n",
       "               tensor([ 0.0082, -0.0372,  0.0161, -0.0013,  0.0137, -0.0329,  0.0178,  0.0153,\n",
       "                        0.0227, -0.0047, -0.0315,  0.0060, -0.0132,  0.0312, -0.0221, -0.0481,\n",
       "                        0.0548, -0.0541,  0.0332, -0.0532, -0.0245,  0.0455, -0.0143,  0.0108,\n",
       "                        0.0189, -0.0475,  0.0269,  0.0012,  0.0579,  0.0067,  0.0297,  0.0624,\n",
       "                        0.0719, -0.0598, -0.0430, -0.0603,  0.0473, -0.0239,  0.0177,  0.0403,\n",
       "                       -0.0193,  0.0328, -0.0306, -0.0327,  0.0201,  0.0545,  0.0131, -0.0668,\n",
       "                       -0.0684,  0.0007,  0.0201,  0.0042,  0.0428,  0.0597, -0.0470, -0.0571,\n",
       "                        0.0487, -0.0539,  0.0680, -0.0560, -0.0377,  0.0035,  0.0150, -0.0061],\n",
       "                      device='cuda:0')),\n",
       "              ('norm.weight',\n",
       "               tensor([1.0167, 1.0009, 0.9972, 1.0065, 1.0055, 1.0041, 0.9995, 1.0145, 1.0002,\n",
       "                       1.0253, 0.9984, 1.0124, 1.0026, 1.0042, 1.0058, 0.9945, 0.9985, 0.9956,\n",
       "                       1.0056, 1.0136, 0.9956, 1.0011, 0.9963, 0.9947, 0.9973, 1.0106, 1.0179,\n",
       "                       0.9980, 0.9951, 1.0060, 1.0026, 0.9964, 1.0082, 1.0014, 1.0245, 1.0130,\n",
       "                       1.0031, 0.9971, 0.9981, 0.9961, 1.0135, 1.0003, 1.0112, 1.0022, 1.0172,\n",
       "                       1.0019, 1.0019, 0.9984, 1.0017, 1.0048, 1.0118, 0.9991, 0.9943, 1.0098,\n",
       "                       1.0040, 0.9868, 1.0042, 1.0069, 1.0103, 0.9980, 1.0088, 0.9998, 1.0040,\n",
       "                       0.9976], device='cuda:0')),\n",
       "              ('norm.bias',\n",
       "               tensor([-1.5897e-03,  3.1293e-03, -4.6348e-03, -2.0468e-03, -6.5266e-04,\n",
       "                        4.1545e-03,  2.0461e-03,  5.2565e-03,  7.1511e-04,  2.4989e-03,\n",
       "                       -2.0496e-03,  2.7685e-03,  2.7366e-03, -4.3909e-03,  3.1336e-03,\n",
       "                       -3.4589e-03,  2.0816e-03,  4.5474e-03, -2.0677e-03, -9.3390e-05,\n",
       "                       -4.3365e-03,  1.9946e-03,  1.6167e-03,  4.6256e-03,  3.6680e-03,\n",
       "                        3.0307e-03,  4.4059e-03, -1.4403e-03,  5.7023e-03,  4.1353e-04,\n",
       "                        8.4939e-04,  5.7717e-03,  4.8814e-03, -3.0211e-03,  4.5674e-03,\n",
       "                       -3.6414e-03,  2.2052e-03,  3.8169e-03,  3.2011e-03,  4.7044e-03,\n",
       "                        6.1747e-03, -1.2563e-03, -1.3995e-03, -2.0273e-03,  1.2307e-03,\n",
       "                       -7.1127e-03, -1.4009e-03, -2.6628e-03, -1.2628e-03, -1.9382e-03,\n",
       "                        5.4965e-03, -1.1042e-04, -3.6246e-03,  5.6811e-04,  5.1639e-03,\n",
       "                        6.2472e-03,  2.9936e-03,  3.1637e-03,  4.5244e-03,  1.6499e-03,\n",
       "                       -2.1107e-03, -3.3931e-03,  4.1911e-03, -3.4541e-03], device='cuda:0')),\n",
       "              ('head.weight',\n",
       "               tensor([[-0.0010,  0.0626,  0.0097,  0.1217,  0.1151, -0.0618, -0.0303, -0.1047,\n",
       "                         0.1080, -0.0525, -0.0410,  0.1002, -0.0861,  0.0034, -0.1291,  0.0448,\n",
       "                         0.1347, -0.0091,  0.0883,  0.0686,  0.0140, -0.0139, -0.0635, -0.0853,\n",
       "                         0.0888, -0.1041, -0.0434,  0.0382,  0.1208,  0.0834,  0.1261, -0.0599,\n",
       "                         0.1197,  0.0357,  0.0156,  0.0876,  0.0028,  0.0346, -0.1046,  0.0478,\n",
       "                         0.0795, -0.0897,  0.0282,  0.0345,  0.0193, -0.1049,  0.0088,  0.1203,\n",
       "                        -0.0415,  0.0895,  0.0398,  0.1205, -0.0818, -0.0434, -0.1134,  0.1145,\n",
       "                         0.1192, -0.1283, -0.0015, -0.0180,  0.1308,  0.0318,  0.1175, -0.0292],\n",
       "                       [-0.1311,  0.0392,  0.0426, -0.0100, -0.0653, -0.0055,  0.0277, -0.0094,\n",
       "                         0.0480, -0.0883,  0.0181,  0.0772,  0.0814, -0.0800, -0.1028,  0.0042,\n",
       "                        -0.1150, -0.0043, -0.0008, -0.0885, -0.0821,  0.0853,  0.0587, -0.0932,\n",
       "                         0.0317,  0.1230, -0.1187,  0.0440, -0.0481,  0.1180, -0.0421, -0.0109,\n",
       "                        -0.0560,  0.0074, -0.0259,  0.0139, -0.1137,  0.1044,  0.0344,  0.0470,\n",
       "                         0.0674, -0.0988, -0.0311,  0.1150, -0.0068, -0.0724, -0.1144,  0.0084,\n",
       "                         0.0430, -0.0714,  0.0591, -0.0682, -0.1021,  0.0765,  0.0919,  0.0011,\n",
       "                         0.1165, -0.0037,  0.1120,  0.0510, -0.0312,  0.0825, -0.0843, -0.1059],\n",
       "                       [ 0.0898, -0.0721, -0.0781,  0.1175, -0.0469, -0.0240, -0.1226,  0.0813,\n",
       "                        -0.0872, -0.0412, -0.0452, -0.0418, -0.0576, -0.1141,  0.0292, -0.0823,\n",
       "                        -0.0962,  0.1027, -0.0287,  0.1002, -0.1117,  0.1126,  0.0403,  0.0730,\n",
       "                        -0.0433, -0.0454,  0.0648, -0.0334,  0.0552,  0.0166, -0.1134,  0.1014,\n",
       "                         0.0833,  0.0873,  0.0421,  0.0177,  0.0566,  0.0560, -0.0273,  0.0147,\n",
       "                         0.0936,  0.0328,  0.0860, -0.0453, -0.0377, -0.1047,  0.0177,  0.0197,\n",
       "                        -0.0603,  0.0227,  0.0382,  0.0837,  0.1035,  0.0848,  0.1357,  0.0408,\n",
       "                        -0.0373, -0.0381,  0.0374, -0.0212,  0.0952, -0.0602, -0.0051, -0.1144],\n",
       "                       [-0.0656, -0.1030,  0.0763, -0.1244,  0.0343,  0.0037, -0.0345,  0.0875,\n",
       "                         0.0854, -0.0075, -0.1110, -0.0036, -0.0204, -0.0524, -0.0056, -0.1138,\n",
       "                        -0.1199, -0.1037,  0.0104,  0.0990,  0.0767, -0.0723, -0.0147, -0.0739,\n",
       "                        -0.0849, -0.0668, -0.0049,  0.1009, -0.0383, -0.0800,  0.1106, -0.0482,\n",
       "                        -0.1063,  0.1147,  0.1272, -0.1027,  0.0284, -0.0002, -0.0931,  0.0325,\n",
       "                         0.0779,  0.0646,  0.0656,  0.0496,  0.0024,  0.0837, -0.0305,  0.0152,\n",
       "                        -0.0087,  0.0890, -0.0930, -0.1166,  0.0624,  0.0649,  0.0826,  0.0433,\n",
       "                         0.0365,  0.0327,  0.0136, -0.0549, -0.1142,  0.0302, -0.1075,  0.0182],\n",
       "                       [ 0.1092,  0.0919, -0.0276,  0.0294, -0.0453,  0.0202, -0.0900, -0.1006,\n",
       "                         0.0430, -0.0818,  0.0070, -0.0298,  0.1228,  0.0670, -0.0905,  0.0309,\n",
       "                         0.0548, -0.0312, -0.0732,  0.0253, -0.0094,  0.0971,  0.0647,  0.0815,\n",
       "                        -0.1077, -0.0040,  0.1067,  0.0311, -0.0962,  0.1441, -0.1283,  0.1116,\n",
       "                         0.0883, -0.1249,  0.0083, -0.1291,  0.0025, -0.0727, -0.1080,  0.0920,\n",
       "                         0.0541, -0.1232,  0.1067, -0.1227,  0.0138, -0.1174, -0.0952, -0.1278,\n",
       "                         0.1130,  0.0449, -0.0472,  0.0719,  0.0157, -0.1283,  0.0010,  0.0769,\n",
       "                        -0.0796, -0.0824, -0.0076, -0.0186,  0.0125,  0.0886, -0.0520, -0.0257],\n",
       "                       [-0.1088, -0.0041, -0.0883, -0.0209, -0.0856,  0.0432, -0.0025,  0.0046,\n",
       "                        -0.0802,  0.0587,  0.0560, -0.1280,  0.0656, -0.0127,  0.0167, -0.1205,\n",
       "                        -0.1045,  0.0415, -0.0837, -0.0730, -0.1110,  0.1065,  0.1094,  0.0226,\n",
       "                         0.0146, -0.0190, -0.0364, -0.1163, -0.1000,  0.0159, -0.0891,  0.0351,\n",
       "                        -0.1041, -0.0655, -0.0239,  0.0750,  0.0129,  0.0993, -0.0922,  0.0334,\n",
       "                        -0.1034, -0.0856,  0.0813,  0.0583,  0.0469,  0.0811,  0.1084, -0.0247,\n",
       "                        -0.1020, -0.0986, -0.1051, -0.0516, -0.0963,  0.0141, -0.0561, -0.0120,\n",
       "                        -0.0065,  0.1244, -0.0615, -0.0216,  0.1125, -0.0957,  0.1234, -0.0615],\n",
       "                       [ 0.1317, -0.1225,  0.0964,  0.0482,  0.1166,  0.0042, -0.1021,  0.0636,\n",
       "                         0.0998,  0.1376,  0.0957, -0.1110, -0.0513,  0.0699,  0.0626,  0.1101,\n",
       "                        -0.0488, -0.0172, -0.0648,  0.0042,  0.0534,  0.0526, -0.0051, -0.1202,\n",
       "                        -0.0782,  0.0739, -0.0186, -0.1282,  0.0180,  0.0790, -0.0623,  0.0436,\n",
       "                        -0.0569,  0.0673, -0.0245, -0.0302, -0.0355, -0.0811, -0.1215, -0.0289,\n",
       "                         0.0904,  0.0094, -0.0247,  0.0967,  0.0967, -0.1063, -0.0552, -0.1221,\n",
       "                        -0.1033, -0.0229, -0.1042, -0.0014,  0.1162,  0.0173,  0.1158, -0.0505,\n",
       "                         0.0909, -0.0374,  0.1202,  0.1064,  0.1159,  0.0791,  0.0661, -0.1127],\n",
       "                       [-0.0430,  0.0012, -0.0843,  0.0567,  0.0710,  0.0298, -0.0297, -0.0894,\n",
       "                        -0.0905,  0.1189, -0.0438,  0.1068, -0.0932, -0.1003,  0.0896,  0.1161,\n",
       "                         0.0443,  0.1196, -0.0679, -0.0497, -0.0468, -0.0084, -0.0504, -0.0448,\n",
       "                         0.0221, -0.0185,  0.1185, -0.0601,  0.0129,  0.0486,  0.0730, -0.1207,\n",
       "                         0.0615, -0.1030,  0.1190, -0.0658, -0.0525, -0.0795, -0.0290, -0.0423,\n",
       "                         0.0837,  0.0137,  0.0669, -0.0906, -0.0957, -0.0634,  0.1089, -0.1043,\n",
       "                         0.0361, -0.0497, -0.0666,  0.0639,  0.1091, -0.0550, -0.0639, -0.0695,\n",
       "                        -0.1073, -0.0847,  0.0763, -0.0518, -0.1336, -0.1013,  0.0357, -0.0780],\n",
       "                       [ 0.0538, -0.0485,  0.1154,  0.1120, -0.0874, -0.0943, -0.0987, -0.0991,\n",
       "                        -0.0960, -0.1394, -0.0195, -0.0466, -0.0234,  0.0678, -0.1194,  0.0204,\n",
       "                        -0.1067, -0.0595,  0.0028,  0.0191,  0.0170,  0.0861,  0.0377, -0.1192,\n",
       "                        -0.1002, -0.0754, -0.0622,  0.0119, -0.1032,  0.0316, -0.0917, -0.0692,\n",
       "                        -0.0383,  0.0857, -0.0945,  0.0748, -0.0044, -0.0450, -0.0607, -0.0140,\n",
       "                        -0.1059, -0.0114,  0.0727,  0.0026, -0.0572,  0.0747,  0.0240,  0.0609,\n",
       "                         0.0265,  0.0351, -0.0680,  0.0268,  0.1017,  0.0651, -0.0204, -0.0456,\n",
       "                        -0.0689, -0.1287, -0.0842, -0.0282,  0.1069,  0.1229, -0.1307, -0.0600],\n",
       "                       [-0.0974, -0.0478,  0.1053,  0.0682, -0.0095, -0.1151, -0.0172, -0.0754,\n",
       "                        -0.0126, -0.0558, -0.1248,  0.1259,  0.0292,  0.0729,  0.0256, -0.0909,\n",
       "                         0.0457, -0.1181, -0.1194, -0.0757,  0.0850,  0.1080, -0.1195,  0.1123,\n",
       "                        -0.0485,  0.1265, -0.1006, -0.0835, -0.0033, -0.0406,  0.0765,  0.1112,\n",
       "                        -0.0637,  0.1039, -0.1049, -0.0632,  0.1411,  0.0932, -0.0985,  0.0837,\n",
       "                         0.0669,  0.1120, -0.0666, -0.1131,  0.0173,  0.0877, -0.0726, -0.1184,\n",
       "                         0.0294, -0.0418,  0.0379,  0.0122,  0.1097,  0.1000, -0.0110,  0.0375,\n",
       "                        -0.0472, -0.0006,  0.0834,  0.0660, -0.0757, -0.1074, -0.0256,  0.0400]],\n",
       "                      device='cuda:0')),\n",
       "              ('head.bias',\n",
       "               tensor([ 0.0532, -0.0403,  0.0911, -0.1180, -0.0722, -0.0565,  0.1019,  0.0037,\n",
       "                        0.1198,  0.0453], device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[[ 3.2022e-03, -1.0761e-03, -5.4423e-04, -2.3081e-04,  2.0452e-03,\n",
       "               1.2422e-03, -1.8756e-03,  4.5222e-03,  2.2110e-03,  3.0416e-03,\n",
       "               1.7429e-03, -1.7021e-03, -1.4557e-03, -1.5083e-03,  2.1669e-03,\n",
       "               6.8113e-04, -2.9396e-03,  1.9190e-04, -9.0510e-04,  7.8291e-04,\n",
       "              -2.1650e-03, -1.3312e-03, -1.0228e-03, -1.8788e-03, -2.0972e-03,\n",
       "               1.3505e-03,  1.3776e-03, -1.2563e-03,  1.5135e-03,  1.3923e-03,\n",
       "              -2.9759e-03, -1.9724e-04, -2.1255e-04,  2.1080e-04,  2.7674e-03,\n",
       "              -4.3403e-04, -2.7764e-03, -1.5112e-03,  3.1437e-04, -2.9416e-03,\n",
       "               1.6238e-03,  1.6924e-04, -9.0278e-04,  1.2573e-03,  2.6062e-03,\n",
       "              -4.6722e-03, -1.1981e-03, -1.5859e-03, -3.5295e-03, -1.1066e-03,\n",
       "              -6.9661e-04,  6.8608e-04,  1.1658e-03, -2.5344e-04,  4.0656e-03,\n",
       "              -3.7944e-03,  1.7426e-03,  3.2881e-04,  3.1411e-03,  6.6649e-05,\n",
       "               2.1957e-03,  8.6369e-04,  2.2728e-03, -2.1649e-03]]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[[4.6342e-05, 1.0641e-05, 4.0961e-05, 1.4210e-05, 1.2311e-05,\n",
       "              7.6654e-06, 1.0833e-05, 2.3742e-05, 1.4431e-05, 1.5563e-05,\n",
       "              1.3001e-05, 1.5450e-05, 1.0753e-05, 4.9635e-05, 2.5469e-05,\n",
       "              2.3705e-05, 1.8843e-05, 1.9648e-05, 1.0750e-05, 2.2239e-05,\n",
       "              2.4970e-05, 1.1461e-05, 1.1393e-05, 3.0738e-05, 8.3047e-06,\n",
       "              2.3546e-05, 1.7902e-05, 1.3766e-05, 1.1192e-05, 1.1499e-05,\n",
       "              2.4966e-05, 1.5452e-05, 1.4463e-05, 1.8532e-05, 3.4708e-05,\n",
       "              1.0508e-05, 1.1599e-05, 2.1468e-05, 8.5108e-06, 5.8796e-06,\n",
       "              2.9428e-05, 1.4862e-05, 1.0925e-05, 1.7236e-05, 5.6939e-06,\n",
       "              2.3335e-05, 1.6613e-05, 1.7047e-05, 1.2699e-05, 2.0012e-05,\n",
       "              1.5869e-05, 1.5712e-05, 2.2300e-05, 1.7016e-05, 1.4845e-05,\n",
       "              1.1576e-05, 1.2582e-05, 4.7721e-05, 1.7675e-05, 7.1520e-06,\n",
       "              3.2021e-05, 4.8711e-05, 2.8464e-05, 8.2517e-06]]], device='cuda:0')},\n",
       "   1: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[[ 3.2022e-03, -1.0761e-03, -5.4423e-04,  ...,  8.6369e-04,\n",
       "               2.2728e-03, -2.1649e-03],\n",
       "             [ 1.1460e-05,  1.1479e-06,  2.7501e-05,  ..., -1.9224e-05,\n",
       "              -2.5255e-06,  2.3309e-05],\n",
       "             [-3.7745e-07, -3.0879e-05,  4.2236e-05,  ..., -5.5623e-05,\n",
       "              -1.7659e-05,  1.1747e-05],\n",
       "             ...,\n",
       "             [ 5.6071e-06,  2.3363e-05, -1.8412e-05,  ..., -6.2461e-06,\n",
       "               2.2733e-05,  4.3307e-06],\n",
       "             [-1.0092e-05,  7.8008e-06, -9.6220e-06,  ..., -2.0301e-06,\n",
       "              -7.6416e-06,  4.3817e-06],\n",
       "             [ 1.4325e-05,  1.7604e-05, -6.4413e-06,  ..., -3.2334e-05,\n",
       "               1.7228e-05,  1.6000e-05]]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[[4.6342e-05, 1.0641e-05, 4.0961e-05,  ..., 4.8711e-05,\n",
       "              2.8464e-05, 8.2517e-06],\n",
       "             [8.0648e-10, 1.1960e-09, 6.3419e-10,  ..., 7.6705e-10,\n",
       "              5.2732e-10, 2.1247e-09],\n",
       "             [2.0545e-09, 3.2687e-09, 1.6101e-09,  ..., 2.8917e-09,\n",
       "              4.4120e-09, 3.9315e-09],\n",
       "             ...,\n",
       "             [1.7124e-09, 1.4590e-09, 7.8470e-10,  ..., 1.7787e-09,\n",
       "              1.2739e-09, 3.8294e-09],\n",
       "             [7.2286e-10, 1.1971e-09, 8.9495e-10,  ..., 5.3437e-10,\n",
       "              7.2554e-10, 2.9342e-09],\n",
       "             [9.2101e-10, 1.4426e-09, 9.0387e-10,  ..., 1.4759e-09,\n",
       "              7.1758e-10, 1.7099e-09]]], device='cuda:0')},\n",
       "   2: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[[[-2.8205e-03, -2.8803e-03, -2.5788e-03, -2.7348e-03],\n",
       "              [-2.8075e-03, -2.8562e-03, -2.5575e-03, -3.0435e-03],\n",
       "              [-2.9282e-03, -2.8382e-03, -2.5163e-03, -2.5750e-03],\n",
       "              [-2.8534e-03, -2.6918e-03, -2.4149e-03, -2.3536e-03]],\n",
       "    \n",
       "             [[-2.0388e-03, -2.1693e-03, -1.7827e-03, -2.1678e-03],\n",
       "              [-2.0527e-03, -1.9950e-03, -1.6974e-03, -2.2390e-03],\n",
       "              [-2.0113e-03, -1.8322e-03, -1.8024e-03, -1.6743e-03],\n",
       "              [-1.8169e-03, -1.8264e-03, -1.5595e-03, -1.4918e-03]],\n",
       "    \n",
       "             [[-2.5047e-03, -2.7286e-03, -2.3735e-03, -2.7790e-03],\n",
       "              [-2.6094e-03, -2.5903e-03, -2.5813e-03, -3.0202e-03],\n",
       "              [-2.6715e-03, -2.3664e-03, -2.4896e-03, -2.5698e-03],\n",
       "              [-2.4701e-03, -2.3681e-03, -2.2262e-03, -2.1108e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.8210e-03, -1.2804e-03, -1.2115e-03, -1.4946e-03],\n",
       "              [-2.6075e-03, -2.1605e-03, -1.9727e-03, -2.2592e-03],\n",
       "              [-3.2366e-03, -3.0405e-03, -2.5850e-03, -3.0145e-03],\n",
       "              [-3.8428e-03, -2.8625e-03, -3.0712e-03, -3.4004e-03]],\n",
       "    \n",
       "             [[ 3.3784e-05,  6.1160e-04,  7.6657e-04,  1.8288e-04],\n",
       "              [-5.8259e-04, -1.2012e-04,  1.9076e-06, -5.4364e-04],\n",
       "              [-1.6557e-03, -1.1086e-03, -1.0025e-03, -1.3705e-03],\n",
       "              [-2.1636e-03, -1.3505e-03, -1.4787e-03, -1.9952e-03]],\n",
       "    \n",
       "             [[-5.4382e-04, -1.7861e-04,  9.4600e-06, -5.3971e-04],\n",
       "              [-1.1381e-03, -8.9649e-04, -9.3955e-04, -1.3321e-03],\n",
       "              [-2.4212e-03, -1.9909e-03, -2.0385e-03, -2.3458e-03],\n",
       "              [-3.0739e-03, -2.5399e-03, -2.6121e-03, -3.0056e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.3226e-03,  2.1450e-03,  2.1361e-03,  2.3090e-03],\n",
       "              [ 2.0624e-03,  2.2689e-03,  2.2683e-03,  2.6142e-03],\n",
       "              [ 2.4524e-03,  2.8292e-03,  2.6418e-03,  3.1370e-03],\n",
       "              [ 2.8043e-03,  2.5434e-03,  2.6746e-03,  3.1172e-03]],\n",
       "    \n",
       "             [[ 6.6058e-04,  4.6908e-04,  4.8466e-04,  7.4170e-04],\n",
       "              [ 3.7130e-04,  4.3754e-04,  6.1459e-04,  9.6561e-04],\n",
       "              [ 1.1165e-03,  1.1770e-03,  1.1855e-03,  1.6224e-03],\n",
       "              [ 1.4201e-03,  1.2711e-03,  1.4022e-03,  1.8891e-03]],\n",
       "    \n",
       "             [[ 1.2565e-03,  1.0345e-03,  1.2677e-03,  1.5031e-03],\n",
       "              [ 1.3972e-03,  1.5907e-03,  1.8014e-03,  1.9749e-03],\n",
       "              [ 2.3992e-03,  2.3923e-03,  2.5535e-03,  2.6761e-03],\n",
       "              [ 2.6214e-03,  2.6331e-03,  2.7270e-03,  3.1002e-03]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-2.8460e-04, -7.3770e-05, -7.7547e-04, -4.1761e-04],\n",
       "              [-9.9949e-04, -8.0245e-04, -1.0735e-03, -1.1651e-03],\n",
       "              [-2.0096e-03, -1.9687e-03, -1.6600e-03, -2.0305e-03],\n",
       "              [-1.8624e-03, -1.8413e-03, -1.6427e-03, -2.0425e-03]],\n",
       "    \n",
       "             [[-1.1149e-04,  7.9578e-05, -5.1030e-04, -2.6810e-04],\n",
       "              [-5.0724e-04, -3.6041e-04, -7.2645e-04, -8.1864e-04],\n",
       "              [-1.3614e-03, -1.2659e-03, -9.4657e-04, -1.3453e-03],\n",
       "              [-1.0241e-03, -1.0750e-03, -7.6313e-04, -1.2972e-03]],\n",
       "    \n",
       "             [[-9.9968e-04, -7.1480e-04, -1.3317e-03, -1.1267e-03],\n",
       "              [-1.4664e-03, -1.2088e-03, -1.4625e-03, -1.6247e-03],\n",
       "              [-2.0409e-03, -2.0581e-03, -1.7855e-03, -2.0231e-03],\n",
       "              [-1.7577e-03, -1.7139e-03, -1.2656e-03, -1.8200e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.1503e-03, -6.3886e-04, -2.7269e-04, -2.3575e-04],\n",
       "              [-2.6482e-04, -3.3494e-04, -9.9935e-05, -2.7319e-04],\n",
       "              [-2.3279e-04, -5.9633e-04, -4.4872e-04, -8.5643e-05],\n",
       "              [-7.2522e-04, -8.7709e-04, -8.9961e-05,  2.3236e-04]],\n",
       "    \n",
       "             [[-1.0887e-03, -7.5220e-04, -5.2513e-04, -3.5026e-04],\n",
       "              [-2.6004e-04, -2.4900e-04, -3.8461e-05, -2.3307e-05],\n",
       "              [-1.3224e-04, -4.8487e-04, -3.4000e-04,  1.2492e-04],\n",
       "              [-7.4513e-04, -7.5613e-04, -2.0265e-04,  2.4202e-04]],\n",
       "    \n",
       "             [[-1.6071e-03, -1.3957e-03, -1.1856e-03, -1.0301e-03],\n",
       "              [-9.0456e-04, -8.8339e-04, -9.8443e-04, -6.9194e-04],\n",
       "              [-4.5644e-04, -8.3314e-04, -8.1687e-04, -4.0312e-04],\n",
       "              [-1.1520e-03, -1.0534e-03, -5.6149e-04, -2.6512e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.1366e-03, -9.3932e-04, -6.4535e-04, -1.0130e-03],\n",
       "              [-1.3666e-03, -1.0520e-03, -1.6013e-03, -1.5003e-03],\n",
       "              [-1.3452e-03, -9.8087e-04, -1.0635e-03, -1.4575e-03],\n",
       "              [-1.6958e-03, -7.2293e-04, -8.9669e-04, -1.3785e-03]],\n",
       "    \n",
       "             [[ 1.1991e-04,  4.4001e-04,  8.2244e-04,  1.1740e-04],\n",
       "              [-2.4407e-04,  2.0673e-04, -2.0006e-04, -3.0226e-04],\n",
       "              [-8.2107e-04, -5.5849e-05, -1.7449e-04, -4.0856e-04],\n",
       "              [-1.5568e-03, -2.5589e-04, -1.4009e-04, -6.7982e-04]],\n",
       "    \n",
       "             [[ 2.5867e-04,  7.5048e-04,  9.1766e-04,  5.9669e-04],\n",
       "              [-1.3734e-04,  1.2807e-04, -1.2021e-04, -2.2498e-04],\n",
       "              [-1.2165e-03, -3.9165e-04, -4.3586e-04, -5.8675e-04],\n",
       "              [-1.8438e-03, -9.0625e-04, -6.7972e-04, -1.0656e-03]]]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[[[4.5796e-06, 4.7714e-06, 4.9956e-06, 4.7159e-06],\n",
       "              [4.0356e-06, 4.3233e-06, 4.6493e-06, 4.4254e-06],\n",
       "              [3.8925e-06, 4.0866e-06, 4.2951e-06, 4.2701e-06],\n",
       "              [3.7331e-06, 3.7774e-06, 3.9195e-06, 3.8793e-06]],\n",
       "    \n",
       "             [[5.0440e-06, 5.5668e-06, 5.9801e-06, 5.5765e-06],\n",
       "              [4.5705e-06, 5.0218e-06, 5.3961e-06, 5.1578e-06],\n",
       "              [4.2817e-06, 4.6006e-06, 4.7838e-06, 4.5206e-06],\n",
       "              [4.0397e-06, 4.0541e-06, 4.0806e-06, 4.0185e-06]],\n",
       "    \n",
       "             [[4.9933e-06, 5.4240e-06, 5.6826e-06, 5.3109e-06],\n",
       "              [4.5678e-06, 4.8810e-06, 5.1874e-06, 4.9654e-06],\n",
       "              [4.1606e-06, 4.4312e-06, 4.5602e-06, 4.4402e-06],\n",
       "              [3.9490e-06, 3.9764e-06, 4.0430e-06, 3.9623e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[5.4041e-06, 5.8080e-06, 5.7805e-06, 5.1299e-06],\n",
       "              [5.5015e-06, 6.0914e-06, 6.1866e-06, 5.5891e-06],\n",
       "              [6.0975e-06, 6.4770e-06, 6.3997e-06, 6.2435e-06],\n",
       "              [5.8947e-06, 5.9734e-06, 6.2554e-06, 6.1992e-06]],\n",
       "    \n",
       "             [[5.7229e-06, 6.3105e-06, 6.2079e-06, 5.3659e-06],\n",
       "              [5.7647e-06, 6.3626e-06, 6.3321e-06, 5.5701e-06],\n",
       "              [6.2959e-06, 6.4249e-06, 6.3335e-06, 5.8468e-06],\n",
       "              [5.8151e-06, 5.7430e-06, 5.6892e-06, 5.5515e-06]],\n",
       "    \n",
       "             [[5.1379e-06, 5.6316e-06, 5.4967e-06, 4.8786e-06],\n",
       "              [5.1996e-06, 5.6392e-06, 5.6772e-06, 5.1248e-06],\n",
       "              [5.6669e-06, 5.7779e-06, 5.7065e-06, 5.5431e-06],\n",
       "              [5.2101e-06, 5.2377e-06, 5.2941e-06, 5.2049e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[3.9741e-06, 4.4065e-06, 4.5503e-06, 4.2549e-06],\n",
       "              [4.2954e-06, 4.7175e-06, 4.8178e-06, 4.6392e-06],\n",
       "              [4.7789e-06, 5.1677e-06, 5.3082e-06, 5.1466e-06],\n",
       "              [4.6332e-06, 4.7913e-06, 5.1630e-06, 5.1336e-06]],\n",
       "    \n",
       "             [[4.0038e-06, 4.5983e-06, 4.6396e-06, 4.2936e-06],\n",
       "              [4.3808e-06, 4.8072e-06, 4.8625e-06, 4.6600e-06],\n",
       "              [4.6635e-06, 4.9170e-06, 5.0506e-06, 4.8167e-06],\n",
       "              [4.2565e-06, 4.3486e-06, 4.6058e-06, 4.4295e-06]],\n",
       "    \n",
       "             [[4.9620e-06, 5.5618e-06, 5.5617e-06, 5.3488e-06],\n",
       "              [5.2351e-06, 5.6896e-06, 5.8844e-06, 5.6394e-06],\n",
       "              [5.2923e-06, 5.6093e-06, 5.8922e-06, 5.7741e-06],\n",
       "              [4.7526e-06, 4.8595e-06, 5.1496e-06, 5.1500e-06]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[4.4634e-06, 4.5203e-06, 4.4700e-06, 4.3665e-06],\n",
       "              [5.0418e-06, 5.1994e-06, 5.0557e-06, 4.8640e-06],\n",
       "              [5.4529e-06, 5.6965e-06, 5.5146e-06, 5.1300e-06],\n",
       "              [5.2593e-06, 5.4180e-06, 5.3520e-06, 4.8932e-06]],\n",
       "    \n",
       "             [[4.6859e-06, 4.7908e-06, 4.7064e-06, 4.6624e-06],\n",
       "              [5.3983e-06, 5.5217e-06, 5.2986e-06, 5.0693e-06],\n",
       "              [5.7665e-06, 5.9958e-06, 5.7423e-06, 5.3898e-06],\n",
       "              [5.4300e-06, 5.5269e-06, 5.4466e-06, 4.9530e-06]],\n",
       "    \n",
       "             [[5.2193e-06, 5.3540e-06, 5.4336e-06, 5.3816e-06],\n",
       "              [6.0002e-06, 6.1924e-06, 6.1182e-06, 5.8564e-06],\n",
       "              [6.4723e-06, 6.8343e-06, 6.5429e-06, 6.0624e-06],\n",
       "              [6.1493e-06, 6.4522e-06, 6.2356e-06, 5.6733e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[3.6241e-06, 3.8766e-06, 3.9906e-06, 3.8988e-06],\n",
       "              [3.7791e-06, 4.0779e-06, 4.1460e-06, 3.8843e-06],\n",
       "              [3.8297e-06, 3.8751e-06, 3.9610e-06, 3.6798e-06],\n",
       "              [3.5011e-06, 3.4056e-06, 3.4460e-06, 3.1899e-06]],\n",
       "    \n",
       "             [[4.0591e-06, 4.3272e-06, 4.4978e-06, 4.4016e-06],\n",
       "              [4.0362e-06, 4.4277e-06, 4.6823e-06, 4.4031e-06],\n",
       "              [3.8805e-06, 4.0883e-06, 4.3175e-06, 4.0902e-06],\n",
       "              [3.4570e-06, 3.4870e-06, 3.5185e-06, 3.4045e-06]],\n",
       "    \n",
       "             [[4.2850e-06, 4.8151e-06, 5.0683e-06, 4.9494e-06],\n",
       "              [4.1896e-06, 4.7454e-06, 5.0873e-06, 4.7282e-06],\n",
       "              [3.9649e-06, 4.4159e-06, 4.7322e-06, 4.5203e-06],\n",
       "              [3.5246e-06, 3.6790e-06, 3.8900e-06, 3.8621e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[5.6618e-06, 5.9137e-06, 5.5271e-06, 4.6861e-06],\n",
       "              [5.2378e-06, 5.5006e-06, 5.1986e-06, 4.4935e-06],\n",
       "              [4.8534e-06, 4.9179e-06, 4.6836e-06, 4.2429e-06],\n",
       "              [4.5938e-06, 4.4020e-06, 4.1256e-06, 3.7787e-06]],\n",
       "    \n",
       "             [[5.8835e-06, 6.1999e-06, 5.8653e-06, 4.7905e-06],\n",
       "              [5.3255e-06, 5.6591e-06, 5.2459e-06, 4.4044e-06],\n",
       "              [5.1300e-06, 5.1469e-06, 4.8419e-06, 4.1363e-06],\n",
       "              [4.9807e-06, 4.7737e-06, 4.3174e-06, 3.7536e-06]],\n",
       "    \n",
       "             [[5.9515e-06, 6.0628e-06, 5.6944e-06, 4.7095e-06],\n",
       "              [5.2834e-06, 5.5088e-06, 5.0997e-06, 4.2907e-06],\n",
       "              [5.1130e-06, 5.0654e-06, 4.8040e-06, 4.1148e-06],\n",
       "              [4.9748e-06, 4.8086e-06, 4.3623e-06, 3.9109e-06]]]], device='cuda:0')},\n",
       "   3: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-1.1549e-03, -1.0971e-03,  6.6731e-04,  2.2183e-04, -2.5489e-04,\n",
       "            -4.6621e-04, -7.2266e-04,  5.5664e-03,  1.2624e-03,  3.1276e-03,\n",
       "            -7.9431e-03,  2.2772e-03, -1.0909e-04, -1.6263e-03, -8.3253e-04,\n",
       "             2.1010e-03, -5.3831e-03, -4.9639e-04, -1.2084e-03, -6.9447e-04,\n",
       "             1.5145e-03, -2.9177e-03, -5.2929e-04,  5.5907e-03,  3.8415e-03,\n",
       "            -2.2170e-03, -1.4563e-03,  3.6643e-03, -1.6871e-03, -8.8702e-04,\n",
       "            -1.0558e-03,  2.5088e-03,  1.4266e-03, -1.0681e-03, -4.3402e-03,\n",
       "             9.0744e-04, -3.0918e-03,  9.4382e-04,  9.6276e-06,  1.6845e-03,\n",
       "             6.1541e-03, -1.1214e-03,  3.9569e-03,  2.6681e-03,  7.4006e-04,\n",
       "             2.4755e-03,  1.2303e-03, -2.6838e-03, -1.6496e-03, -5.8874e-03,\n",
       "            -3.1709e-03,  5.2261e-05,  7.3323e-03, -2.4085e-03,  1.8968e-03,\n",
       "             2.5070e-03,  1.2053e-03, -5.7901e-03, -1.2314e-03,  4.2912e-03,\n",
       "            -2.1034e-03, -3.9818e-03,  4.3662e-04, -9.9402e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([9.0960e-06, 7.8770e-06, 4.5893e-06, 2.0533e-06, 2.2992e-06, 4.3598e-06,\n",
       "            7.5873e-06, 1.9035e-05, 3.7476e-06, 1.0209e-05, 3.5279e-05, 5.1651e-06,\n",
       "            6.2834e-06, 7.1753e-06, 9.4681e-06, 4.0549e-06, 1.9793e-05, 1.7460e-06,\n",
       "            6.9899e-06, 6.7699e-06, 5.0725e-06, 2.0952e-05, 1.4491e-05, 2.3350e-05,\n",
       "            1.5855e-05, 2.1314e-06, 8.5065e-06, 2.2591e-05, 5.5567e-06, 5.1888e-06,\n",
       "            4.6663e-06, 8.0405e-06, 7.5667e-06, 9.4822e-06, 1.1033e-05, 7.2148e-06,\n",
       "            6.9536e-06, 2.4401e-06, 5.0113e-06, 3.4924e-06, 2.3093e-05, 3.6990e-06,\n",
       "            9.8874e-06, 5.6082e-06, 3.8350e-06, 9.5625e-06, 3.1668e-06, 6.7826e-06,\n",
       "            4.5429e-06, 2.3719e-05, 1.3642e-05, 2.1391e-06, 3.0650e-05, 6.2244e-06,\n",
       "            8.9870e-06, 8.7962e-06, 7.3337e-06, 2.9798e-05, 5.2824e-06, 3.2383e-05,\n",
       "            9.3410e-06, 8.6697e-06, 2.9616e-06, 9.0117e-06], device='cuda:0')},\n",
       "   4: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-9.5868e-04, -2.0238e-04,  5.7251e-04,  9.1996e-04, -3.4025e-03,\n",
       "            -1.9771e-03, -7.8922e-04, -8.0907e-04, -9.5349e-04, -5.5473e-04,\n",
       "            -1.9979e-05, -9.5440e-04, -1.3886e-03, -1.6030e-03, -1.9207e-03,\n",
       "            -4.2300e-04,  1.5637e-04,  1.2974e-03, -1.4298e-04, -2.9033e-04,\n",
       "            -6.6774e-04, -1.0604e-03, -1.0614e-03,  2.5034e-05,  1.6806e-03,\n",
       "             9.7007e-05, -8.5039e-04, -2.6650e-04,  7.2189e-04, -2.4006e-04,\n",
       "            -1.9074e-03, -6.5252e-04,  6.8193e-05, -4.3456e-04, -1.9175e-03,\n",
       "             6.1046e-04, -1.9433e-05,  7.6215e-05, -1.2847e-04,  3.9211e-04,\n",
       "            -3.2693e-04, -3.0124e-03, -1.6494e-03, -1.5142e-03, -5.4147e-04,\n",
       "            -1.7575e-03,  5.5120e-04,  6.3576e-04, -7.9802e-04,  1.6546e-05,\n",
       "             7.3728e-04,  9.9591e-04,  1.4422e-03,  3.8201e-05, -4.9318e-04,\n",
       "            -1.3654e-03,  2.2236e-03,  4.0468e-03,  4.6180e-04, -2.3178e-04,\n",
       "            -5.0061e-04,  3.1418e-04, -4.3799e-04, -3.8946e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([2.4844e-07, 8.1107e-07, 6.5577e-07, 1.4494e-06, 9.7233e-06, 3.2523e-06,\n",
       "            9.2579e-07, 9.8559e-07, 1.8443e-06, 5.0185e-07, 2.9922e-06, 1.0876e-06,\n",
       "            1.2420e-06, 1.3842e-06, 1.7699e-06, 1.3151e-06, 3.6136e-06, 1.3039e-06,\n",
       "            4.1915e-07, 1.4097e-06, 1.4500e-06, 2.1783e-06, 1.2537e-06, 2.1462e-06,\n",
       "            6.5563e-06, 2.4833e-06, 4.4543e-06, 3.9292e-06, 5.9392e-06, 4.4421e-07,\n",
       "            1.1011e-06, 1.1061e-06, 4.4420e-07, 1.4201e-06, 7.4382e-06, 1.9135e-06,\n",
       "            2.7913e-06, 2.4649e-07, 1.6618e-06, 8.2904e-07, 9.8805e-07, 3.6251e-06,\n",
       "            3.1044e-06, 1.2389e-05, 6.1506e-07, 2.9066e-06, 3.8688e-06, 2.0670e-06,\n",
       "            3.8403e-06, 6.8951e-07, 1.3694e-06, 3.8664e-06, 3.3671e-06, 1.1204e-06,\n",
       "            9.2333e-07, 2.9832e-06, 2.7702e-06, 7.0828e-06, 4.8206e-07, 9.0645e-07,\n",
       "            1.4325e-06, 1.3151e-06, 4.3300e-06, 3.6629e-06], device='cuda:0')},\n",
       "   5: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-1.7530e-03, -1.5569e-03,  1.6764e-03,  7.6749e-04,  8.1796e-05,\n",
       "            -1.2934e-03, -1.4615e-03,  3.2027e-03, -6.6114e-04,  2.4079e-03,\n",
       "            -5.7162e-03,  1.3293e-03,  6.2174e-04, -1.0413e-03, -1.3379e-03,\n",
       "             1.7692e-03, -2.2743e-03, -2.4419e-03, -1.3332e-03, -1.5841e-03,\n",
       "             2.0851e-03, -1.7952e-03,  3.6522e-04,  3.0422e-03,  2.1293e-03,\n",
       "             4.6590e-04, -3.0187e-03,  1.1901e-03, -7.4750e-04, -2.1997e-03,\n",
       "            -4.6230e-04,  1.2533e-03, -1.0149e-03, -2.1096e-03, -4.5829e-03,\n",
       "             9.3667e-04, -3.7717e-03, -7.5151e-04, -1.0039e-03,  6.1672e-04,\n",
       "             3.8395e-03,  1.2901e-03,  3.4132e-03,  1.6919e-03,  1.7605e-03,\n",
       "             2.1436e-03,  2.6154e-03, -1.1780e-03,  5.7498e-04, -4.7913e-03,\n",
       "            -9.4123e-04, -1.6922e-03,  4.4496e-03, -3.5523e-03,  5.9802e-04,\n",
       "             8.2580e-04,  1.2788e-03, -4.5551e-03, -1.3584e-03,  2.2470e-03,\n",
       "            -1.0140e-03, -2.1820e-03,  5.6695e-04, -1.4681e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([5.7269e-06, 6.3751e-06, 2.5150e-06, 1.9725e-06, 7.2202e-06, 6.2715e-06,\n",
       "            4.0090e-06, 9.0430e-06, 3.1899e-06, 6.7483e-06, 2.8315e-05, 2.6078e-06,\n",
       "            5.5764e-06, 5.3738e-06, 8.7381e-06, 5.8159e-06, 9.7015e-06, 4.4133e-06,\n",
       "            3.8593e-06, 2.9443e-06, 8.1916e-06, 1.6817e-05, 9.5259e-06, 9.5235e-06,\n",
       "            7.2210e-06, 4.0577e-06, 1.6507e-05, 1.4043e-05, 4.8279e-06, 9.9579e-06,\n",
       "            2.4073e-06, 2.6951e-06, 2.8325e-06, 6.1150e-06, 1.6366e-05, 6.4260e-06,\n",
       "            9.8224e-06, 1.3582e-06, 4.5001e-06, 1.5872e-06, 1.2728e-05, 2.5440e-06,\n",
       "            9.9368e-06, 2.9723e-06, 4.5369e-06, 1.0234e-05, 6.0664e-06, 2.7340e-06,\n",
       "            4.3167e-06, 1.9427e-05, 9.5204e-06, 4.0376e-06, 1.6595e-05, 9.2934e-06,\n",
       "            4.4813e-06, 6.4162e-06, 1.8702e-06, 1.8746e-05, 2.6628e-06, 2.3783e-05,\n",
       "            4.0860e-06, 5.7726e-06, 3.4309e-06, 3.1609e-06], device='cuda:0')},\n",
       "   6: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[-6.3223e-05, -5.1837e-04, -5.0325e-04,  ..., -1.1173e-04,\n",
       "             -5.0101e-04, -6.1250e-04],\n",
       "            [-1.8575e-04, -6.4899e-04, -6.7093e-04,  ..., -5.5893e-05,\n",
       "             -5.8994e-04, -3.0576e-04],\n",
       "            [-6.1078e-05, -1.2629e-04, -1.6129e-04,  ..., -6.0003e-05,\n",
       "             -1.4807e-04, -1.0620e-04],\n",
       "            ...,\n",
       "            [ 1.1313e-03, -1.2283e-03, -4.2647e-05,  ..., -7.1775e-04,\n",
       "              2.1156e-03, -2.6229e-03],\n",
       "            [-2.5549e-06,  1.3951e-04,  7.5752e-04,  ...,  3.0723e-04,\n",
       "             -5.5104e-04,  2.7678e-06],\n",
       "            [ 1.1462e-04,  4.7030e-04,  9.2327e-04,  ...,  2.6240e-04,\n",
       "             -1.2651e-03,  4.3420e-04]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.8906e-09, 1.1400e-07, 1.4208e-07,  ..., 3.7602e-09, 1.1935e-07,\n",
       "             1.3781e-07],\n",
       "            [3.1677e-08, 1.8015e-06, 2.0096e-06,  ..., 5.2212e-08, 1.7121e-06,\n",
       "             2.1250e-06],\n",
       "            [3.9417e-09, 1.9098e-07, 2.8455e-07,  ..., 6.2435e-09, 2.2422e-07,\n",
       "             2.2588e-07],\n",
       "            ...,\n",
       "            [6.4294e-07, 1.7155e-06, 3.6894e-06,  ..., 1.3623e-06, 6.2636e-06,\n",
       "             1.0575e-05],\n",
       "            [2.6303e-07, 6.8899e-07, 1.2359e-06,  ..., 3.6548e-07, 2.5206e-06,\n",
       "             4.8574e-06],\n",
       "            [3.6442e-07, 8.9349e-07, 2.1340e-06,  ..., 5.9381e-07, 3.1767e-06,\n",
       "             6.2512e-06]], device='cuda:0')},\n",
       "   7: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-3.1648e-04, -2.7846e-04, -1.4354e-05,  3.7340e-04, -4.4480e-04,\n",
       "            -2.3071e-04,  3.2408e-04, -3.0732e-04, -4.7601e-04, -8.5480e-04,\n",
       "            -5.4056e-04, -2.0133e-04, -2.1528e-04,  1.7039e-04,  1.7729e-04,\n",
       "             1.9027e-04,  6.5867e-05,  1.7209e-04,  2.3155e-05, -2.5722e-04,\n",
       "             4.6556e-04, -1.9429e-04,  1.6462e-04,  3.4165e-04, -5.3806e-04,\n",
       "             8.5878e-04,  9.0318e-05,  4.1709e-05,  1.0130e-04,  4.4000e-04,\n",
       "            -5.7766e-04, -2.1605e-04, -5.0630e-04, -2.6235e-04, -2.3921e-04,\n",
       "            -7.3617e-05,  1.9685e-04, -1.0211e-03, -9.7123e-04, -4.9458e-04,\n",
       "             5.0899e-04, -5.1039e-04, -5.1093e-04, -2.2232e-04, -3.1916e-04,\n",
       "            -4.9229e-04, -1.5652e-04, -1.2331e-03,  8.8814e-05,  1.4163e-04,\n",
       "            -5.0188e-04, -6.0169e-04,  1.9771e-04,  2.5648e-04,  9.0315e-04,\n",
       "             3.8972e-04,  4.4842e-04,  1.1693e-03,  5.2414e-04, -1.3021e-03,\n",
       "            -1.7226e-04, -1.7744e-04,  4.5183e-04, -4.4889e-05,  9.8939e-11,\n",
       "            -4.0718e-11,  2.5750e-11,  2.8878e-11,  3.3404e-11,  8.1785e-12,\n",
       "            -3.0794e-11,  4.5729e-11,  3.2660e-11,  9.7625e-11,  5.5579e-12,\n",
       "             4.8674e-11,  3.0417e-11, -1.2924e-11, -3.0973e-11,  3.0445e-12,\n",
       "            -2.7573e-11, -2.1542e-10, -1.1227e-10, -8.6296e-11,  3.7930e-12,\n",
       "            -1.3115e-10,  5.8294e-12, -8.4459e-12,  1.3691e-11,  9.5080e-11,\n",
       "            -1.3325e-11,  8.0407e-11,  1.7053e-11,  3.0707e-12, -1.7300e-11,\n",
       "             6.2427e-11, -2.6491e-10, -1.2529e-11, -1.4183e-11, -5.3251e-10,\n",
       "             3.7095e-10,  7.0154e-11, -2.2990e-10, -1.6722e-10,  1.1942e-10,\n",
       "            -8.8034e-11, -1.5922e-10, -3.8090e-10,  1.2927e-10, -8.2049e-10,\n",
       "            -3.3706e-10, -6.1114e-10,  6.8830e-10, -1.7998e-10, -4.2740e-10,\n",
       "            -4.4314e-11, -2.0975e-10, -2.3345e-10,  1.8000e-10, -1.0764e-10,\n",
       "            -7.7406e-11,  5.4921e-11, -2.2903e-10, -2.1244e-10,  3.2920e-10,\n",
       "             5.1695e-12,  1.4857e-10,  2.1294e-10, -3.3667e-04, -3.2588e-04,\n",
       "             1.1886e-03,  3.0788e-03,  1.9450e-03, -2.3641e-03, -1.1438e-03,\n",
       "            -7.7755e-05, -4.9570e-04, -1.9722e-03, -1.7016e-03,  2.5821e-03,\n",
       "             3.7702e-03,  2.4964e-03,  3.1751e-03, -2.2266e-03,  1.1615e-03,\n",
       "            -1.2574e-03,  9.1709e-04,  1.6125e-03,  5.7933e-05, -3.7001e-03,\n",
       "            -1.3997e-03,  5.1743e-04, -3.8305e-03,  1.5949e-03, -3.3802e-04,\n",
       "            -4.4336e-03,  6.5922e-04, -5.6106e-04,  1.6663e-03,  4.2511e-04,\n",
       "             3.3153e-03,  2.4877e-03,  4.1375e-03,  1.6914e-03,  1.9895e-03,\n",
       "             1.5807e-03, -7.6820e-04, -2.0965e-03, -2.1772e-03,  3.3786e-04,\n",
       "            -1.9618e-03,  3.9294e-03, -1.6063e-03, -1.6647e-03, -3.0137e-03,\n",
       "             4.2790e-04, -1.6210e-03, -2.2748e-03,  9.3979e-04,  4.5801e-03,\n",
       "             3.8084e-03,  9.7780e-04,  8.8527e-04,  5.0543e-04, -5.3591e-04,\n",
       "             2.4198e-03,  1.8226e-03, -1.2607e-03,  1.6204e-03,  4.3859e-03,\n",
       "            -2.0132e-03, -2.6138e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([7.2915e-08, 9.7710e-07, 1.5203e-07, 1.2287e-07, 4.0983e-07, 4.0743e-07,\n",
       "            1.6646e-07, 2.0580e-07, 5.0349e-07, 1.3843e-06, 3.9746e-07, 2.2046e-07,\n",
       "            2.0871e-07, 1.1070e-06, 8.3252e-08, 2.8331e-07, 2.6302e-07, 1.4994e-07,\n",
       "            1.0175e-07, 4.7447e-07, 2.4651e-07, 1.2754e-07, 2.5910e-07, 2.0679e-07,\n",
       "            6.3642e-07, 9.7252e-07, 5.0220e-07, 4.0610e-07, 4.9749e-07, 2.9138e-07,\n",
       "            1.6420e-07, 1.7574e-07, 4.4881e-07, 1.8204e-07, 1.3321e-07, 1.8440e-07,\n",
       "            2.1514e-07, 5.9425e-07, 8.9874e-07, 3.7344e-07, 1.5274e-07, 3.6664e-07,\n",
       "            1.8716e-07, 2.8069e-07, 1.7213e-07, 2.1226e-07, 2.3665e-07, 6.9944e-07,\n",
       "            5.7512e-07, 2.2637e-07, 3.9698e-07, 2.8518e-07, 1.9050e-07, 1.4275e-07,\n",
       "            4.3881e-07, 2.1500e-07, 1.5725e-07, 1.0219e-06, 2.9568e-07, 7.0723e-07,\n",
       "            1.4532e-07, 2.8959e-07, 4.2943e-07, 2.2716e-07, 5.1387e-21, 1.1754e-20,\n",
       "            3.0749e-21, 1.6543e-20, 1.4276e-20, 3.2111e-22, 5.5403e-21, 2.6882e-20,\n",
       "            8.7083e-21, 1.0441e-20, 1.5397e-22, 1.7497e-20, 4.8896e-20, 2.8809e-21,\n",
       "            6.2546e-21, 8.1018e-22, 1.4095e-20, 5.3021e-20, 1.0769e-20, 4.0252e-21,\n",
       "            1.6963e-22, 5.1937e-21, 1.7396e-21, 2.1381e-21, 4.0960e-21, 1.5325e-20,\n",
       "            2.2530e-21, 3.6771e-21, 5.2770e-22, 8.7990e-23, 2.7107e-20, 4.2466e-20,\n",
       "            2.4394e-19, 2.8965e-21, 2.5714e-21, 1.0793e-19, 5.6096e-20, 2.4361e-21,\n",
       "            7.4867e-20, 8.1593e-20, 5.0381e-20, 3.5475e-20, 8.2139e-21, 1.0160e-19,\n",
       "            1.1776e-20, 2.0303e-19, 5.0479e-20, 1.7850e-19, 4.3638e-19, 1.9379e-20,\n",
       "            1.3640e-19, 4.1293e-21, 2.9764e-20, 2.1941e-20, 1.1608e-19, 9.6046e-20,\n",
       "            1.0736e-20, 2.3686e-20, 3.6823e-20, 9.5580e-20, 4.8752e-20, 1.9339e-21,\n",
       "            3.8096e-19, 5.3043e-20, 5.5221e-06, 6.4733e-06, 7.8010e-06, 1.2843e-05,\n",
       "            7.4829e-06, 1.1625e-05, 4.9733e-06, 8.6688e-06, 4.8795e-06, 1.1595e-05,\n",
       "            7.4247e-06, 1.2471e-05, 2.5875e-05, 8.3548e-06, 9.4585e-06, 7.6666e-06,\n",
       "            6.3871e-06, 2.2347e-05, 6.8599e-06, 4.7437e-06, 6.2150e-06, 7.9192e-06,\n",
       "            9.4315e-06, 2.1479e-05, 1.6645e-05, 8.0236e-06, 3.3571e-06, 1.6951e-05,\n",
       "            6.6113e-06, 2.4011e-06, 9.2534e-06, 3.0811e-05, 1.1591e-05, 6.1849e-06,\n",
       "            1.2704e-05, 7.7286e-06, 8.5531e-06, 1.0949e-05, 7.9619e-06, 1.3101e-05,\n",
       "            6.8719e-06, 7.7085e-06, 7.1581e-06, 8.1137e-06, 8.6660e-06, 4.5217e-06,\n",
       "            1.1216e-05, 6.5761e-06, 1.2776e-05, 1.3807e-05, 9.3506e-06, 9.4331e-06,\n",
       "            1.4092e-05, 8.9063e-06, 6.5456e-06, 1.2555e-05, 9.9556e-06, 9.8298e-06,\n",
       "            7.9956e-06, 7.0212e-06, 1.2984e-05, 1.8774e-05, 4.3177e-06, 9.5436e-06],\n",
       "           device='cuda:0')},\n",
       "   8: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[-5.0267e-04,  2.9483e-03,  7.0936e-04,  ..., -2.3278e-03,\n",
       "              1.5693e-04, -3.6366e-03],\n",
       "            [ 2.6671e-04, -1.0042e-03, -4.2514e-04,  ...,  3.6318e-04,\n",
       "             -4.9654e-04,  1.1366e-04],\n",
       "            [-1.7008e-04, -1.9161e-03, -6.7331e-04,  ..., -3.5059e-04,\n",
       "             -1.2763e-04,  2.1442e-04],\n",
       "            ...,\n",
       "            [-2.7554e-04, -6.9826e-04, -3.8382e-04,  ..., -3.4703e-04,\n",
       "             -6.5300e-04, -1.1801e-03],\n",
       "            [-3.4974e-05,  2.3860e-03,  3.8316e-04,  ..., -1.1917e-03,\n",
       "              1.2662e-04, -1.4390e-03],\n",
       "            [ 2.6315e-04, -2.1627e-03, -6.1336e-04,  ...,  7.7348e-04,\n",
       "             -1.8723e-04,  1.7157e-03]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[8.5517e-07, 2.1252e-05, 1.3440e-06,  ..., 8.3174e-06, 1.1552e-06,\n",
       "             6.8059e-06],\n",
       "            [3.8700e-07, 7.3987e-06, 5.0330e-07,  ..., 3.0530e-06, 4.2891e-07,\n",
       "             3.1243e-06],\n",
       "            [7.4353e-07, 2.0039e-05, 1.0071e-06,  ..., 6.9221e-06, 8.3420e-07,\n",
       "             6.5958e-06],\n",
       "            ...,\n",
       "            [1.0304e-06, 2.8941e-05, 1.3799e-06,  ..., 7.6787e-06, 7.8480e-07,\n",
       "             4.3388e-06],\n",
       "            [6.1952e-07, 1.4165e-05, 8.6298e-07,  ..., 7.0581e-06, 8.2437e-07,\n",
       "             7.8812e-06],\n",
       "            [3.6138e-07, 7.0798e-06, 5.3264e-07,  ..., 2.4465e-06, 4.6798e-07,\n",
       "             2.5203e-06]], device='cuda:0')},\n",
       "   9: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 3.0480e-03, -8.9317e-04, -1.7436e-03, -6.2486e-04,  1.0562e-03,\n",
       "             1.7210e-03, -1.3833e-03,  7.5506e-03,  3.5921e-03,  4.1071e-03,\n",
       "            -1.5141e-03, -3.9999e-04, -2.2482e-03, -2.8599e-03,  2.2323e-03,\n",
       "             1.1006e-03, -6.4745e-03,  1.0615e-03, -1.6118e-03,  1.0208e-03,\n",
       "            -2.4015e-03, -2.9995e-03, -2.0639e-03,  9.8419e-04, -2.0726e-04,\n",
       "            -8.4497e-04,  1.2816e-03,  1.1258e-03,  1.4663e-04,  1.5181e-03,\n",
       "            -4.4161e-03,  1.6264e-03,  2.1195e-03,  1.2596e-04,  1.8657e-03,\n",
       "            -7.3748e-04, -2.6223e-03, -5.9159e-05,  1.3221e-03, -1.6441e-03,\n",
       "             4.4281e-03, -1.5473e-03,  6.6086e-04,  2.4582e-03,  2.1868e-03,\n",
       "            -4.1462e-03, -2.1854e-03, -3.0691e-03, -5.6152e-03, -3.1892e-03,\n",
       "            -3.0669e-03,  1.6462e-03,  4.8885e-03, -2.8075e-04,  5.0467e-03,\n",
       "            -2.3169e-03,  1.4135e-03, -2.2563e-03,  3.0337e-03,  2.1978e-03,\n",
       "             4.7190e-04, -1.6615e-03,  1.8088e-03, -1.7631e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([3.6448e-05, 1.1483e-05, 3.9683e-05, 1.4066e-05, 1.7494e-05, 9.5375e-06,\n",
       "            1.4488e-05, 3.5442e-05, 1.9884e-05, 3.1512e-05, 1.2711e-05, 1.9532e-05,\n",
       "            1.1033e-05, 4.5398e-05, 3.7341e-05, 3.0816e-05, 3.7653e-05, 2.8302e-05,\n",
       "            1.1626e-05, 3.5688e-05, 3.0639e-05, 1.3297e-05, 1.2245e-05, 4.2348e-05,\n",
       "            7.8527e-06, 2.0108e-05, 2.0110e-05, 9.2902e-06, 1.6605e-05, 1.4387e-05,\n",
       "            2.6938e-05, 1.2247e-05, 1.6298e-05, 2.1208e-05, 3.6220e-05, 1.1696e-05,\n",
       "            1.6389e-05, 2.8840e-05, 1.2276e-05, 9.9814e-06, 4.2120e-05, 2.4057e-05,\n",
       "            1.4259e-05, 1.7359e-05, 6.5949e-06, 3.1042e-05, 1.4574e-05, 2.5041e-05,\n",
       "            1.6648e-05, 2.9820e-05, 2.6314e-05, 1.5688e-05, 4.0507e-05, 1.2644e-05,\n",
       "            2.1594e-05, 1.2252e-05, 2.0665e-05, 4.7668e-05, 3.2213e-05, 9.5093e-06,\n",
       "            3.3805e-05, 6.5777e-05, 1.8892e-05, 1.0561e-05], device='cuda:0')},\n",
       "   10: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-6.9042e-05,  9.3960e-04,  5.1225e-04,  1.3934e-04,  2.9919e-04,\n",
       "            -1.0668e-04, -7.3505e-05,  2.0597e-04,  6.4944e-04, -2.6421e-05,\n",
       "             8.2191e-05, -3.4176e-04, -9.8713e-05, -6.9171e-04,  1.7028e-04,\n",
       "            -4.0382e-04,  4.3680e-04, -3.5326e-04, -4.5932e-04,  3.9493e-04,\n",
       "             5.4680e-05, -1.2547e-03, -3.3994e-05, -3.5598e-05,  8.3324e-04,\n",
       "            -2.0527e-04,  8.0926e-05,  1.0735e-03,  1.5616e-04, -3.1099e-04,\n",
       "             6.3722e-04,  9.8726e-04, -1.4735e-04,  1.9126e-04, -2.3167e-04,\n",
       "            -1.4551e-05, -1.6628e-04,  5.9769e-04, -1.3146e-04,  4.3171e-04,\n",
       "            -2.2232e-05,  3.2007e-04, -8.3221e-04, -1.3222e-04,  2.1585e-05,\n",
       "             2.8920e-04,  1.4780e-04,  3.7298e-04,  4.2102e-05,  9.7915e-05,\n",
       "            -5.6078e-04,  1.6920e-03, -3.5896e-04, -1.0288e-04,  3.0186e-04,\n",
       "            -1.1614e-04, -2.4937e-04, -6.3839e-04,  1.1917e-04,  9.4829e-04,\n",
       "            -1.9311e-04, -8.0417e-05,  4.6272e-04,  5.3111e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([8.9299e-08, 3.4954e-06, 1.2631e-06, 1.5017e-07, 3.3754e-07, 3.4892e-07,\n",
       "            4.0523e-07, 1.2604e-07, 1.4271e-06, 1.0559e-07, 4.3550e-07, 1.9232e-07,\n",
       "            1.1256e-07, 9.0632e-07, 1.0688e-07, 5.6493e-07, 5.3987e-07, 3.3805e-06,\n",
       "            9.3987e-07, 1.0688e-06, 1.3012e-07, 3.6058e-06, 1.1112e-07, 3.1416e-06,\n",
       "            1.1790e-06, 1.6556e-07, 1.3091e-07, 2.1674e-06, 9.9769e-07, 1.8366e-07,\n",
       "            3.1672e-06, 8.2645e-06, 4.4519e-08, 3.7625e-07, 1.7462e-07, 2.9894e-07,\n",
       "            6.4813e-08, 1.2656e-06, 1.1759e-06, 4.4859e-07, 4.0026e-07, 4.3414e-07,\n",
       "            3.0443e-07, 8.4830e-07, 1.9575e-07, 4.2230e-07, 8.4966e-07, 1.3419e-06,\n",
       "            6.1533e-07, 2.8284e-07, 4.2461e-07, 7.2713e-06, 2.1040e-07, 1.5575e-07,\n",
       "            3.7863e-07, 1.5367e-07, 3.2590e-08, 4.0231e-06, 3.8390e-07, 4.0757e-06,\n",
       "            7.4504e-08, 6.7849e-08, 1.5999e-06, 1.5603e-06], device='cuda:0')},\n",
       "   11: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-6.0348e-05,  1.2867e-03,  3.4809e-04, -6.3109e-04, -3.7893e-04,\n",
       "             8.7821e-04, -4.1000e-04,  2.4603e-03,  2.3777e-04,  1.5722e-05,\n",
       "            -1.0097e-04,  1.3909e-03, -3.4100e-04, -7.5190e-04,  6.2119e-04,\n",
       "            -3.0400e-05, -1.0112e-03, -3.1630e-05, -1.4446e-04, -5.6792e-04,\n",
       "            -8.7446e-05, -8.7624e-04, -2.2232e-03,  1.0241e-04, -6.0934e-04,\n",
       "            -2.9807e-06, -3.5930e-04,  1.2733e-03,  4.0058e-05,  3.1521e-04,\n",
       "            -1.2190e-03, -1.1813e-04, -9.3331e-05, -4.1177e-05,  9.8589e-04,\n",
       "             2.7331e-04, -4.9636e-04, -4.2277e-04, -5.1811e-06, -7.3206e-04,\n",
       "             4.5184e-04, -3.5570e-06, -2.6231e-04,  5.1675e-05, -3.9784e-04,\n",
       "             9.0074e-04, -1.4352e-04,  3.7059e-04, -1.1663e-03, -1.3127e-04,\n",
       "            -8.2976e-04,  1.3783e-03,  1.9077e-03,  4.2622e-05,  1.4083e-03,\n",
       "            -1.1367e-03,  4.2392e-04, -3.0900e-04,  1.2511e-05, -8.6068e-04,\n",
       "             3.1404e-04,  2.1803e-04,  4.3962e-04,  5.2913e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([2.1578e-06, 2.2084e-06, 6.9531e-07, 1.5417e-06, 2.0500e-06, 1.0516e-06,\n",
       "            1.0248e-06, 2.8901e-06, 8.5535e-07, 1.0929e-06, 7.8310e-07, 1.9453e-06,\n",
       "            7.0886e-07, 1.7797e-06, 1.2634e-06, 9.9060e-07, 1.9202e-06, 6.5789e-07,\n",
       "            1.7045e-06, 2.2641e-06, 5.6677e-07, 1.5588e-06, 6.2920e-06, 1.5272e-06,\n",
       "            9.3648e-07, 6.3515e-07, 6.6858e-07, 1.6128e-06, 7.7608e-07, 1.1978e-06,\n",
       "            2.3171e-06, 1.1404e-06, 8.0357e-07, 8.2383e-07, 2.7255e-06, 6.0143e-07,\n",
       "            1.4569e-06, 1.3545e-06, 9.7504e-07, 1.3973e-06, 3.2864e-06, 9.4770e-07,\n",
       "            1.2460e-06, 7.1896e-07, 1.4694e-06, 1.7858e-06, 1.2953e-06, 8.0755e-07,\n",
       "            1.0648e-06, 1.3461e-06, 8.4682e-07, 1.7058e-06, 1.7740e-06, 1.1648e-06,\n",
       "            2.3774e-06, 3.2064e-06, 7.4440e-07, 8.1830e-07, 1.5158e-06, 1.1674e-06,\n",
       "            8.7448e-07, 1.1171e-06, 1.0624e-06, 6.2607e-07], device='cuda:0')},\n",
       "   12: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[ 5.1835e-05,  5.9467e-04, -9.6530e-06,  ...,  1.0992e-04,\n",
       "              4.3647e-04,  2.3298e-04],\n",
       "            [-5.3486e-04,  2.2153e-03,  2.4717e-03,  ...,  4.0174e-05,\n",
       "              1.6764e-03,  2.4135e-03],\n",
       "            [-1.9332e-04,  5.7662e-04,  9.6695e-04,  ...,  2.4643e-04,\n",
       "              4.3305e-04,  7.4916e-04],\n",
       "            ...,\n",
       "            [-1.1612e-04,  1.3967e-03,  1.2766e-03,  ..., -4.1368e-05,\n",
       "              9.5338e-04,  8.5470e-04],\n",
       "            [-1.9502e-04,  1.0951e-04,  4.4891e-04,  ..., -1.1966e-04,\n",
       "              7.5125e-05,  8.1948e-05],\n",
       "            [ 7.4693e-05,  3.0131e-04, -2.5505e-04,  ...,  1.1907e-04,\n",
       "              1.4616e-04,  5.9882e-05]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[9.5139e-08, 2.3999e-06, 2.4106e-06,  ..., 7.0447e-08, 1.6366e-06,\n",
       "             2.7118e-06],\n",
       "            [2.2429e-07, 6.6686e-06, 6.9706e-06,  ..., 2.1729e-07, 4.5941e-06,\n",
       "             8.7322e-06],\n",
       "            [3.5775e-07, 8.8475e-06, 9.3172e-06,  ..., 3.2518e-07, 6.1743e-06,\n",
       "             1.0806e-05],\n",
       "            ...,\n",
       "            [4.9410e-08, 8.5913e-07, 9.3719e-07,  ..., 3.3171e-08, 5.4014e-07,\n",
       "             9.4992e-07],\n",
       "            [2.8491e-08, 3.6796e-07, 4.6913e-07,  ..., 5.8558e-08, 2.6637e-07,\n",
       "             3.8072e-07],\n",
       "            [6.2031e-08, 1.2584e-07, 8.1810e-08,  ..., 8.0370e-08, 1.4487e-07,\n",
       "             1.5737e-07]], device='cuda:0')},\n",
       "   13: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-4.3536e-05,  1.8249e-03,  1.0541e-03, -4.8781e-06,  1.4218e-03,\n",
       "            -1.4836e-04, -2.1784e-04,  1.1908e-04,  6.4839e-04, -5.3541e-04,\n",
       "            -1.3706e-04,  2.3906e-03, -5.0871e-04,  4.5789e-05, -9.5665e-04,\n",
       "            -1.9053e-04, -7.3764e-05,  6.3788e-04, -1.2482e-03, -2.2696e-04,\n",
       "             6.3658e-04,  7.3830e-04, -8.4340e-06, -6.5400e-04,  1.6302e-04,\n",
       "             5.4351e-04, -1.7627e-04,  2.7272e-04, -5.0274e-05, -2.4342e-04,\n",
       "             2.5266e-04,  5.2548e-04,  2.5535e-04,  8.0279e-05, -2.1880e-04,\n",
       "            -6.8544e-05,  7.5312e-04,  4.8438e-05,  1.9364e-04, -1.5435e-04,\n",
       "            -5.6491e-04,  2.2837e-07,  1.3283e-04,  8.8684e-06, -3.1250e-05,\n",
       "             1.4182e-03, -8.1089e-04,  4.6436e-04, -3.8591e-04,  2.7395e-04,\n",
       "             1.3319e-03, -3.5120e-04, -3.4728e-04, -3.1902e-04, -1.2007e-04,\n",
       "             3.8368e-04,  1.2350e-03,  3.4440e-04,  8.1301e-04, -9.1186e-04,\n",
       "             4.2925e-04, -1.0484e-03, -6.4656e-04,  5.6154e-05, -6.0658e-05,\n",
       "            -3.5885e-04, -5.3956e-05, -1.9512e-04,  2.0015e-04, -2.7297e-04,\n",
       "             4.6959e-04,  4.0055e-04, -6.1889e-04,  2.3155e-04, -3.0573e-04,\n",
       "             5.8307e-04,  4.3398e-04,  7.5899e-04, -7.3985e-04, -1.2250e-03,\n",
       "            -3.0179e-04,  4.1433e-04,  1.5263e-04,  2.1282e-04,  1.2134e-03,\n",
       "             3.5730e-04,  1.2320e-04, -6.3314e-04, -2.9745e-04, -2.8560e-04,\n",
       "            -1.7755e-04,  1.9874e-03,  1.5690e-04, -4.6104e-04,  7.4632e-04,\n",
       "            -3.7428e-04, -3.6093e-05, -2.8973e-04,  5.5735e-04, -1.5892e-04,\n",
       "            -1.5806e-04, -5.1484e-05, -2.7201e-05, -3.1109e-04, -2.1744e-04,\n",
       "            -2.3132e-04,  4.0049e-04, -4.6289e-04,  8.1068e-04,  3.6852e-04,\n",
       "             2.3776e-05,  1.2446e-03,  1.8879e-05,  3.5941e-04,  8.5052e-04,\n",
       "            -2.8566e-04,  1.9538e-04, -2.9214e-04,  1.6437e-04,  2.2066e-04,\n",
       "            -8.2188e-05,  6.2184e-04, -8.8959e-04,  9.1698e-04,  1.9747e-03,\n",
       "             3.2548e-04, -5.1441e-05,  1.3948e-04,  1.7067e-05, -2.2050e-04,\n",
       "            -3.8821e-04, -4.7749e-04, -2.9943e-04,  2.7155e-05,  1.4960e-05,\n",
       "            -3.1069e-05, -1.5419e-04, -4.4559e-04, -5.7399e-04,  3.9733e-04,\n",
       "             1.0372e-03, -2.2769e-04, -2.5274e-04, -1.2853e-04, -4.7731e-04,\n",
       "            -7.7402e-04,  8.0394e-05,  2.5106e-05, -2.1473e-04,  1.6284e-04,\n",
       "            -1.1151e-03,  2.6351e-04, -6.2817e-05,  2.4558e-04, -1.0642e-03,\n",
       "            -2.9080e-04,  1.1950e-03,  5.6891e-04,  3.0120e-04, -2.5514e-04,\n",
       "            -2.8319e-04, -7.9554e-04,  1.1796e-04,  2.1004e-04,  3.8519e-04,\n",
       "            -4.2961e-04, -3.7911e-04,  5.2794e-04, -6.7660e-04,  1.3623e-04,\n",
       "             3.1441e-04,  2.8867e-04,  6.1779e-05, -2.4785e-07,  1.0290e-03,\n",
       "             2.2159e-04,  7.1397e-04,  1.5184e-04,  5.4781e-04,  1.7548e-05,\n",
       "            -1.8805e-04,  2.3650e-04,  2.5235e-04, -2.9134e-04, -3.1365e-04,\n",
       "             5.3939e-04,  3.4602e-04, -2.5099e-04, -2.8698e-04,  6.2735e-04,\n",
       "             1.1651e-04,  7.2044e-05], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.4066e-06, 4.5168e-06, 5.3448e-06, 2.0882e-07, 1.8523e-06, 3.9097e-07,\n",
       "            3.7087e-07, 1.1163e-07, 2.1147e-06, 8.4512e-06, 8.7666e-08, 2.4631e-06,\n",
       "            1.7617e-07, 9.4398e-07, 2.4460e-06, 1.9727e-07, 5.1343e-07, 1.7716e-06,\n",
       "            1.2427e-06, 1.9115e-06, 2.7146e-07, 1.7516e-06, 1.6175e-06, 1.2263e-06,\n",
       "            6.5576e-08, 7.5625e-07, 7.3005e-08, 1.9724e-06, 2.3187e-07, 3.8359e-07,\n",
       "            1.1027e-06, 3.2130e-07, 2.2513e-07, 1.0850e-06, 4.6748e-07, 1.4653e-07,\n",
       "            4.7807e-07, 7.4481e-08, 1.0552e-06, 7.7155e-07, 1.2622e-06, 1.1021e-07,\n",
       "            1.6826e-07, 1.2613e-07, 1.4834e-06, 2.9243e-06, 1.7296e-06, 4.3998e-07,\n",
       "            1.9244e-07, 2.3470e-07, 2.2318e-06, 2.7891e-07, 8.7306e-08, 8.5371e-08,\n",
       "            1.1898e-07, 1.6130e-06, 2.6747e-06, 5.2909e-07, 1.8165e-06, 9.6162e-07,\n",
       "            3.0213e-07, 1.6335e-06, 3.0189e-07, 2.4793e-06, 8.4888e-07, 9.2070e-07,\n",
       "            6.2261e-07, 5.2233e-07, 1.4831e-06, 9.8628e-07, 2.9517e-07, 4.0652e-07,\n",
       "            7.1457e-07, 1.0603e-06, 1.8021e-07, 1.1511e-06, 1.2835e-06, 1.4989e-06,\n",
       "            1.2060e-06, 1.6119e-06, 9.6384e-08, 4.6438e-06, 8.2645e-07, 3.4632e-06,\n",
       "            2.5130e-06, 1.1500e-07, 9.4393e-08, 4.2248e-06, 2.8415e-07, 2.3349e-07,\n",
       "            1.7054e-07, 2.9599e-06, 3.8580e-06, 2.4225e-07, 1.9373e-06, 9.7947e-07,\n",
       "            2.0131e-07, 4.9551e-07, 6.6525e-07, 8.1321e-08, 5.8538e-07, 1.4597e-06,\n",
       "            7.5766e-08, 1.0439e-06, 1.4594e-06, 9.0026e-07, 5.2022e-07, 6.8969e-07,\n",
       "            5.8114e-07, 3.4647e-07, 3.5757e-06, 1.4409e-06, 5.8748e-07, 8.8161e-07,\n",
       "            1.0154e-06, 1.0500e-06, 2.1741e-06, 2.1975e-07, 4.5142e-07, 1.9321e-07,\n",
       "            9.7801e-07, 2.7624e-07, 1.2542e-06, 4.1368e-06, 3.4715e-06, 6.0857e-07,\n",
       "            3.5717e-06, 4.1635e-07, 8.0336e-07, 1.2572e-06, 3.9507e-07, 2.5489e-06,\n",
       "            7.2944e-07, 1.5809e-06, 3.8840e-06, 1.0483e-06, 7.1986e-07, 1.8606e-07,\n",
       "            1.8250e-06, 1.0848e-07, 2.3636e-06, 9.0133e-07, 2.3677e-06, 7.2788e-08,\n",
       "            3.2041e-07, 1.8364e-06, 1.8963e-06, 1.9822e-06, 9.9256e-08, 5.4454e-07,\n",
       "            1.2913e-06, 5.6886e-07, 2.8071e-07, 8.4310e-07, 4.8462e-06, 6.7790e-07,\n",
       "            2.2738e-06, 9.1141e-07, 7.5676e-07, 4.0403e-07, 4.0625e-07, 1.7006e-06,\n",
       "            9.6837e-08, 1.1505e-07, 2.4142e-06, 1.8529e-06, 1.4348e-07, 1.0025e-06,\n",
       "            1.3951e-07, 2.1955e-06, 4.7286e-07, 7.2557e-06, 1.3033e-06, 1.8456e-08,\n",
       "            7.7869e-06, 2.3627e-07, 1.4814e-06, 5.5657e-08, 4.2665e-07, 9.5196e-07,\n",
       "            2.3142e-07, 2.9078e-07, 9.6125e-07, 1.9841e-07, 8.5039e-07, 2.7352e-06,\n",
       "            1.6502e-07, 6.1833e-08, 3.6455e-07, 5.1240e-07, 3.4067e-07, 3.3944e-07],\n",
       "           device='cuda:0')},\n",
       "   14: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[ 2.4003e-03,  8.3912e-04,  1.5363e-03,  ..., -2.6659e-05,\n",
       "             -3.4601e-04,  1.3179e-04],\n",
       "            [-4.2390e-04, -1.2500e-05, -9.2253e-04,  ..., -3.5352e-04,\n",
       "              9.1991e-05,  9.3278e-04],\n",
       "            [-1.2850e-03, -1.0247e-03, -1.0512e-03,  ..., -1.7654e-04,\n",
       "              5.0401e-05, -6.4706e-04],\n",
       "            ...,\n",
       "            [-5.9191e-04,  8.0726e-06, -2.9804e-04,  ..., -3.9491e-04,\n",
       "             -4.2664e-04, -8.8673e-04],\n",
       "            [ 8.4710e-04,  3.4912e-05, -2.3620e-04,  ...,  8.5643e-05,\n",
       "             -2.2713e-06,  2.6537e-04],\n",
       "            [-8.3666e-04, -8.1628e-04, -8.4673e-04,  ..., -1.0090e-04,\n",
       "             -3.6126e-04,  2.2799e-04]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[8.5991e-06, 4.2174e-06, 9.3737e-06,  ..., 9.5575e-08, 9.3209e-07,\n",
       "             1.9483e-06],\n",
       "            [2.7452e-06, 1.4066e-06, 3.1303e-06,  ..., 9.6803e-08, 2.7682e-07,\n",
       "             7.8115e-07],\n",
       "            [9.1965e-06, 4.8873e-06, 9.5106e-06,  ..., 1.9909e-07, 9.7778e-07,\n",
       "             1.7497e-06],\n",
       "            ...,\n",
       "            [1.1684e-05, 6.2271e-06, 1.1908e-05,  ..., 1.9605e-07, 9.5498e-07,\n",
       "             1.5142e-06],\n",
       "            [7.4304e-06, 3.2454e-06, 8.0420e-06,  ..., 1.1515e-07, 8.1645e-07,\n",
       "             1.5686e-06],\n",
       "            [2.9422e-06, 1.5470e-06, 3.2974e-06,  ..., 8.9659e-08, 2.8710e-07,\n",
       "             6.4160e-07]], device='cuda:0')},\n",
       "   15: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 0.0029, -0.0016, -0.0019,  0.0002,  0.0016,  0.0010, -0.0010,  0.0059,\n",
       "             0.0035,  0.0031, -0.0004, -0.0010, -0.0015, -0.0039,  0.0033,  0.0008,\n",
       "            -0.0063,  0.0011, -0.0014,  0.0020, -0.0032, -0.0028,  0.0007,  0.0011,\n",
       "             0.0004, -0.0012,  0.0008, -0.0001, -0.0007,  0.0004, -0.0032,  0.0023,\n",
       "             0.0031,  0.0005,  0.0005, -0.0012, -0.0014,  0.0003,  0.0016, -0.0006,\n",
       "             0.0050, -0.0012,  0.0007,  0.0024,  0.0027, -0.0041, -0.0020, -0.0035,\n",
       "            -0.0050, -0.0025, -0.0007,  0.0012,  0.0036,  0.0001,  0.0046, -0.0010,\n",
       "             0.0014, -0.0019,  0.0020,  0.0024,  0.0016, -0.0028,  0.0005, -0.0019],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([3.2438e-05, 1.1061e-05, 4.1497e-05, 1.3327e-05, 1.8827e-05, 1.0346e-05,\n",
       "            1.1145e-05, 2.9063e-05, 2.1138e-05, 3.6127e-05, 1.4121e-05, 2.2693e-05,\n",
       "            1.4560e-05, 4.2285e-05, 3.7815e-05, 3.2511e-05, 3.4392e-05, 2.8012e-05,\n",
       "            1.3257e-05, 2.9121e-05, 3.2017e-05, 1.2887e-05, 9.5535e-06, 4.7734e-05,\n",
       "            9.4606e-06, 2.0060e-05, 2.3311e-05, 1.2832e-05, 1.7951e-05, 1.4134e-05,\n",
       "            2.3038e-05, 1.3626e-05, 1.8906e-05, 2.4428e-05, 2.9091e-05, 1.4119e-05,\n",
       "            1.5602e-05, 3.6273e-05, 1.4068e-05, 1.0794e-05, 3.2266e-05, 2.6035e-05,\n",
       "            1.5910e-05, 2.2551e-05, 8.4922e-06, 3.4863e-05, 1.7464e-05, 3.0100e-05,\n",
       "            1.5959e-05, 3.5681e-05, 2.5614e-05, 1.5573e-05, 3.7911e-05, 1.6324e-05,\n",
       "            1.9820e-05, 1.1928e-05, 2.2081e-05, 4.8891e-05, 3.9043e-05, 9.5476e-06,\n",
       "            3.8426e-05, 7.5281e-05, 2.4505e-05, 1.3093e-05], device='cuda:0')},\n",
       "   16: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-6.7431e-04, -1.3331e-03, -8.8160e-04,  2.6194e-04,  3.0426e-04,\n",
       "             5.0716e-05, -1.2205e-03,  5.9537e-04,  2.3651e-04, -1.8371e-03,\n",
       "            -9.4640e-04, -1.4681e-03, -7.3415e-04, -2.7472e-03,  1.8446e-05,\n",
       "            -3.3840e-04,  8.2341e-04, -3.2912e-04, -8.3740e-04, -1.1891e-03,\n",
       "             4.4093e-04, -9.9942e-04,  4.0565e-04, -1.3199e-03,  2.5729e-05,\n",
       "            -1.0026e-03, -2.1646e-04, -6.5983e-04, -3.9169e-04, -7.3790e-04,\n",
       "            -7.0562e-05, -5.0472e-04, -9.9530e-04, -1.4227e-03, -5.4277e-04,\n",
       "            -6.5402e-04,  6.3366e-04, -1.8466e-04, -1.0855e-03,  3.7194e-04,\n",
       "             1.5388e-04, -9.0322e-05, -1.1354e-03, -3.5835e-04, -1.2562e-03,\n",
       "             3.1832e-04, -8.7692e-04, -9.6141e-04,  7.3429e-05, -1.5396e-04,\n",
       "            -2.3496e-03, -1.5029e-03, -1.4961e-03, -7.2655e-04,  4.2745e-04,\n",
       "            -3.6853e-04, -3.9370e-04,  5.0094e-04,  3.1589e-05, -2.0719e-03,\n",
       "            -1.2141e-03,  2.0745e-03, -2.9707e-04,  1.2765e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([8.1435e-07, 4.6895e-06, 2.1002e-06, 7.0082e-07, 6.6581e-06, 6.4357e-07,\n",
       "            1.7289e-06, 1.1048e-06, 4.1587e-07, 2.2033e-06, 1.2312e-06, 2.6132e-06,\n",
       "            2.6481e-07, 2.9930e-06, 2.0293e-06, 4.6567e-07, 4.6676e-06, 1.7137e-06,\n",
       "            9.7076e-07, 2.3605e-06, 3.7724e-07, 9.4888e-07, 2.1491e-06, 4.6317e-06,\n",
       "            1.1192e-06, 5.4009e-07, 1.5800e-06, 1.7256e-06, 3.2757e-06, 2.1975e-06,\n",
       "            1.0410e-06, 2.2153e-06, 1.9286e-06, 1.1804e-06, 3.1695e-07, 1.0581e-06,\n",
       "            1.4169e-06, 6.0149e-07, 8.0920e-07, 7.0836e-07, 1.8836e-06, 1.3258e-06,\n",
       "            8.8077e-07, 1.9012e-06, 9.7985e-07, 3.7197e-07, 9.3787e-07, 9.6034e-07,\n",
       "            1.4405e-06, 8.2404e-07, 3.1252e-06, 1.1211e-06, 2.8138e-06, 6.8243e-07,\n",
       "            3.4752e-06, 6.9501e-07, 4.5964e-07, 4.3702e-06, 1.0643e-06, 3.0035e-06,\n",
       "            4.7948e-06, 9.4411e-07, 8.7084e-07, 1.1427e-05], device='cuda:0')},\n",
       "   17: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 1.3375e-03, -2.6426e-04, -1.3199e-03, -5.0537e-04, -1.0574e-03,\n",
       "             6.4295e-04,  1.5991e-03,  2.5914e-03,  2.2951e-03,  1.1564e-03,\n",
       "            -4.3365e-03,  1.2524e-03, -3.3924e-04, -2.6391e-05, -1.7835e-04,\n",
       "            -5.9285e-04, -3.0476e-03,  8.9322e-04, -9.2387e-04,  8.4537e-04,\n",
       "            -1.3918e-03, -2.1384e-03, -5.6819e-04,  3.4521e-03,  2.4052e-03,\n",
       "            -1.5672e-03,  2.7153e-04,  1.4729e-03, -1.0313e-03,  2.9067e-05,\n",
       "            -9.6716e-04,  2.6555e-03,  3.7597e-03, -1.0123e-03, -1.3441e-04,\n",
       "            -1.2883e-03, -8.4887e-05,  1.7998e-03,  2.0996e-03,  1.8148e-03,\n",
       "             2.7378e-03, -1.4527e-03,  1.5331e-03,  1.4838e-03,  8.4432e-04,\n",
       "            -4.1012e-04, -1.4392e-03, -2.4060e-03, -1.7193e-03, -2.1648e-03,\n",
       "            -2.2906e-03,  2.3609e-04,  3.5769e-03, -1.5010e-04,  5.2540e-04,\n",
       "             1.0593e-03, -7.0155e-04, -3.2057e-03,  6.7309e-04,  3.3822e-03,\n",
       "            -1.6564e-03, -3.5347e-03, -9.6857e-04,  2.3935e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([4.2142e-06, 2.5354e-06, 3.4360e-06, 3.1735e-06, 5.2955e-06, 1.1208e-06,\n",
       "            4.7544e-06, 6.9099e-06, 5.5074e-06, 9.1443e-06, 9.3545e-06, 3.8268e-06,\n",
       "            2.8669e-06, 7.3200e-06, 3.6800e-06, 2.6559e-06, 1.3673e-05, 4.4430e-06,\n",
       "            4.8557e-06, 7.8390e-06, 3.6281e-06, 4.0287e-06, 3.3347e-06, 1.0381e-05,\n",
       "            5.8903e-06, 5.1252e-06, 3.1523e-06, 5.9730e-06, 3.2277e-06, 1.4675e-06,\n",
       "            2.7537e-06, 7.2001e-06, 1.2635e-05, 4.5303e-06, 1.8579e-06, 4.7774e-06,\n",
       "            4.4974e-06, 3.7788e-06, 5.5673e-06, 6.6469e-06, 5.3012e-06, 5.9175e-06,\n",
       "            2.3137e-06, 5.0222e-06, 3.5587e-06, 5.4598e-06, 5.4381e-06, 4.9163e-06,\n",
       "            5.4153e-06, 6.2071e-06, 3.7808e-06, 5.0081e-06, 1.0302e-05, 2.6019e-06,\n",
       "            4.5691e-06, 4.3352e-06, 7.2484e-06, 9.2107e-06, 7.5348e-06, 1.4126e-05,\n",
       "            4.8319e-06, 6.6426e-06, 3.8287e-06, 6.5015e-06], device='cuda:0')},\n",
       "   18: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[-5.6965e-05,  8.1823e-05,  5.7699e-04,  ...,  1.0131e-04,\n",
       "              7.9907e-05,  3.0485e-04],\n",
       "            [-2.2975e-05,  2.8307e-04,  8.8200e-06,  ..., -1.0882e-04,\n",
       "              2.3362e-04,  2.3325e-04],\n",
       "            [-1.6855e-04, -1.0607e-04,  2.9680e-04,  ...,  8.8831e-05,\n",
       "             -1.7969e-04, -1.6889e-05],\n",
       "            ...,\n",
       "            [ 5.3141e-04,  1.1450e-05, -5.6577e-04,  ...,  5.9831e-05,\n",
       "              4.4889e-04, -5.3130e-04],\n",
       "            [-7.6568e-04, -1.7812e-04, -2.0832e-05,  ...,  1.0874e-04,\n",
       "             -1.8986e-04,  8.4492e-04],\n",
       "            [-4.7378e-04,  1.4907e-04,  1.8090e-04,  ...,  4.8704e-05,\n",
       "             -2.8581e-04,  2.3569e-04]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.3633e-07, 7.5656e-07, 7.5671e-07,  ..., 8.5391e-08, 6.6254e-07,\n",
       "             1.2265e-06],\n",
       "            [5.2550e-08, 3.0456e-07, 2.9379e-07,  ..., 3.6880e-08, 2.6318e-07,\n",
       "             4.9050e-07],\n",
       "            [1.3932e-07, 7.9541e-07, 7.8957e-07,  ..., 9.9694e-08, 6.8883e-07,\n",
       "             1.2697e-06],\n",
       "            ...,\n",
       "            [1.5682e-06, 6.9044e-07, 1.0487e-06,  ..., 2.3971e-07, 6.6044e-07,\n",
       "             5.3307e-06],\n",
       "            [5.1525e-07, 2.6036e-07, 3.3328e-07,  ..., 1.1482e-07, 2.5907e-07,\n",
       "             1.9663e-06],\n",
       "            [3.2806e-07, 2.6743e-07, 2.9456e-07,  ..., 1.0192e-07, 2.1812e-07,\n",
       "             1.1393e-06]], device='cuda:0')},\n",
       "   19: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 2.2708e-04,  1.4548e-04,  3.6731e-06,  1.5182e-04,  1.5513e-04,\n",
       "             1.8769e-04, -2.6914e-04,  2.9205e-04,  3.9482e-05, -1.4595e-05,\n",
       "             1.4842e-04, -3.9273e-05,  2.1358e-05,  1.0727e-04,  5.1864e-05,\n",
       "             8.4382e-05, -3.6873e-04,  1.3041e-04, -6.9544e-05, -2.2628e-05,\n",
       "             2.1737e-04,  7.8012e-05,  6.0887e-05, -1.5286e-04,  1.8455e-04,\n",
       "             5.3336e-05,  2.3894e-05,  1.7815e-04, -4.3182e-05, -1.2424e-04,\n",
       "            -4.9251e-05,  3.3723e-04,  2.6288e-04,  6.5438e-05, -4.7001e-05,\n",
       "             1.0127e-03,  7.1912e-04, -1.6122e-04, -1.3602e-04, -8.0742e-06,\n",
       "            -4.5287e-05,  4.9391e-04,  2.4564e-04,  8.5026e-05, -1.4517e-04,\n",
       "            -1.4928e-04, -2.8926e-04, -4.2770e-04,  9.6386e-06, -4.1318e-04,\n",
       "             3.1185e-05,  2.1006e-04, -2.2425e-04, -3.9320e-04,  1.6065e-04,\n",
       "             4.2845e-04,  1.0706e-03,  8.3131e-04,  3.2078e-05,  3.1278e-04,\n",
       "             4.6331e-04,  9.4130e-05,  3.5055e-04,  2.3042e-04,  1.2582e-10,\n",
       "            -3.1617e-11, -1.2159e-11,  4.5833e-11,  7.4396e-11, -1.4342e-11,\n",
       "            -2.7175e-10,  7.9258e-11, -1.1223e-10,  2.5051e-11, -2.7499e-10,\n",
       "            -3.8311e-11, -6.2938e-11,  5.0393e-12,  1.6393e-10,  1.2153e-10,\n",
       "             6.9176e-12,  1.3288e-10,  2.0917e-11,  1.6653e-11,  3.4625e-10,\n",
       "             1.3693e-13,  7.4574e-11,  9.1495e-11, -4.6461e-11,  9.3727e-11,\n",
       "             9.4164e-11,  4.9868e-11,  2.7960e-11, -1.2391e-10, -5.9774e-11,\n",
       "             2.4285e-10,  8.2458e-11, -1.5522e-11,  3.0269e-12,  3.2849e-11,\n",
       "             5.9957e-12, -6.5382e-12, -5.9207e-12, -1.6427e-11, -4.1695e-11,\n",
       "            -1.0304e-11,  5.5330e-12,  7.6680e-12,  2.5193e-11, -1.3955e-11,\n",
       "            -1.4572e-11,  1.2069e-11,  1.3177e-11, -1.5045e-11, -3.7578e-11,\n",
       "            -5.7697e-11, -1.6874e-11, -1.0565e-11,  8.3050e-12,  2.8997e-11,\n",
       "             6.4496e-11, -5.5189e-11,  6.5207e-11,  3.7544e-12, -4.1789e-12,\n",
       "            -2.7583e-11, -5.6566e-12,  6.0875e-11,  3.1830e-04,  1.1918e-03,\n",
       "            -1.1804e-04,  2.2875e-03, -1.7160e-03, -2.5295e-03, -3.2001e-03,\n",
       "            -7.5534e-04,  8.4202e-04, -2.4751e-03,  1.1417e-03, -2.0007e-03,\n",
       "            -2.4194e-03,  2.0178e-03, -1.8254e-03, -3.2028e-04, -1.5118e-03,\n",
       "             3.1277e-03, -7.3461e-04,  9.1427e-04,  2.9375e-04, -6.7251e-04,\n",
       "            -6.2415e-04, -9.8989e-04, -1.0093e-03, -4.0677e-04, -1.8047e-03,\n",
       "            -2.1382e-03, -1.7497e-03, -7.6976e-04, -1.6222e-03,  1.1576e-03,\n",
       "            -6.3381e-04,  4.4790e-05, -2.3160e-03,  4.4137e-04,  1.3177e-03,\n",
       "            -1.5153e-04,  1.7488e-03, -4.5836e-04, -5.6816e-06,  2.3872e-04,\n",
       "            -4.3414e-03, -7.8273e-04, -2.6136e-03,  1.5739e-04, -1.5551e-04,\n",
       "            -2.0953e-04,  1.2571e-03,  2.1274e-03, -9.0883e-04,  1.8601e-03,\n",
       "             1.0625e-03,  1.3907e-03,  1.2367e-03,  6.3426e-04, -1.3103e-03,\n",
       "             1.9182e-03, -1.2061e-04,  1.7603e-03, -1.1915e-04, -5.4088e-04,\n",
       "             1.1723e-03,  3.4049e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([4.9997e-07, 1.9471e-07, 5.1399e-07, 1.3830e-07, 1.5264e-07, 2.2402e-07,\n",
       "            6.2468e-07, 2.9359e-07, 2.1445e-07, 4.7035e-07, 6.3927e-07, 2.2961e-07,\n",
       "            2.8843e-07, 6.1574e-07, 1.2316e-07, 9.2234e-08, 6.4780e-07, 8.1860e-07,\n",
       "            9.3470e-08, 2.1228e-07, 2.3544e-07, 1.0272e-07, 2.0629e-07, 5.9125e-07,\n",
       "            2.5708e-07, 2.9289e-07, 1.7793e-07, 1.1219e-07, 1.9683e-07, 2.7312e-07,\n",
       "            3.5238e-07, 2.7412e-07, 5.8296e-08, 2.4940e-07, 1.4136e-07, 1.0878e-06,\n",
       "            2.1131e-07, 1.0852e-07, 5.4212e-07, 1.7911e-07, 1.8219e-07, 1.3452e-07,\n",
       "            2.3163e-07, 1.5635e-07, 3.7600e-07, 6.3885e-08, 1.1306e-07, 1.2769e-07,\n",
       "            1.0216e-07, 3.9626e-07, 1.3737e-07, 1.0205e-07, 1.9528e-07, 7.2855e-07,\n",
       "            1.3281e-07, 4.1362e-07, 1.3000e-06, 4.0506e-07, 1.5133e-07, 3.5006e-07,\n",
       "            2.8152e-07, 9.7206e-08, 4.7755e-07, 1.1975e-07, 2.4720e-20, 5.1042e-21,\n",
       "            8.3034e-22, 2.3656e-21, 1.6249e-21, 1.7468e-21, 2.2431e-20, 4.1407e-20,\n",
       "            6.9680e-21, 1.2001e-21, 4.2272e-20, 5.4627e-22, 8.6827e-22, 3.0208e-22,\n",
       "            1.9666e-20, 1.0540e-20, 4.6210e-21, 8.9450e-21, 3.6914e-22, 4.0462e-21,\n",
       "            3.5875e-20, 1.6710e-21, 3.2766e-21, 5.4592e-21, 6.5269e-21, 9.8878e-21,\n",
       "            8.3318e-21, 2.6005e-21, 1.6980e-21, 1.4983e-20, 9.1927e-21, 7.1334e-20,\n",
       "            1.4154e-20, 5.8699e-21, 2.6870e-21, 3.6163e-21, 3.2973e-20, 4.0270e-22,\n",
       "            5.6668e-22, 3.5599e-21, 2.0263e-20, 3.6740e-21, 5.9433e-22, 7.8691e-21,\n",
       "            2.1964e-21, 1.2527e-20, 9.7033e-22, 1.7983e-20, 2.3529e-21, 1.0971e-21,\n",
       "            3.5022e-21, 1.4986e-20, 4.0079e-21, 1.6730e-21, 6.9479e-21, 2.0992e-21,\n",
       "            5.9302e-21, 1.7927e-20, 1.2906e-20, 3.7089e-21, 2.0514e-22, 2.5810e-21,\n",
       "            2.9483e-21, 1.8299e-20, 5.5622e-06, 6.0232e-06, 3.6400e-06, 8.1415e-06,\n",
       "            7.8443e-06, 1.0020e-05, 9.5048e-06, 1.3903e-05, 1.1114e-05, 6.2286e-06,\n",
       "            5.4334e-06, 9.7836e-06, 1.0300e-05, 5.5389e-06, 6.7921e-06, 7.8161e-06,\n",
       "            1.1518e-05, 1.6849e-05, 1.1318e-05, 5.7851e-06, 3.0937e-06, 5.2520e-06,\n",
       "            7.7876e-06, 7.2273e-06, 1.8753e-05, 6.5049e-06, 7.0943e-06, 1.4363e-05,\n",
       "            5.0798e-06, 9.9520e-06, 2.5549e-06, 3.4969e-06, 4.1315e-06, 4.2132e-06,\n",
       "            1.5770e-05, 1.3315e-05, 8.2164e-06, 7.4127e-06, 9.4454e-06, 5.6438e-06,\n",
       "            1.3571e-05, 8.1549e-06, 2.0891e-05, 1.8543e-05, 4.2209e-06, 3.3194e-06,\n",
       "            5.9852e-06, 7.4111e-06, 5.3277e-06, 6.8438e-06, 5.5525e-06, 9.2204e-06,\n",
       "            7.4250e-06, 6.8671e-06, 4.1230e-06, 1.6395e-06, 5.0378e-06, 6.3330e-06,\n",
       "            5.1397e-06, 1.3294e-05, 1.0459e-05, 1.2034e-05, 3.8213e-06, 2.5457e-06],\n",
       "           device='cuda:0')},\n",
       "   20: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[-3.8980e-04, -4.4327e-05,  7.7804e-04,  ..., -4.1660e-04,\n",
       "              1.3483e-03,  4.7821e-04],\n",
       "            [ 3.6156e-04,  1.1368e-04, -6.5620e-04,  ...,  5.0608e-04,\n",
       "             -9.3066e-04, -9.6146e-04],\n",
       "            [ 4.7498e-04,  9.8014e-04, -5.1659e-04,  ..., -8.0167e-05,\n",
       "             -7.9092e-04, -2.8674e-04],\n",
       "            ...,\n",
       "            [ 4.0423e-04,  6.0486e-04, -6.2761e-05,  ...,  7.8336e-05,\n",
       "              1.5858e-04,  3.1648e-04],\n",
       "            [-5.5607e-04, -5.5232e-04,  7.5478e-04,  ..., -1.2783e-05,\n",
       "              1.1139e-03,  7.1511e-04],\n",
       "            [ 2.0427e-04,  2.2650e-04, -3.6153e-04,  ...,  5.1651e-04,\n",
       "             -1.1017e-03, -1.5151e-03]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.7457e-06, 1.2477e-06, 1.5385e-06,  ..., 1.4057e-06, 3.7582e-06,\n",
       "             1.1623e-06],\n",
       "            [5.6639e-07, 5.1822e-07, 8.6472e-07,  ..., 6.5109e-07, 1.4296e-06,\n",
       "             5.8303e-07],\n",
       "            [1.7774e-06, 1.0566e-06, 1.4760e-06,  ..., 1.1610e-06, 2.7760e-06,\n",
       "             1.0144e-06],\n",
       "            ...,\n",
       "            [2.1484e-06, 1.0501e-06, 1.5632e-06,  ..., 1.5276e-06, 3.3602e-06,\n",
       "             1.0506e-06],\n",
       "            [1.3141e-06, 1.1641e-06, 1.4815e-06,  ..., 1.2892e-06, 2.8952e-06,\n",
       "             1.0645e-06],\n",
       "            [4.5831e-07, 4.5510e-07, 7.6256e-07,  ..., 5.4823e-07, 1.3321e-06,\n",
       "             5.4683e-07]], device='cuda:0')},\n",
       "   21: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 2.5274e-03, -1.5766e-03, -9.7168e-04,  3.6139e-04,  2.6575e-03,\n",
       "             6.2221e-04, -2.0262e-03,  3.5833e-03,  1.8481e-03,  3.4355e-03,\n",
       "             1.8401e-03, -2.4602e-03, -1.6011e-03, -2.2949e-03,  2.3052e-03,\n",
       "             1.1806e-03, -3.2931e-03,  5.4562e-04, -1.0138e-03,  8.5194e-04,\n",
       "            -1.3722e-03, -8.8678e-04,  3.7371e-04, -2.1640e-03, -1.4784e-03,\n",
       "             6.6383e-04,  1.3183e-03, -1.2120e-03,  1.3964e-03,  1.3392e-03,\n",
       "            -2.5645e-03,  7.2809e-05, -4.5887e-04,  5.8247e-04,  1.1582e-03,\n",
       "            -2.1751e-04, -1.8816e-03, -1.2080e-03, -9.3368e-05, -2.3529e-03,\n",
       "             1.9738e-03, -1.6254e-04, -1.9786e-04,  1.1747e-03,  1.9973e-03,\n",
       "            -4.4852e-03, -1.2235e-03, -1.3910e-03, -3.2280e-03, -1.2180e-03,\n",
       "            -7.7651e-04,  2.6024e-04,  7.1289e-04, -5.4823e-05,  3.5745e-03,\n",
       "            -2.1218e-03,  1.5098e-03,  5.7079e-04,  2.6149e-03,  4.0233e-04,\n",
       "             1.6673e-03,  1.1008e-03,  2.1850e-03, -2.4212e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([3.6341e-05, 9.5154e-06, 3.9598e-05, 1.2352e-05, 1.1694e-05, 7.3278e-06,\n",
       "            8.0755e-06, 1.9181e-05, 1.3338e-05, 1.6952e-05, 1.1083e-05, 1.6097e-05,\n",
       "            1.2288e-05, 4.3883e-05, 2.8023e-05, 2.2465e-05, 1.8217e-05, 1.6894e-05,\n",
       "            1.3125e-05, 1.6697e-05, 2.1617e-05, 1.1599e-05, 1.0681e-05, 3.5536e-05,\n",
       "            9.6127e-06, 2.0918e-05, 1.6581e-05, 1.4517e-05, 9.6223e-06, 9.3562e-06,\n",
       "            1.7748e-05, 1.4914e-05, 1.3829e-05, 1.9397e-05, 2.2252e-05, 1.0855e-05,\n",
       "            8.2696e-06, 2.4912e-05, 8.9952e-06, 4.7247e-06, 2.1561e-05, 1.4461e-05,\n",
       "            9.1235e-06, 1.7986e-05, 4.7054e-06, 2.2875e-05, 1.6081e-05, 1.8199e-05,\n",
       "            1.1439e-05, 2.2803e-05, 1.5625e-05, 1.1493e-05, 2.1034e-05, 1.4871e-05,\n",
       "            1.3414e-05, 8.6601e-06, 9.7665e-06, 4.5286e-05, 2.1961e-05, 7.2777e-06,\n",
       "            3.2907e-05, 5.2185e-05, 2.7185e-05, 8.6812e-06], device='cuda:0')},\n",
       "   22: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-5.2175e-04,  1.8954e-03, -1.7219e-04,  3.1766e-04, -4.9475e-04,\n",
       "             1.7841e-04,  2.7009e-04, -7.5830e-05,  3.9030e-04, -7.4028e-04,\n",
       "             2.1996e-04, -3.6965e-04,  5.7878e-05,  4.5167e-04, -2.6029e-05,\n",
       "             1.2751e-04,  1.6983e-03,  1.0773e-03,  4.3910e-04,  1.7228e-05,\n",
       "             2.3872e-04, -6.3641e-04, -5.3034e-05,  4.2308e-04,  7.7991e-04,\n",
       "            -2.3911e-04,  4.2785e-04,  4.3769e-04, -5.4358e-05, -3.2134e-04,\n",
       "             7.2898e-04,  1.0765e-03, -3.4901e-05, -2.1346e-04, -3.6234e-04,\n",
       "             1.6992e-04, -1.6554e-05,  1.3425e-04,  2.0575e-04,  1.0717e-04,\n",
       "            -2.8803e-04, -1.4140e-04,  3.6362e-04,  8.0206e-04, -5.8542e-04,\n",
       "            -4.0052e-04, -1.2203e-04, -4.5467e-04,  1.9417e-04,  2.0495e-04,\n",
       "            -2.6948e-04,  1.9037e-03, -9.8025e-05, -6.0758e-04, -1.0926e-04,\n",
       "            -3.8986e-04,  2.9686e-04, -5.2994e-04, -1.9485e-04,  9.4008e-04,\n",
       "            -1.9386e-04, -3.5274e-04,  1.2637e-03,  1.8682e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.6766e-07, 3.0265e-06, 1.2664e-06, 1.5144e-07, 2.2995e-07, 1.3028e-06,\n",
       "            6.8208e-07, 3.6088e-07, 2.2038e-06, 3.5345e-07, 3.4449e-07, 1.2919e-07,\n",
       "            5.5110e-07, 1.2598e-06, 1.4062e-07, 4.2340e-07, 1.5627e-06, 2.7876e-06,\n",
       "            8.3502e-07, 7.3945e-07, 5.3048e-07, 1.6949e-06, 1.2140e-08, 2.2105e-06,\n",
       "            1.6590e-06, 3.1759e-07, 5.7869e-07, 8.4929e-07, 2.0983e-06, 1.5449e-07,\n",
       "            1.6382e-06, 6.7268e-06, 2.8840e-08, 4.1886e-07, 3.8371e-07, 7.3756e-07,\n",
       "            3.7245e-08, 8.3405e-07, 9.8671e-07, 1.3736e-07, 5.0264e-07, 2.4399e-07,\n",
       "            3.9674e-07, 1.4505e-06, 6.3830e-07, 1.6252e-07, 1.2021e-06, 7.8627e-07,\n",
       "            1.2241e-06, 4.6020e-07, 9.2498e-07, 5.8118e-06, 5.4930e-08, 2.6054e-07,\n",
       "            2.0034e-07, 2.6819e-07, 1.3632e-07, 1.0314e-05, 8.8706e-07, 4.5243e-06,\n",
       "            2.6832e-07, 6.4091e-08, 2.4796e-06, 3.2885e-06], device='cuda:0')},\n",
       "   23: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 4.3378e-04,  1.0836e-03, -3.1226e-04,  9.5346e-04,  1.1200e-03,\n",
       "            -1.7227e-04, -5.0787e-04,  3.1322e-04,  6.9004e-04,  8.6191e-04,\n",
       "             3.8783e-04,  2.3539e-04,  1.2377e-04, -2.3403e-04,  5.6705e-04,\n",
       "             2.7070e-04, -1.1481e-03, -8.3648e-04, -4.4083e-04,  1.3676e-04,\n",
       "            -1.4484e-05, -4.8311e-04,  1.8398e-04, -3.2757e-04, -8.5648e-04,\n",
       "            -1.0099e-04,  8.0827e-04,  3.1621e-04,  6.7192e-05,  1.0739e-03,\n",
       "            -7.0604e-04, -4.2638e-04, -1.9689e-04, -1.6972e-04,  1.4343e-04,\n",
       "             4.2954e-04, -2.5315e-04, -2.2668e-04, -1.1029e-04, -6.3767e-04,\n",
       "            -2.4514e-04, -2.1785e-04,  8.2254e-04, -6.7635e-04,  1.3023e-03,\n",
       "            -7.2734e-04,  6.2825e-07, -2.4397e-04, -3.6457e-04, -2.8712e-04,\n",
       "            -3.2782e-04,  9.3866e-04,  5.0700e-05, -4.4358e-04,  7.4656e-05,\n",
       "            -1.1734e-03, -6.2318e-04,  1.2850e-04,  2.1218e-04, -5.0245e-04,\n",
       "             7.3855e-04,  1.0904e-03,  1.1354e-03,  1.7223e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([7.4110e-07, 1.7112e-06, 9.4373e-07, 1.0252e-06, 1.4950e-06, 2.0674e-06,\n",
       "            1.2129e-06, 2.1731e-06, 1.1166e-06, 1.6954e-06, 5.3677e-07, 1.6691e-06,\n",
       "            1.4014e-06, 8.1970e-07, 2.0495e-06, 1.0906e-06, 1.5703e-06, 9.6231e-07,\n",
       "            8.3483e-07, 1.8061e-06, 1.6140e-06, 8.1870e-07, 4.2148e-07, 1.0769e-06,\n",
       "            1.3024e-06, 1.5286e-06, 1.0001e-06, 5.4741e-07, 1.5144e-06, 1.2772e-06,\n",
       "            1.2046e-06, 1.0177e-06, 7.2457e-07, 1.1291e-06, 2.0668e-06, 1.1493e-06,\n",
       "            7.8594e-07, 7.4738e-07, 1.0230e-06, 9.2089e-07, 1.8761e-06, 1.2353e-06,\n",
       "            1.5805e-06, 1.0025e-06, 1.8187e-06, 6.5234e-07, 1.4168e-06, 5.2146e-07,\n",
       "            1.4665e-06, 1.2966e-06, 5.3752e-07, 1.2060e-06, 8.4954e-07, 1.2941e-06,\n",
       "            7.1215e-07, 1.3890e-06, 2.3481e-06, 2.3100e-06, 2.8067e-06, 1.1891e-06,\n",
       "            1.7979e-06, 6.8557e-07, 1.3329e-06, 1.6490e-06], device='cuda:0')},\n",
       "   24: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[-2.5731e-04, -8.1924e-05,  1.3762e-04,  ..., -5.0657e-05,\n",
       "             -2.4664e-04,  8.6969e-05],\n",
       "            [-1.4250e-04,  1.1159e-03,  4.6777e-04,  ..., -2.1819e-04,\n",
       "              1.0008e-03,  6.9058e-04],\n",
       "            [ 2.7614e-05, -3.0913e-05, -2.7360e-05,  ..., -3.6543e-05,\n",
       "              6.9939e-06, -4.0560e-05],\n",
       "            ...,\n",
       "            [-5.5686e-05,  9.4576e-05,  7.3530e-05,  ..., -1.4509e-05,\n",
       "              7.8707e-05,  8.2458e-05],\n",
       "            [-8.3115e-05,  5.6361e-04,  5.1586e-04,  ..., -7.8222e-05,\n",
       "              4.9458e-04,  2.5958e-04],\n",
       "            [-4.4481e-04,  1.1999e-03,  6.3916e-04,  ..., -1.9186e-04,\n",
       "              9.9507e-04,  6.3695e-04]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.7724e-07, 2.6667e-06, 2.0364e-06,  ..., 1.3908e-07, 2.8982e-06,\n",
       "             3.6362e-06],\n",
       "            [1.8639e-07, 1.9071e-06, 9.3655e-07,  ..., 9.9806e-08, 1.6858e-06,\n",
       "             1.4476e-06],\n",
       "            [8.6946e-09, 1.2477e-07, 5.7686e-08,  ..., 9.7105e-09, 1.4866e-07,\n",
       "             1.1978e-07],\n",
       "            ...,\n",
       "            [3.2176e-09, 2.9395e-08, 1.5870e-08,  ..., 1.9171e-09, 2.7978e-08,\n",
       "             2.8484e-08],\n",
       "            [3.2065e-07, 2.3977e-06, 1.3754e-06,  ..., 1.2731e-07, 2.1242e-06,\n",
       "             2.0026e-06],\n",
       "            [1.6270e-07, 1.7739e-06, 1.0647e-06,  ..., 1.2073e-07, 1.7854e-06,\n",
       "             1.9262e-06]], device='cuda:0')},\n",
       "   25: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-2.5147e-05,  5.9914e-04, -8.3455e-06,  1.6118e-05,  1.1177e-04,\n",
       "            -1.3195e-04, -1.0807e-04,  9.1649e-05,  6.2743e-04,  1.4890e-04,\n",
       "             6.3905e-05,  3.2044e-05, -7.3092e-04, -1.0549e-04,  6.0350e-05,\n",
       "             7.9929e-04, -5.3087e-04,  1.0819e-03, -1.6827e-04, -3.0408e-04,\n",
       "            -1.5417e-04,  1.6461e-04,  2.3593e-05, -3.7702e-04, -1.4514e-04,\n",
       "            -7.7764e-04, -9.4525e-05,  1.9340e-04,  3.8008e-04,  5.5848e-04,\n",
       "             5.0601e-05,  8.9624e-04, -1.0509e-03, -4.6857e-05, -3.6971e-05,\n",
       "             5.1965e-04,  1.0567e-04,  1.6416e-04,  5.1701e-04, -4.0858e-04,\n",
       "            -6.2802e-04, -1.7822e-05, -1.3469e-04,  7.3937e-04,  2.9308e-05,\n",
       "            -2.0297e-04, -1.2052e-04, -6.9864e-05,  9.2136e-04,  1.0543e-03,\n",
       "             5.0635e-04,  8.4152e-05, -3.0118e-04,  7.7399e-04, -7.3197e-05,\n",
       "            -4.3218e-06, -5.3568e-05,  1.1819e-04,  6.9590e-04, -4.1974e-06,\n",
       "            -4.1271e-04,  3.7329e-05, -2.8273e-05,  7.0361e-06, -3.1371e-04,\n",
       "            -2.6063e-04,  3.6219e-05, -8.9757e-05, -2.1753e-04,  7.3407e-04,\n",
       "             2.5163e-05,  1.5391e-04,  7.9954e-04, -3.5254e-04, -3.4810e-05,\n",
       "             3.2825e-04, -2.0660e-05, -6.3517e-05,  3.8331e-04, -6.4541e-05,\n",
       "            -9.5282e-05,  2.0319e-04,  3.1690e-04,  1.4398e-04, -1.6629e-04,\n",
       "             8.2048e-05,  3.9297e-04, -8.8803e-05,  1.1099e-04, -4.5237e-04,\n",
       "             2.3467e-04,  3.9177e-04,  5.3537e-04, -6.5900e-05,  2.8101e-04,\n",
       "            -5.8376e-04, -9.4464e-04,  7.6234e-04, -4.1330e-05, -4.6118e-04,\n",
       "            -3.9388e-04,  1.7414e-04, -3.7311e-05, -7.2523e-05,  2.6108e-05,\n",
       "             4.5448e-04,  9.5699e-05,  9.0071e-04, -9.6632e-06,  7.1476e-04,\n",
       "            -3.5784e-05,  2.5596e-05,  9.2412e-04, -8.4810e-05, -1.2261e-04,\n",
       "             3.0571e-05,  3.7216e-04,  2.1858e-04,  3.9193e-04,  4.3853e-04,\n",
       "            -2.0405e-04,  4.1706e-07, -6.5761e-04, -9.7915e-06, -2.8524e-04,\n",
       "            -1.5935e-04,  8.4610e-04,  1.0999e-04,  1.1740e-04,  5.1039e-05,\n",
       "            -4.3220e-04,  7.2764e-05, -4.6993e-05,  5.1273e-04, -6.4538e-05,\n",
       "             7.4785e-04,  5.3254e-04, -2.8725e-04, -9.5626e-05,  8.2724e-05,\n",
       "            -9.2997e-05, -3.9658e-04, -1.9184e-04,  8.4080e-06, -7.9674e-05,\n",
       "            -7.5292e-04,  1.5207e-05,  1.7623e-04, -4.9251e-05,  4.4710e-05,\n",
       "            -1.7265e-05,  2.7833e-04,  5.3710e-04, -4.7715e-05, -1.5778e-04,\n",
       "            -9.6001e-05,  1.6838e-04, -5.1542e-04, -2.2194e-05, -2.6712e-05,\n",
       "             2.1464e-05,  1.3230e-04,  1.1801e-03, -3.2910e-04, -9.6788e-05,\n",
       "            -3.6354e-04,  6.0471e-05, -1.0912e-04,  1.6179e-03, -7.8370e-04,\n",
       "             4.5619e-04,  3.0113e-04,  1.5342e-03, -1.1618e-04,  7.1433e-04,\n",
       "             2.7091e-05,  1.7285e-04, -1.5613e-04, -1.3275e-04, -3.2767e-05,\n",
       "            -3.1183e-04, -4.4625e-04,  1.1906e-05, -6.0375e-04, -1.3047e-03,\n",
       "            -1.9285e-04,  1.1698e-05, -6.7115e-04,  5.1693e-05,  6.5916e-05,\n",
       "             4.1617e-04,  6.0772e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.5852e-06, 8.4187e-07, 6.5922e-08, 5.8256e-09, 1.3345e-06, 7.8018e-08,\n",
       "            2.1096e-07, 1.4795e-06, 1.7137e-06, 1.2288e-07, 1.7396e-08, 1.8798e-06,\n",
       "            2.2382e-06, 5.5844e-06, 1.5791e-06, 1.1738e-06, 6.7219e-07, 2.0333e-06,\n",
       "            3.1638e-06, 9.1514e-07, 6.6087e-07, 2.1041e-06, 1.6042e-07, 1.4565e-06,\n",
       "            7.1802e-08, 5.6055e-07, 6.4085e-07, 1.8500e-07, 7.1335e-07, 4.6659e-06,\n",
       "            2.9670e-07, 1.4402e-06, 1.4909e-06, 8.4561e-07, 5.8237e-08, 7.0303e-07,\n",
       "            1.4519e-06, 1.1903e-06, 1.5470e-06, 3.7173e-07, 5.6387e-07, 1.0231e-06,\n",
       "            1.2980e-06, 2.6174e-06, 7.0111e-07, 1.0867e-07, 3.2552e-07, 2.8200e-06,\n",
       "            9.5979e-07, 1.3543e-06, 6.2749e-07, 1.2479e-06, 2.2687e-07, 2.2276e-06,\n",
       "            3.7025e-08, 4.3625e-09, 2.1161e-08, 1.2635e-06, 2.2422e-06, 2.8037e-07,\n",
       "            3.9600e-07, 7.3269e-09, 8.0358e-09, 8.6319e-08, 4.3169e-07, 5.4776e-07,\n",
       "            7.0022e-09, 4.7091e-08, 2.3518e-07, 3.2805e-06, 7.7201e-09, 5.6397e-07,\n",
       "            2.2059e-06, 1.2011e-07, 1.0195e-06, 2.0621e-06, 1.1449e-06, 2.8696e-07,\n",
       "            1.6080e-06, 2.5473e-07, 4.7994e-07, 3.9113e-08, 2.2515e-07, 4.1492e-08,\n",
       "            1.2690e-08, 3.1974e-07, 1.8667e-06, 8.3694e-07, 9.5737e-07, 7.7044e-07,\n",
       "            1.1814e-06, 2.7291e-06, 1.2431e-06, 8.0100e-08, 4.4356e-06, 1.8417e-06,\n",
       "            3.2144e-06, 2.5930e-06, 9.8535e-08, 9.5154e-08, 8.4593e-07, 1.3464e-06,\n",
       "            6.0916e-08, 3.1003e-07, 9.1639e-07, 3.2436e-07, 7.1943e-07, 9.5087e-07,\n",
       "            2.1049e-08, 2.2303e-06, 7.8211e-08, 1.8648e-06, 1.7919e-06, 3.8265e-07,\n",
       "            1.0554e-06, 3.1153e-08, 8.1298e-07, 7.7727e-07, 1.4200e-06, 7.3019e-07,\n",
       "            7.0422e-07, 1.1133e-08, 1.1124e-06, 1.4886e-07, 6.8953e-07, 6.1138e-07,\n",
       "            5.3149e-06, 1.8847e-08, 4.6298e-07, 7.5821e-08, 6.8187e-08, 7.1244e-07,\n",
       "            1.8818e-08, 7.3427e-07, 1.0052e-08, 1.4858e-06, 3.4637e-07, 1.4242e-06,\n",
       "            6.1464e-08, 3.0298e-06, 1.6571e-07, 1.2361e-06, 1.4290e-07, 3.2119e-08,\n",
       "            3.4203e-07, 1.6716e-06, 1.9222e-06, 5.5658e-07, 3.6381e-08, 1.1670e-08,\n",
       "            9.3764e-07, 1.1563e-06, 2.1554e-06, 2.0474e-07, 8.6626e-07, 1.0225e-06,\n",
       "            1.3222e-06, 5.7996e-07, 3.2463e-06, 1.8264e-07, 5.8196e-08, 1.2570e-06,\n",
       "            1.5863e-06, 9.5274e-08, 9.0785e-08, 8.1044e-07, 2.2918e-07, 6.9485e-07,\n",
       "            3.8250e-06, 1.6717e-07, 4.1645e-06, 1.3105e-06, 2.1632e-06, 2.3509e-07,\n",
       "            3.1238e-06, 5.2466e-08, 2.1402e-06, 6.9121e-08, 1.9717e-08, 3.6222e-06,\n",
       "            1.6360e-07, 1.0029e-06, 1.7363e-06, 2.2204e-06, 6.1402e-07, 1.4427e-07,\n",
       "            1.0195e-06, 1.7304e-06, 1.1875e-07, 1.4241e-08, 1.1170e-06, 9.1413e-07],\n",
       "           device='cuda:0')},\n",
       "   26: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[ 1.0209e-03,  5.7794e-04, -2.1805e-04,  ..., -2.3644e-04,\n",
       "              8.8857e-04,  4.2104e-04],\n",
       "            [-1.0501e-03, -1.0367e-03,  3.0559e-04,  ...,  4.3358e-04,\n",
       "             -1.3583e-03,  1.7286e-04],\n",
       "            [-3.4255e-05, -6.4389e-04,  9.6037e-05,  ...,  1.8383e-04,\n",
       "             -8.1459e-04, -1.9224e-04],\n",
       "            ...,\n",
       "            [ 6.2111e-04, -8.8031e-05,  1.0569e-04,  ...,  1.8075e-05,\n",
       "             -3.7943e-04,  2.5261e-04],\n",
       "            [ 4.7175e-04,  8.8687e-04, -9.3639e-05,  ..., -2.7003e-04,\n",
       "              1.2754e-03,  2.3439e-04],\n",
       "            [-1.0387e-03, -9.6092e-04,  3.3365e-04,  ...,  3.8281e-04,\n",
       "             -1.5943e-03, -3.6428e-04]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.3213e-05, 7.1457e-07, 1.0296e-06,  ..., 1.0657e-06, 1.5453e-06,\n",
       "             1.9139e-06],\n",
       "            [5.7789e-06, 4.7577e-07, 4.2083e-07,  ..., 4.2277e-07, 1.0540e-06,\n",
       "             7.8277e-07],\n",
       "            [1.2237e-05, 6.4449e-07, 8.9424e-07,  ..., 9.7777e-07, 1.3905e-06,\n",
       "             1.7936e-06],\n",
       "            ...,\n",
       "            [1.9610e-05, 7.8100e-07, 1.4140e-06,  ..., 1.5679e-06, 1.9575e-06,\n",
       "             2.8508e-06],\n",
       "            [9.5323e-06, 7.8512e-07, 7.5671e-07,  ..., 7.6556e-07, 1.8751e-06,\n",
       "             1.6969e-06],\n",
       "            [2.9300e-06, 2.9796e-07, 2.1873e-07,  ..., 2.2220e-07, 8.3801e-07,\n",
       "             4.3156e-07]], device='cuda:0')},\n",
       "   27: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 1.6670e-03, -2.5803e-03, -1.2472e-03, -1.5653e-03,  1.9870e-03,\n",
       "            -4.4797e-06, -2.4519e-03,  3.0340e-03,  4.5902e-04,  3.1401e-03,\n",
       "             1.4755e-03, -7.6861e-04, -7.0800e-04, -2.9740e-03,  3.4353e-03,\n",
       "             6.8072e-04, -1.9225e-03,  1.1248e-03, -7.0786e-04,  1.1019e-03,\n",
       "            -1.2964e-03,  1.0331e-04,  8.7647e-05, -7.1153e-04, -2.8267e-04,\n",
       "             1.0956e-03, -1.6135e-04, -2.0558e-03,  1.3118e-03,  1.0702e-03,\n",
       "            -2.1232e-03,  6.9170e-04, -3.3784e-04, -1.5005e-03,  6.5890e-04,\n",
       "            -9.6586e-04, -1.0952e-03, -3.7184e-04, -7.9067e-04, -1.4069e-03,\n",
       "             1.1402e-03,  2.8131e-04, -4.9503e-04,  2.2940e-03,  5.2240e-04,\n",
       "            -2.4900e-03, -1.3962e-03, -4.8552e-04, -2.7102e-03, -2.1584e-03,\n",
       "            -9.0470e-04, -1.3686e-03,  4.3532e-04, -3.7130e-04,  3.9364e-03,\n",
       "            -1.9470e-03,  2.5854e-03,  9.4869e-05,  2.4689e-03,  7.5010e-04,\n",
       "             1.5309e-03, -4.9481e-05,  1.8590e-03, -2.6499e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([3.8333e-05, 1.4760e-05, 3.5353e-05, 1.6613e-05, 1.2716e-05, 9.6733e-06,\n",
       "            9.0694e-06, 1.6064e-05, 1.3297e-05, 2.1638e-05, 1.1523e-05, 2.1925e-05,\n",
       "            1.6363e-05, 4.5062e-05, 2.4838e-05, 2.8187e-05, 1.8731e-05, 2.0720e-05,\n",
       "            1.4522e-05, 1.5855e-05, 2.4643e-05, 1.2040e-05, 1.3124e-05, 3.6337e-05,\n",
       "            1.3310e-05, 2.2829e-05, 1.6946e-05, 1.5052e-05, 9.2104e-06, 1.0935e-05,\n",
       "            2.0448e-05, 1.6099e-05, 1.4842e-05, 2.4674e-05, 1.8405e-05, 1.7108e-05,\n",
       "            1.1047e-05, 2.4395e-05, 6.9842e-06, 5.3686e-06, 1.9944e-05, 1.5540e-05,\n",
       "            9.1804e-06, 2.1129e-05, 4.8324e-06, 2.5666e-05, 1.7090e-05, 1.9015e-05,\n",
       "            1.3311e-05, 2.1313e-05, 1.7101e-05, 1.3115e-05, 2.7229e-05, 1.3026e-05,\n",
       "            1.8392e-05, 8.5950e-06, 1.2573e-05, 4.2050e-05, 1.7737e-05, 8.4651e-06,\n",
       "            3.7749e-05, 5.6272e-05, 2.8443e-05, 8.1482e-06], device='cuda:0')},\n",
       "   28: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-1.8795e-03, -3.1785e-03, -1.2382e-03, -3.4039e-04, -1.3923e-03,\n",
       "            -1.3721e-03, -1.4521e-04,  3.0548e-04,  7.9296e-04, -1.1077e-03,\n",
       "             1.2837e-03,  1.0543e-03, -1.5048e-03,  3.7497e-03,  1.4869e-03,\n",
       "             1.8296e-04,  2.4946e-03, -2.2569e-03, -6.3256e-05, -1.6110e-03,\n",
       "             4.4853e-04, -3.7455e-04, -4.5312e-04,  1.8512e-03,  4.4877e-04,\n",
       "            -1.6571e-03,  1.4868e-04, -5.9452e-04, -8.7275e-04, -4.6173e-04,\n",
       "             3.3050e-03, -5.2363e-04, -1.2647e-03,  5.7822e-04, -3.1728e-03,\n",
       "             4.7228e-04, -5.6804e-04,  7.1002e-04, -8.4199e-04,  7.9024e-05,\n",
       "             7.3462e-04,  2.7334e-04, -1.0155e-03, -4.4060e-03, -1.1631e-03,\n",
       "            -2.3159e-03, -7.1017e-04,  9.5993e-05,  1.4901e-03, -1.8440e-04,\n",
       "             2.4746e-04, -7.6284e-04, -7.9439e-04, -1.8562e-03,  1.5217e-03,\n",
       "             9.3537e-04, -6.1073e-04,  8.3295e-04,  1.6512e-03, -3.2474e-03,\n",
       "            -1.8371e-03, -5.2504e-04,  2.0111e-03, -2.1442e-03], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([7.5238e-06, 2.8001e-05, 1.1349e-04, 3.4607e-06, 4.9027e-06, 1.2498e-05,\n",
       "            1.7295e-05, 8.0842e-06, 4.3424e-05, 7.0923e-06, 1.0087e-05, 4.4786e-06,\n",
       "            1.5487e-05, 1.1613e-04, 5.0912e-06, 1.7469e-05, 1.7583e-05, 1.3487e-04,\n",
       "            2.1387e-05, 9.1159e-06, 1.7525e-05, 2.1948e-05, 6.7861e-07, 6.6423e-05,\n",
       "            5.1957e-05, 5.2088e-06, 1.0204e-05, 2.8022e-05, 3.0332e-05, 1.6022e-06,\n",
       "            4.8375e-05, 2.3429e-04, 1.6096e-06, 1.0148e-05, 6.9556e-06, 1.0019e-05,\n",
       "            7.0046e-07, 6.0361e-05, 1.9211e-05, 1.4037e-06, 1.0544e-05, 8.2019e-06,\n",
       "            2.7290e-06, 3.7193e-05, 2.9784e-06, 1.0818e-05, 2.1383e-05, 5.3689e-05,\n",
       "            1.7799e-05, 1.5543e-05, 3.3611e-05, 1.1711e-04, 4.3061e-06, 4.5332e-06,\n",
       "            4.4411e-06, 3.1609e-06, 3.5089e-06, 1.8757e-04, 8.8340e-06, 4.0270e-05,\n",
       "            1.0336e-05, 6.9789e-06, 8.1897e-05, 1.7589e-05], device='cuda:0')},\n",
       "   29: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([ 0.0022, -0.0024, -0.0002, -0.0007,  0.0019,  0.0016, -0.0009,  0.0042,\n",
       "             0.0018,  0.0036,  0.0024, -0.0027, -0.0012, -0.0013,  0.0025,  0.0011,\n",
       "            -0.0022,  0.0017, -0.0001,  0.0008, -0.0008, -0.0002,  0.0009, -0.0016,\n",
       "            -0.0002,  0.0013,  0.0005, -0.0016,  0.0015,  0.0006, -0.0015,  0.0010,\n",
       "            -0.0007,  0.0012,  0.0013, -0.0002, -0.0014, -0.0006,  0.0002, -0.0013,\n",
       "             0.0023,  0.0005, -0.0008,  0.0031,  0.0016, -0.0029, -0.0007, -0.0010,\n",
       "            -0.0028, -0.0007, -0.0007, -0.0009,  0.0008,  0.0008,  0.0041, -0.0010,\n",
       "             0.0027,  0.0012,  0.0027,  0.0017,  0.0016,  0.0006,  0.0016, -0.0023],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([6.6902e-05, 1.8268e-05, 7.7565e-05, 2.7227e-05, 2.0411e-05, 2.0448e-05,\n",
       "            2.1006e-05, 2.5373e-05, 2.2950e-05, 3.0683e-05, 1.6752e-05, 3.6878e-05,\n",
       "            1.9993e-05, 6.0345e-05, 3.8906e-05, 4.8938e-05, 2.8970e-05, 4.6055e-05,\n",
       "            1.6986e-05, 2.1639e-05, 4.7076e-05, 1.3178e-05, 1.4967e-05, 7.9557e-05,\n",
       "            3.2218e-05, 3.8400e-05, 2.1111e-05, 2.3399e-05, 2.2929e-05, 1.5147e-05,\n",
       "            3.2470e-05, 3.8435e-05, 2.3141e-05, 3.9652e-05, 2.7979e-05, 2.4926e-05,\n",
       "            1.5406e-05, 5.6729e-05, 1.5572e-05, 1.0854e-05, 3.4210e-05, 2.0185e-05,\n",
       "            1.1249e-05, 2.3998e-05, 6.9800e-06, 3.2362e-05, 1.9479e-05, 3.6040e-05,\n",
       "            1.4351e-05, 2.9321e-05, 2.3312e-05, 2.1277e-05, 4.2936e-05, 1.8106e-05,\n",
       "            2.5559e-05, 1.6129e-05, 1.9561e-05, 5.0317e-05, 2.9779e-05, 9.2760e-06,\n",
       "            6.5805e-05, 9.9481e-05, 3.6266e-05, 9.8067e-06], device='cuda:0')},\n",
       "   30: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([[-4.5693e-03, -5.3156e-03,  3.9742e-03,  6.2905e-03, -5.0713e-03,\n",
       "             -7.8759e-03,  6.8157e-03, -1.0285e-02, -6.1844e-03, -7.5657e-03,\n",
       "             -2.1862e-03,  7.7072e-03, -6.9843e-03,  1.0063e-02, -7.9992e-03,\n",
       "              1.1679e-03,  9.6171e-03,  2.7191e-03,  7.1326e-03,  8.9605e-05,\n",
       "              2.0291e-03, -1.6157e-03, -1.2674e-03, -3.5825e-03,  3.7560e-03,\n",
       "              5.7074e-04, -1.1331e-02, -1.2211e-04,  2.6515e-03, -1.3518e-03,\n",
       "              7.8632e-03, -1.9503e-03, -1.1320e-04,  5.3857e-03, -1.0553e-02,\n",
       "              8.0095e-03, -1.2148e-04,  9.1184e-03,  5.0212e-03, -2.0801e-04,\n",
       "             -9.0454e-03, -1.6379e-03, -6.5492e-03,  6.4192e-03, -8.7033e-03,\n",
       "              3.2690e-03,  2.4023e-03,  5.9427e-03,  5.9149e-03,  9.8024e-04,\n",
       "              9.0341e-03, -2.8718e-03, -1.0964e-03,  5.7807e-03, -5.2005e-03,\n",
       "              5.5286e-03,  4.7527e-03, -1.3622e-02, -3.8294e-03,  7.3439e-03,\n",
       "              2.2615e-03, -9.2608e-04, -7.8728e-03, -3.3183e-03],\n",
       "            [ 3.8448e-04,  5.5082e-03, -1.5718e-03,  8.2047e-04,  1.4725e-03,\n",
       "              4.6482e-04, -6.6000e-03, -2.8987e-03,  2.6099e-03,  3.1837e-03,\n",
       "              1.3435e-03, -7.0735e-03,  3.2174e-03, -4.0821e-03,  1.5306e-03,\n",
       "              1.4594e-03, -4.1474e-03, -2.3355e-03, -4.4408e-03,  3.1712e-03,\n",
       "             -5.8557e-04,  8.4725e-04,  3.6895e-03, -2.0189e-03, -6.0680e-03,\n",
       "             -1.5581e-03,  6.6721e-03,  1.5801e-03, -1.3970e-03, -4.6512e-04,\n",
       "             -7.4425e-03, -3.1903e-03,  2.0781e-03, -1.8860e-04,  8.5488e-03,\n",
       "              3.1361e-03,  1.1988e-03, -5.9679e-03, -6.6157e-03, -5.4864e-04,\n",
       "              3.5218e-03,  1.4048e-03,  5.3764e-03, -6.8876e-03,  1.2952e-03,\n",
       "             -2.8586e-04, -1.2814e-03,  1.0401e-03, -3.0684e-03,  1.6578e-03,\n",
       "              1.5688e-03,  8.3802e-03, -3.9282e-04, -5.8501e-03,  4.2976e-03,\n",
       "             -1.6324e-03, -3.7669e-03,  4.9284e-03, -8.8047e-05, -1.6895e-03,\n",
       "              2.8763e-03, -1.8139e-03,  4.9104e-03,  2.5559e-03],\n",
       "            [-5.2581e-03,  9.9204e-03,  4.6285e-03, -3.7087e-03, -1.2482e-03,\n",
       "             -1.8452e-03, -2.1044e-03,  1.7447e-03,  1.0457e-02, -3.3338e-03,\n",
       "              6.1854e-03, -4.9777e-03,  1.1918e-02, -2.3532e-02,  6.1627e-03,\n",
       "              2.7236e-03, -1.0701e-02, -1.1823e-02, -1.3328e-02, -5.6205e-03,\n",
       "             -1.3075e-03,  1.3038e-02, -1.0251e-03, -6.5237e-03, -5.7251e-03,\n",
       "              9.9341e-04,  5.8299e-03,  9.4773e-03, -5.9338e-03, -1.5748e-03,\n",
       "             -6.1713e-03, -1.8589e-02, -3.0634e-03,  3.2554e-03,  1.3984e-03,\n",
       "              3.0836e-03,  7.5011e-05, -1.2799e-03, -6.9195e-03, -5.0930e-04,\n",
       "              9.1570e-03,  6.6831e-03,  1.3853e-03, -1.2143e-02, -2.1322e-03,\n",
       "              6.5690e-03, -8.1825e-03,  2.6063e-03, -7.6476e-03, -7.5207e-03,\n",
       "              1.0196e-02,  1.5089e-02, -1.1313e-03,  3.5097e-03,  3.1397e-03,\n",
       "              2.8866e-03, -1.0043e-03,  2.9913e-02,  9.7963e-03, -1.9145e-02,\n",
       "             -6.5608e-03, -6.9177e-03,  1.8881e-02,  8.7038e-03],\n",
       "            [-5.8755e-03, -1.1508e-03,  6.2878e-03,  2.4212e-04, -3.1129e-03,\n",
       "             -5.4354e-03,  9.8318e-04, -2.0918e-03, -1.4261e-03, -3.1608e-03,\n",
       "             -1.6897e-03,  7.3786e-03,  1.6289e-03, -1.8244e-03, -1.5691e-03,\n",
       "              5.9717e-04,  2.5446e-03, -1.3537e-03, -2.1408e-03, -8.3131e-03,\n",
       "              7.1957e-03,  2.5312e-03, -3.0661e-03, -4.2591e-03,  3.8649e-03,\n",
       "              6.0283e-03, -5.7647e-03,  2.3342e-03,  1.0395e-03,  8.5452e-04,\n",
       "              7.6918e-03, -9.5954e-03, -2.1087e-03,  4.7533e-03, -9.2678e-03,\n",
       "              3.2655e-03,  1.2582e-03,  4.6182e-04,  4.4844e-03,  2.1505e-03,\n",
       "             -1.5688e-03,  3.2252e-03, -5.3625e-03, -7.5631e-04, -9.4833e-03,\n",
       "             -1.3978e-05, -5.5118e-03,  4.0767e-03,  4.2727e-03, -1.3777e-03,\n",
       "              9.9096e-03, -2.3328e-03,  1.5954e-03,  3.7359e-03, -2.1840e-03,\n",
       "              3.9207e-03, -4.0402e-04, -2.7934e-03,  5.8104e-03,  7.1939e-04,\n",
       "             -1.9522e-03,  3.4153e-03, -4.4338e-03,  2.5091e-03],\n",
       "            [ 9.0435e-04, -2.0857e-03, -4.2035e-03,  1.0219e-03, -6.8550e-05,\n",
       "              3.0017e-04,  5.4429e-03,  8.0997e-05, -5.6687e-03, -8.6956e-04,\n",
       "             -3.2571e-03,  6.0862e-03, -2.7468e-03,  1.0152e-02, -5.1130e-04,\n",
       "             -3.3029e-04,  3.0338e-03,  4.4458e-03,  3.7375e-03,  3.1178e-03,\n",
       "             -5.3332e-03, -6.1769e-03,  1.3493e-03,  3.5581e-03,  2.7177e-03,\n",
       "             -2.2089e-03, -9.0554e-04, -4.2024e-03,  2.3745e-03, -1.7562e-03,\n",
       "              3.9809e-03,  1.2046e-02, -8.3491e-04, -2.6853e-03, -1.4173e-03,\n",
       "             -2.3897e-03,  2.3279e-03,  1.8925e-03,  2.0994e-03,  1.9970e-03,\n",
       "             -6.3168e-03, -5.0956e-03, -2.6531e-03,  5.0716e-03,  1.0392e-03,\n",
       "              6.7933e-04,  6.9731e-03, -2.1817e-03,  4.0796e-03,  3.5536e-03,\n",
       "             -7.5671e-03, -1.1058e-02, -5.5579e-04,  5.4374e-03, -1.5241e-03,\n",
       "             -2.3310e-04,  3.0181e-03, -7.7890e-03, -5.8686e-03,  5.0487e-03,\n",
       "              2.0051e-05,  1.6283e-03, -9.3262e-03, -1.9519e-03],\n",
       "            [ 3.1668e-03, -5.5205e-03,  3.0836e-03,  1.8491e-03,  5.7591e-04,\n",
       "             -5.0320e-03, -1.4935e-03,  1.3717e-03, -5.3762e-03, -6.2961e-05,\n",
       "             -2.0243e-03,  6.3957e-03, -7.0697e-03,  3.3012e-03, -4.4226e-03,\n",
       "             -1.6830e-03,  6.9124e-03,  6.5966e-03,  8.9139e-04, -4.2163e-03,\n",
       "              2.4021e-03,  9.3343e-05, -4.4988e-03,  4.5213e-03,  8.5532e-03,\n",
       "              5.8415e-03, -5.8935e-03, -5.7968e-03,  1.5227e-03,  3.8412e-03,\n",
       "              3.3822e-03,  5.8990e-03,  3.0003e-03, -2.7476e-03, -5.0282e-03,\n",
       "              2.5878e-03, -1.9026e-03,  1.0396e-03,  6.8205e-03,  3.3399e-04,\n",
       "             -1.2130e-03,  3.8442e-04, -3.0894e-03,  5.7834e-04, -2.7163e-03,\n",
       "             -5.1060e-03, -5.8556e-03, -8.4822e-04,  4.8123e-03,  2.1650e-04,\n",
       "              4.8831e-03, -7.6461e-03,  4.8938e-03, -2.5277e-03, -8.6268e-04,\n",
       "             -2.1148e-03, -2.1161e-03, -8.5467e-03,  1.0624e-03,  6.3781e-03,\n",
       "              6.2291e-04,  2.6084e-03, -3.8322e-03, -1.5233e-03],\n",
       "            [-7.7406e-03,  2.6285e-02,  5.8724e-03, -1.4816e-03,  4.4697e-03,\n",
       "             -1.8327e-03, -8.1348e-03,  2.5682e-03,  1.6477e-02,  8.6078e-04,\n",
       "              9.7605e-03, -1.1818e-02,  1.3671e-02, -2.8036e-02,  1.1564e-02,\n",
       "              1.2741e-03, -1.8144e-02, -1.8220e-02, -2.2106e-02, -2.4013e-03,\n",
       "             -1.0458e-03,  1.7766e-02, -2.6725e-04, -1.1866e-02, -1.7359e-02,\n",
       "             -5.8561e-03,  1.9043e-02,  1.2339e-02, -4.9181e-03, -5.7257e-04,\n",
       "             -1.7728e-02, -2.7926e-02,  4.1103e-03,  4.8951e-03,  1.4443e-02,\n",
       "              3.3169e-03, -1.7818e-03, -9.8580e-03, -1.2058e-02, -1.8684e-03,\n",
       "              1.3819e-02,  7.3874e-03,  6.8186e-03, -1.9543e-02,  3.6386e-04,\n",
       "              1.2595e-03, -9.2102e-03,  5.3705e-03, -1.3062e-02, -1.1786e-02,\n",
       "              8.5976e-03,  3.2722e-02, -5.6546e-03, -5.3337e-03,  4.0180e-03,\n",
       "              8.1906e-04, -3.9623e-03,  3.7866e-02,  1.5449e-02, -3.0098e-02,\n",
       "             -3.8564e-03, -7.8921e-03,  2.8792e-02,  1.3803e-02],\n",
       "            [ 4.6746e-03, -8.9736e-03, -1.3694e-03, -1.7787e-03, -6.6343e-03,\n",
       "              3.5871e-03,  1.4909e-03,  1.4617e-03,  2.7582e-03,  6.6337e-05,\n",
       "              8.5416e-04, -3.5539e-04,  1.5634e-03,  2.7631e-03,  2.4622e-04,\n",
       "             -9.1167e-04, -3.6436e-03,  7.9318e-04,  6.0194e-03, -6.2451e-04,\n",
       "              4.1027e-04, -4.2141e-03,  2.7589e-03,  1.6892e-03, -2.9210e-05,\n",
       "             -1.6473e-03, -2.0433e-03,  9.5976e-04, -1.0578e-03, -7.4670e-04,\n",
       "              2.9255e-03,  2.4015e-04, -5.7064e-03,  9.0759e-04, -6.2380e-03,\n",
       "             -2.7905e-03,  1.1436e-03, -3.5566e-05,  7.1617e-04,  9.0362e-04,\n",
       "             -1.7163e-03,  1.0683e-03, -9.6923e-05,  7.7221e-03,  5.9006e-03,\n",
       "              1.0198e-03,  3.3187e-03,  2.2297e-03, -1.7692e-03,  2.4766e-03,\n",
       "             -3.5353e-03, -5.3843e-03, -8.5914e-04,  3.9468e-03,  4.6908e-03,\n",
       "              4.0505e-04, -1.9094e-05, -5.7446e-03, -6.3520e-03,  5.2666e-03,\n",
       "              5.3653e-03,  8.9921e-04, -6.9684e-03, -2.2950e-03],\n",
       "            [ 6.9986e-03, -1.0018e-02, -9.7783e-03, -5.4801e-03,  7.6480e-03,\n",
       "              1.2230e-02,  2.8011e-03,  7.1107e-03, -7.2285e-03,  1.2049e-02,\n",
       "             -6.0110e-03, -4.4235e-03, -8.0109e-03,  1.4593e-02,  1.1479e-03,\n",
       "             -1.8762e-03,  5.6516e-03,  9.4891e-03,  9.3256e-03,  7.6242e-03,\n",
       "             -4.1468e-03, -1.1670e-02,  3.6156e-04,  1.0074e-02,  6.1738e-03,\n",
       "              1.0299e-03, -1.7810e-03, -9.1560e-03,  3.8137e-03,  1.9296e-03,\n",
       "              2.8691e-03,  2.4198e-02,  3.6906e-04, -1.1111e-02,  6.1338e-03,\n",
       "             -1.2586e-02,  1.0684e-03,  9.1484e-04,  4.6423e-03, -2.1673e-04,\n",
       "             -2.2386e-04, -5.2773e-03,  3.7964e-03,  8.7190e-03,  9.2371e-03,\n",
       "             -3.6357e-03,  8.0400e-03, -1.2932e-02,  1.7104e-03,  4.3581e-03,\n",
       "             -2.2466e-02, -1.9466e-02,  4.0489e-03, -5.1662e-03, -2.9175e-03,\n",
       "             -4.9857e-03,  5.3999e-04, -1.2784e-02, -7.1274e-03,  1.5161e-02,\n",
       "             -2.6846e-03,  3.9588e-03, -7.3752e-03, -9.5702e-03],\n",
       "            [ 7.3146e-03, -8.6501e-03, -6.9238e-03,  2.2249e-03,  1.9692e-03,\n",
       "              5.4392e-03,  7.9885e-04,  9.3772e-04, -6.4175e-03, -1.1665e-03,\n",
       "             -2.9752e-03,  1.0801e-03, -7.1866e-03,  1.6602e-02, -6.1498e-03,\n",
       "             -2.4211e-03,  8.8765e-03,  9.6886e-03,  1.4909e-02,  7.1729e-03,\n",
       "              3.8164e-04, -1.0600e-02,  1.9653e-03,  8.4078e-03,  4.1158e-03,\n",
       "             -3.1934e-03, -3.8260e-03, -7.4137e-03,  1.9048e-03, -1.5812e-04,\n",
       "              2.6291e-03,  1.8868e-02,  2.2688e-03, -2.4649e-03,  1.9804e-03,\n",
       "             -5.6332e-03, -3.2661e-03,  3.7142e-03,  1.8088e-03, -2.0340e-03,\n",
       "             -6.4138e-03, -8.1424e-03,  3.7437e-04,  1.0820e-02,  5.1992e-03,\n",
       "             -3.7551e-03,  9.3074e-03, -5.3037e-03,  4.7575e-03,  7.4413e-03,\n",
       "             -1.0621e-02, -7.4327e-03, -8.4811e-04, -3.5328e-03, -3.4574e-03,\n",
       "             -4.5940e-03,  2.9619e-03, -2.1427e-02, -8.8526e-03,  1.1015e-02,\n",
       "              3.9080e-03,  5.0398e-03, -1.2775e-02, -8.9128e-03]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.0537e-04, 5.6140e-04, 4.6215e-04, 5.6776e-05, 9.0304e-05, 3.2902e-04,\n",
       "             1.9841e-04, 1.2114e-04, 6.6695e-04, 1.3180e-04, 1.8772e-04, 3.7350e-05,\n",
       "             2.6161e-04, 8.7456e-04, 5.1184e-05, 1.0116e-04, 2.1053e-04, 9.1723e-04,\n",
       "             4.6231e-04, 1.5074e-04, 1.2505e-04, 6.4887e-04, 1.5502e-05, 3.7565e-04,\n",
       "             4.3768e-04, 9.9936e-05, 1.2949e-04, 5.0716e-04, 4.3102e-04, 4.4464e-05,\n",
       "             4.4673e-04, 2.3333e-03, 2.9684e-05, 1.5078e-04, 1.0682e-04, 2.9643e-04,\n",
       "             1.8533e-05, 2.4983e-04, 3.5646e-04, 5.0676e-05, 1.2003e-04, 1.2073e-04,\n",
       "             7.8689e-05, 5.1440e-04, 2.0447e-04, 1.3622e-04, 3.8332e-04, 5.3783e-04,\n",
       "             3.5665e-04, 2.3506e-04, 7.8682e-04, 2.0880e-03, 4.4476e-05, 6.9749e-05,\n",
       "             5.8140e-05, 7.3819e-05, 6.9755e-05, 1.4754e-03, 1.2591e-04, 1.5362e-03,\n",
       "             4.9486e-05, 7.7635e-05, 8.2840e-04, 7.0074e-04],\n",
       "            [1.1748e-04, 6.9815e-04, 6.8913e-04, 4.5428e-05, 9.1739e-05, 3.3518e-04,\n",
       "             3.3604e-04, 1.1109e-04, 1.0381e-03, 9.3638e-05, 3.1523e-04, 4.3243e-05,\n",
       "             4.0665e-04, 1.3450e-03, 6.6447e-05, 1.6518e-04, 2.3904e-04, 1.3530e-03,\n",
       "             7.1278e-04, 2.6522e-04, 1.8785e-04, 9.9799e-04, 1.5383e-05, 4.2910e-04,\n",
       "             6.6643e-04, 7.3535e-05, 1.3691e-04, 7.1206e-04, 7.0287e-04, 2.9432e-05,\n",
       "             6.9424e-04, 3.3067e-03, 3.2641e-05, 1.7282e-04, 1.1571e-04, 2.0286e-04,\n",
       "             1.7498e-05, 4.0255e-04, 5.6917e-04, 6.3420e-05, 1.7179e-04, 2.2531e-04,\n",
       "             8.9354e-05, 7.6233e-04, 1.3849e-04, 1.8190e-04, 6.5013e-04, 6.6339e-04,\n",
       "             5.8175e-04, 3.1715e-04, 8.7794e-04, 2.8913e-03, 5.8261e-05, 1.1002e-04,\n",
       "             5.1750e-05, 9.5349e-05, 4.9691e-05, 2.2917e-03, 1.8654e-04, 2.2251e-03,\n",
       "             6.3199e-05, 6.8882e-05, 1.1863e-03, 1.1004e-03],\n",
       "            [7.0797e-05, 8.3504e-04, 6.3240e-04, 6.3320e-05, 1.2407e-04, 3.0907e-04,\n",
       "             3.7268e-04, 1.4475e-04, 1.1353e-03, 1.0849e-04, 3.4583e-04, 6.6798e-05,\n",
       "             3.9937e-04, 1.2296e-03, 8.9343e-05, 1.7626e-04, 3.6871e-04, 1.4402e-03,\n",
       "             8.1142e-04, 1.7721e-04, 1.6350e-04, 8.6826e-04, 1.2906e-05, 3.8450e-04,\n",
       "             7.6066e-04, 9.4290e-05, 2.7071e-04, 6.5850e-04, 7.5097e-04, 4.9556e-05,\n",
       "             9.3143e-04, 3.0452e-03, 3.7050e-05, 1.2227e-04, 1.9903e-04, 2.0031e-04,\n",
       "             2.8327e-05, 5.2224e-04, 6.2574e-04, 8.0548e-05, 2.6770e-04, 2.0344e-04,\n",
       "             1.4412e-04, 7.4045e-04, 1.2824e-04, 1.7914e-04, 5.4806e-04, 5.8006e-04,\n",
       "             6.3491e-04, 3.0419e-04, 6.9284e-04, 3.0988e-03, 4.9734e-05, 1.5570e-04,\n",
       "             9.8746e-05, 1.2343e-04, 6.4337e-05, 2.3450e-03, 2.0087e-04, 2.3594e-03,\n",
       "             8.1497e-05, 7.5603e-05, 1.3157e-03, 1.0562e-03],\n",
       "            [6.7264e-05, 5.1731e-04, 2.6970e-04, 4.8301e-05, 7.0614e-05, 1.6464e-04,\n",
       "             1.5287e-04, 9.9600e-05, 5.8442e-04, 7.6026e-05, 1.6245e-04, 4.9250e-05,\n",
       "             2.6472e-04, 9.5576e-04, 1.0341e-04, 6.3966e-05, 2.9563e-04, 7.2094e-04,\n",
       "             5.6308e-04, 1.2490e-04, 7.8018e-05, 5.0884e-04, 1.1888e-05, 2.3130e-04,\n",
       "             3.8723e-04, 4.9610e-05, 2.0269e-04, 3.5969e-04, 3.3378e-04, 3.0403e-05,\n",
       "             4.7013e-04, 1.6450e-03, 1.9739e-05, 6.4925e-05, 1.4246e-04, 1.1856e-04,\n",
       "             1.6188e-05, 2.0997e-04, 2.7407e-04, 4.0180e-05, 2.0063e-04, 1.2615e-04,\n",
       "             8.2111e-05, 5.0617e-04, 9.3831e-05, 8.2127e-05, 3.5109e-04, 2.8609e-04,\n",
       "             3.8241e-04, 2.3529e-04, 4.5074e-04, 1.5830e-03, 2.7506e-05, 6.0830e-05,\n",
       "             6.4626e-05, 5.0843e-05, 4.5185e-05, 1.8057e-03, 1.8254e-04, 1.3575e-03,\n",
       "             5.2071e-05, 7.2507e-05, 8.4150e-04, 5.4556e-04],\n",
       "            [6.4797e-05, 5.3931e-04, 2.6714e-04, 5.6859e-05, 7.5601e-05, 1.7003e-04,\n",
       "             1.9559e-04, 1.4626e-04, 6.3355e-04, 1.0288e-04, 1.8581e-04, 7.2018e-05,\n",
       "             2.6560e-04, 9.4922e-04, 8.8448e-05, 7.2874e-05, 3.6325e-04, 6.9992e-04,\n",
       "             6.0745e-04, 1.3424e-04, 7.4782e-05, 5.0800e-04, 1.2549e-05, 2.2387e-04,\n",
       "             4.1198e-04, 5.0996e-05, 2.5610e-04, 3.5996e-04, 3.4740e-04, 4.7273e-05,\n",
       "             5.7939e-04, 1.6484e-03, 2.3820e-05, 7.3372e-05, 2.1681e-04, 1.5132e-04,\n",
       "             2.0961e-05, 2.6677e-04, 2.9544e-04, 3.3671e-05, 2.6198e-04, 1.2352e-04,\n",
       "             1.2671e-04, 4.9830e-04, 1.2614e-04, 9.2490e-05, 3.5988e-04, 2.6889e-04,\n",
       "             4.0832e-04, 2.1991e-04, 4.5339e-04, 1.6893e-03, 2.4609e-05, 1.0090e-04,\n",
       "             9.8219e-05, 7.5363e-05, 5.3529e-05, 1.7135e-03, 1.9239e-04, 1.4280e-03,\n",
       "             3.7752e-05, 6.6176e-05, 8.9431e-04, 5.5060e-04],\n",
       "            [6.4760e-05, 6.3345e-04, 4.5901e-04, 6.0216e-05, 1.0156e-04, 2.3906e-04,\n",
       "             2.7206e-04, 1.0587e-04, 8.7079e-04, 8.1293e-05, 2.5210e-04, 5.6700e-05,\n",
       "             3.3797e-04, 1.0706e-03, 9.9070e-05, 1.2611e-04, 3.2925e-04, 1.1496e-03,\n",
       "             6.5883e-04, 1.3765e-04, 1.2729e-04, 7.0638e-04, 1.3487e-05, 3.3619e-04,\n",
       "             5.9493e-04, 6.5569e-05, 2.3386e-04, 5.3611e-04, 5.7636e-04, 3.5071e-05,\n",
       "             6.5233e-04, 2.3909e-03, 2.4579e-05, 1.0216e-04, 1.5029e-04, 1.4118e-04,\n",
       "             1.8837e-05, 3.6653e-04, 4.5740e-04, 6.6172e-05, 2.0412e-04, 1.6055e-04,\n",
       "             1.1556e-04, 6.1646e-04, 8.9082e-05, 1.3406e-04, 4.5314e-04, 4.5850e-04,\n",
       "             5.3187e-04, 2.6044e-04, 5.2860e-04, 2.3464e-03, 4.5837e-05, 9.1487e-05,\n",
       "             6.0757e-05, 7.8855e-05, 5.6416e-05, 2.0541e-03, 1.6943e-04, 1.8471e-03,\n",
       "             6.9419e-05, 7.5626e-05, 1.0566e-03, 8.1992e-04],\n",
       "            [4.7905e-05, 6.2439e-04, 4.8079e-04, 5.8245e-05, 9.7056e-05, 2.4416e-04,\n",
       "             3.0200e-04, 1.4306e-04, 9.4676e-04, 8.9941e-05, 2.9664e-04, 6.6626e-05,\n",
       "             3.5482e-04, 1.0897e-03, 8.9330e-05, 1.3275e-04, 3.5457e-04, 1.1279e-03,\n",
       "             7.3503e-04, 1.4115e-04, 1.2387e-04, 6.8536e-04, 1.1427e-05, 3.0561e-04,\n",
       "             6.7575e-04, 9.4335e-05, 2.4561e-04, 5.3317e-04, 5.8103e-04, 4.2232e-05,\n",
       "             7.6197e-04, 2.3263e-03, 2.3550e-05, 1.0146e-04, 1.7071e-04, 1.7834e-04,\n",
       "             2.0912e-05, 4.4428e-04, 5.3142e-04, 6.5884e-05, 2.7455e-04, 1.8267e-04,\n",
       "             1.3269e-04, 6.3889e-04, 1.1995e-04, 1.4234e-04, 4.7138e-04, 3.8129e-04,\n",
       "             5.4353e-04, 2.5015e-04, 5.0789e-04, 2.3909e-03, 4.2110e-05, 1.2229e-04,\n",
       "             9.9882e-05, 8.8423e-05, 7.7868e-05, 2.1315e-03, 1.9020e-04, 1.8790e-03,\n",
       "             5.6036e-05, 6.6621e-05, 1.0722e-03, 9.0278e-04],\n",
       "            [7.8991e-05, 6.2443e-04, 4.4349e-04, 5.2121e-05, 9.7603e-05, 2.0705e-04,\n",
       "             2.7607e-04, 1.1788e-04, 8.1944e-04, 7.5942e-05, 2.4772e-04, 5.0332e-05,\n",
       "             3.0946e-04, 1.0819e-03, 8.6034e-05, 1.1992e-04, 3.2394e-04, 1.0446e-03,\n",
       "             6.5821e-04, 1.5977e-04, 1.2322e-04, 6.9522e-04, 1.3496e-05, 2.9322e-04,\n",
       "             5.2493e-04, 5.5243e-05, 1.9478e-04, 4.9177e-04, 5.1726e-04, 3.3302e-05,\n",
       "             6.4962e-04, 2.2644e-03, 2.6989e-05, 9.7474e-05, 1.4337e-04, 1.2660e-04,\n",
       "             1.7988e-05, 3.5791e-04, 4.1493e-04, 5.3959e-05, 2.1362e-04, 1.6068e-04,\n",
       "             1.0243e-04, 6.1267e-04, 8.9785e-05, 1.1854e-04, 5.0125e-04, 4.4298e-04,\n",
       "             5.0528e-04, 2.5006e-04, 5.1663e-04, 2.1780e-03, 4.0735e-05, 9.6141e-05,\n",
       "             7.0107e-05, 7.8911e-05, 4.4307e-05, 2.0205e-03, 1.9603e-04, 1.7741e-03,\n",
       "             7.4948e-05, 7.0059e-05, 1.0322e-03, 7.6459e-04],\n",
       "            [1.4298e-04, 2.1678e-03, 2.7888e-03, 1.1198e-04, 4.3475e-04, 1.0960e-03,\n",
       "             1.5854e-03, 2.3077e-04, 3.9661e-03, 1.5392e-04, 1.2354e-03, 6.0256e-05,\n",
       "             1.0914e-03, 2.8256e-03, 6.4311e-05, 7.9530e-04, 6.2066e-04, 5.7177e-03,\n",
       "             1.7323e-03, 4.8418e-04, 8.3020e-04, 3.1058e-03, 2.2994e-05, 1.4543e-03,\n",
       "             2.5377e-03, 2.3161e-04, 2.5038e-04, 2.4789e-03, 3.0038e-03, 9.4341e-05,\n",
       "             2.6118e-03, 1.1505e-02, 1.2983e-04, 5.1984e-04, 1.7243e-04, 4.3924e-04,\n",
       "             6.1114e-05, 1.8977e-03, 2.3861e-03, 3.1032e-04, 2.3284e-04, 5.9503e-04,\n",
       "             3.1620e-04, 1.9887e-03, 1.8936e-04, 6.7253e-04, 1.9462e-03, 2.5914e-03,\n",
       "             1.9927e-03, 7.4674e-04, 2.1893e-03, 1.0680e-02, 2.4052e-04, 4.2735e-04,\n",
       "             5.3996e-05, 4.6617e-04, 1.2299e-04, 5.5288e-03, 1.9083e-04, 7.5289e-03,\n",
       "             2.6360e-04, 1.0367e-04, 3.5462e-03, 3.8329e-03],\n",
       "            [1.0591e-04, 5.8903e-04, 5.1587e-04, 4.1991e-05, 6.5109e-05, 2.8466e-04,\n",
       "             2.2986e-04, 8.1685e-05, 7.7111e-04, 7.1019e-05, 2.2373e-04, 3.6536e-05,\n",
       "             3.1423e-04, 1.1215e-03, 6.3203e-05, 1.1982e-04, 1.8261e-04, 1.0448e-03,\n",
       "             6.0935e-04, 1.9845e-04, 1.1539e-04, 7.8285e-04, 1.4019e-05, 3.5499e-04,\n",
       "             4.9229e-04, 6.6165e-05, 1.2159e-04, 5.6687e-04, 5.2981e-04, 2.6608e-05,\n",
       "             5.2309e-04, 2.5862e-03, 2.5486e-05, 1.3273e-04, 8.6989e-05, 1.7535e-04,\n",
       "             1.8167e-05, 2.9516e-04, 4.0328e-04, 4.9834e-05, 1.4933e-04, 1.7545e-04,\n",
       "             6.2542e-05, 6.4725e-04, 1.3757e-04, 1.3885e-04, 4.9012e-04, 4.8664e-04,\n",
       "             4.4117e-04, 2.9151e-04, 7.4175e-04, 2.2111e-03, 4.0110e-05, 8.4388e-05,\n",
       "             5.0131e-05, 6.7977e-05, 4.6772e-05, 1.9340e-03, 1.7833e-04, 1.7512e-03,\n",
       "             5.4220e-05, 7.1339e-05, 9.5817e-04, 8.5938e-04]], device='cuda:0')},\n",
       "   31: {'step': tensor(782.),\n",
       "    'exp_avg': tensor([-0.0038,  0.0033,  0.0075,  0.0011, -0.0052, -0.0010,  0.0161, -0.0019,\n",
       "            -0.0087, -0.0074], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0004, 0.0005, 0.0005, 0.0003, 0.0003, 0.0004, 0.0004, 0.0004, 0.0017,\n",
       "            0.0004], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.00011999999999999999,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.005,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'decoupled_weight_decay': True,\n",
       "    'initial_lr': 0.0003,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17,\n",
       "     18,\n",
       "     19,\n",
       "     20,\n",
       "     21,\n",
       "     22,\n",
       "     23,\n",
       "     24,\n",
       "     25,\n",
       "     26,\n",
       "     27,\n",
       "     28,\n",
       "     29,\n",
       "     30,\n",
       "     31]}]},\n",
       " 'val_acc': 30.97,\n",
       " 'val_loss': 1.9895038063049317,\n",
       " 'train_acc': 20.922,\n",
       " 'train_loss': 2.16878330657959}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "checkpoint = torch.load('/home/wd/Documents/work_stuff/ViT_REPLICATION/checkpoints/vit_small/vit_small_dataCIFAR10_valacc31.pth')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec692c",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d72394",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_vit_rep_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
